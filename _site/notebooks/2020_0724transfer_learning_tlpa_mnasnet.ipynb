{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2020-0724transfer_learning_tlpa_mnasnet.ipynb",
      "provenance": [],
      "private_outputs": true,
      "authorship_tag": "ABX9TyPr5F8GwwN4H168vwazP+TR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/project-ccap/project-ccap.github.io/blob/master/notebooks/2020_0724transfer_learning_tlpa_mnasnet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "biqi4yv5xBNR",
        "colab_type": "text"
      },
      "source": [
        "# TLPA 画像を使ってディープラーニングモデルによる転移学習を行う PyTorch デモ\n",
        "- author: 浅川伸一\n",
        "- date: 2020-0726"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFhhY4_NC3--",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 各画像の画面表示時に日本語キャプションを付与する準備\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "!pip install japanize-matplotlib\n",
        "import japanize_matplotlib\n",
        "\n",
        "#  ImageNet の各ラベルの WordNet ID 処理用\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw')\n",
        "\n",
        "# ライブラリのインストール\n",
        "!git clone https://github.com/project-ccap/ccap.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_X1G-MzSF-bx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 画像データ，設定データを Google Drive から入手\n",
        "# このセルを実行するとブラウザの別タブで Google アカウントへの認証が求められる\n",
        "# Google アカウントを選択するとクリデンシャルキーが表示されるので，そのキーを\n",
        "# コピーして，このセルの出力欄にある空欄に貼り付けてエンターキー (リターンキー) を押下する\n",
        "\n",
        "# Import PyDrive and associated libraries.\n",
        "# This only needs to be done once per notebook.\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "# This only needs to be done once per notebook.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "# 以下実際のデータの情報\n",
        "#https://drive.google.com/file/d/1xKXbovkEQwdJefzCuaS_a351LUIuRz-1/view?usp=sharing \n",
        "#for Gdrive cis.twcu.ac.jp/GitHub_shared/ccap_data.tgz\n",
        "file_id = '1xKXbovkEQwdJefzCuaS_a351LUIuRz-1'\n",
        "downloaded = drive.CreateFile({'id': file_id})\n",
        "downloaded.GetContentFile('ccap_data.tgz')\n",
        "\n",
        "# 入手したデータの解凍\n",
        "!tar xzf ccap_data.tgz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKa1wHOyZLEx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 以下は動作確認，ImageNet の利用\n",
        "# ただし本来 ImageNet の画像利用には登録が必要である\n",
        "# そのため，利用時には各ユーザの責任において ImageNet への登録申請を行うこと\n",
        "# 参照 URL: http://image-net.org/download-images\n",
        "# 文献: J. Deng, W. Dong, R. Socher, L.-J. Li, K. Li and L. Fei-Fei, ImageNet: A Large-Scale Hierarchical Image Database,\n",
        "#       IEEE Computer Vision and Pattern Recognition (CVPR), 2009.\n",
        "from ccap import imagenetDataset\n",
        "imagenet = imagenetDataset()\n",
        "\n",
        "# 最初のデータの表示\n",
        "print(imagenet(0))\n",
        "\n",
        "# 4 番目のデータ 0 から始まるので 3 が 4 番目のデータを表す\n",
        "print(imagenet.data[3])\n",
        "\n",
        "# 最後の画像データをランダムサンプリングして一枚だけ表示\n",
        "# 実行するたび表示されるデータは異なる\n",
        "imagenet.sample_and_show(999)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7yDwGfrlflw6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TLPA データの利用\n",
        "# 文献: 藤田郁代 他, 2000, 「失語症語彙検査」の開発, 音声言語医学 42:179-202\n",
        "from ccap import tlpaDataset\n",
        "tlpa = tlpaDataset()\n",
        "\n",
        "# 最初のデータの表示\n",
        "print(tlpa(0))\n",
        "\n",
        "# 図版画像の表示\n",
        "tlpa.show_an_image('桜')\n",
        "\n",
        "# 総データ数の表示\n",
        "print(tlpa.__len__())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CcYwj6NHrgLm",
        "colab_type": "text"
      },
      "source": [
        "# ここから先は PyTorch を使った転移学習の実際"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fhQPDqZ_qpsg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import PIL.Image as PILImage\n",
        "from scipy.special import logsumexp, softmax\n",
        "from termcolor import colored\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "#from torchvision import models, transforms\n",
        "import torch.utils.data as data\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xr5rqKlhj1LK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torchvision.models as models\n",
        "#resnet18 = models.resnet18()\n",
        "#alexnet = models.alexnet()\n",
        "#vgg16 = models.vgg16()\n",
        "#squeezenet = models.squeezenet1_0()\n",
        "#densenet = models.densenet161()\n",
        "#inception = models.inception_v3()\n",
        "#googlenet = models.googlenet()\n",
        "#shufflenet = models.shufflenet_v2_x1_0()\n",
        "#mobilenet = models.mobilenet_v2()\n",
        "#resnext50_32x4d = models.resnext50_32x4d()\n",
        "#wide_resnet50_2 = models.wide_resnet50_2()\n",
        "#mnasnet = models.mnasnet1_0()\n",
        "\n",
        "net = models.mnasnet1_0(pretrained=True, progress=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hlmBJnaXmrzG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchvision import transforms\n",
        "\n",
        "transform = transforms.Compose([transforms.Resize(256), \n",
        "                                transforms.CenterCrop(224), \n",
        "                                transforms.ToTensor()])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nl1tS3uBpytO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#tlpa = tlpaDataset()\n",
        "tlpa_img_path = [tlpa.data[k]['img'] for k in tlpa.data.keys()]\n",
        "#tlpa.data.keys()\n",
        "tlpa_name_dict = {i:k for i, k in enumerate(tlpa.data.keys())}\n",
        "print(tlpa_name_dict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OdAtcl1uqP9s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 入力画像の前処理をするクラス\n",
        "# 訓練時と推論時で処理が異なる\n",
        "class ImageTransform():\n",
        "    \"\"\"\n",
        "    画像の前処理クラス。訓練時、検証時で異なる動作をする。\n",
        "    画像のサイズをリサイズし、色を標準化する。\n",
        "    訓練時は RandomResizedCrop と RandomHorizontalFlip で データ拡張\n",
        "\n",
        "\n",
        "    Attributes\n",
        "    ----------\n",
        "    resize : int\n",
        "        リサイズ先の画像の大きさ。\n",
        "    mean : (R, G, B)\n",
        "        各色チャネルの平均値。\n",
        "    std : (R, G, B)\n",
        "        各色チャネルの標準偏差。\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, resize, mean, std):\n",
        "        self.data_transform = {\n",
        "                        'train': transforms.Compose(\n",
        "                            [transforms.RandomResizedCrop(resize, scale=(0.8, 1.0)),  # データ拡張\n",
        "                             transforms.RandomHorizontalFlip(),  # データ拡張\n",
        "                             transforms.RandomAffine(degrees=(-20,20), translate=None, scale=[0.9,1.1]),\n",
        "                             transforms.ToTensor(),  # テンソルに変換\n",
        "                             transforms.Normalize(mean, std)  # 標準化\n",
        "                             ]),\n",
        "                        'val': transforms.Compose(\n",
        "                            [transforms.Resize((resize, resize)),  # リサイズ\n",
        "                             # transforms.CenterCrop(resize),  # 画像中央をresize×resizeで切り取り\n",
        "                             transforms.ToTensor(),  # テンソルに変換\n",
        "                             transforms.Normalize(mean, std)  # 標準化\n",
        "                             ])\n",
        "                        }\n",
        "\n",
        "    def __call__(self, img, phase='train'):\n",
        "        \"\"\"\n",
        "        Parameters\n",
        "        ----------\n",
        "        phase : 'train' or 'val'\n",
        "            前処理のモードを指定。\n",
        "        \"\"\"\n",
        "        return self.data_transform[phase](img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HXpaMxvap0TX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Dataset の作成\n",
        "class tlpa_torch_Dataset(data.Dataset):\n",
        "    \"\"\"\n",
        "    TLPA 画像のDatasetクラス。PyTorchのDatasetクラスを継承。\n",
        "\n",
        "    Attributes\n",
        "    ----------\n",
        "    file_list : リスト\n",
        "        画像のパスを格納したリスト\n",
        "    transform : object\n",
        "        前処理クラスのインスタンス\n",
        "    phase : 'train' or 'test'\n",
        "        学習か訓練かを設定する。\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, file_list, name_dict, transform=None, phase='train'):\n",
        "        self.file_list = file_list  # ファイルパスのリスト\n",
        "        self.transform = transform  # 前処理クラスのインスタンス\n",
        "        self.phase = phase  # train or valの指定\n",
        "        self.namedict = name_dict\n",
        "\n",
        "    def __len__(self):\n",
        "        '''画像の枚数を返す'''\n",
        "        return len(self.file_list)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        '''\n",
        "        前処理をした画像のTensor形式のデータとラベルを取得\n",
        "        '''\n",
        "\n",
        "        # index番目の画像をロード\n",
        "        img_path = self.file_list[index]\n",
        "        img = PILImage.open(img_path)  # [高さ][幅][色RGB]\n",
        "\n",
        "        # 画像の前処理を実施\n",
        "        img_transformed = self.transform(\n",
        "            img, self.phase)  # torch.Size([3, 224, 224])\n",
        "\n",
        "        # 画像のラベルをファイル名から抜き出す\n",
        "        label = self.namedict[index]\n",
        "        return img_transformed, label\n",
        "\n",
        "\n",
        "# 画像の前処理に必要なパラメータの定義\n",
        "size = 224\n",
        "mean = (0.485, 0.456, 0.406)\n",
        "std = (0.229, 0.224, 0.225)\n",
        "\n",
        "train_dataset = tlpa_torch_Dataset(file_list=tlpa_img_path, \n",
        "                                   name_dict=tlpa_name_dict,  \n",
        "                                   transform=ImageTransform(size, mean, std), \n",
        "                                   phase='train')\n",
        "\n",
        "val_dataset = tlpa_torch_Dataset(file_list=tlpa_img_path, \n",
        "                                 name_dict=tlpa_name_dict, \n",
        "                                 transform=ImageTransform(size, mean, std), \n",
        "                                 phase='val')\n",
        "\n",
        "# 動作確認\n",
        "index = 3\n",
        "print(train_dataset.__getitem__(index)[0].size())\n",
        "print(train_dataset.__getitem__(index)[1])\n",
        "print(train_dataset.__len__())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QsdX1_HRqVVd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ミニバッチのサイズの設定\n",
        "batch_size = 32\n",
        "\n",
        "# DataLoaderを作成\n",
        "train_dataloader = torch.utils.data.DataLoader(\n",
        "    train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "val_dataloader = torch.utils.data.DataLoader(\n",
        "    val_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# 辞書型変数へまとめる\n",
        "dataloaders_dict = {\"train\": train_dataloader, \"val\": val_dataloader}\n",
        "\n",
        "# 動作確認\n",
        "batch_iterator = iter(dataloaders_dict[\"train\"])  # イテレータに変換\n",
        "inputs, labels = next(batch_iterator)  # 1番目の要素を取り出す\n",
        "print(inputs.size())\n",
        "print(labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24eoSq4_r-vG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 事前学習済のモデル構成を表示\n",
        "net"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "svVDlv05sMf-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 直上出力の最後 `Linear(in_features=1280, out_features=1000, bias=True)` に注目\n",
        "# モデルの最終直下層の出力ユニット数を TLPA に合わせて 180 にする\n",
        "net.classifier[1] = nn.Linear(in_features=1280, out_features=180)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "546I4n5-si1C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 訓練モードに設定\n",
        "net.train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_NnIfDFs8up",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 損失関数の設定\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OpMXZJAetLTJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 転移学習で学習させるパラメータを params_to_update に格納\n",
        "params_to_update = []\n",
        "\n",
        "# 学習させるパラメータ名\n",
        "update_param_names = [\"classifier.1.weight\", \"classifier.1.bias\"]\n",
        "\n",
        "# 学習させるパラメータ以外は勾配計算をなくし、変化しないように設定\n",
        "for name, param in net.named_parameters():\n",
        "    if name in update_param_names:\n",
        "        param.requires_grad = True\n",
        "        params_to_update.append(param)\n",
        "        print(name)\n",
        "    else:\n",
        "        param.requires_grad = False\n",
        "\n",
        "# params_to_update を表示\n",
        "print(params_to_update)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_JPfEgPtfH3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "update_param_names = [\"classifier.1.weight\", \"classifier.1.bias\"]\n",
        "for name, param in net.named_parameters():\n",
        "    if name in update_param_names:\n",
        "#        param.requires_grad = True\n",
        "#        params_to_update.append(param)\n",
        "        print(name)\n",
        "    else:\n",
        "#        param.requires_grad = False\n",
        "        continue\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GUBRRvCvtguf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 最適化手法の設定\n",
        "#optimizer = optim.SGD(params=params_to_update, lr=0.001, momentum=0.9)\n",
        "#help(optim.Adam)\n",
        "#optimizer = optim.SGD(params=params_to_update, lr=0.001, momentum=0.9)\n",
        "optimizer = optim.Adam(params=params_to_update) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UjIi328Duagu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 学習関数の定義\n",
        "def train_model(net, dataloaders_dict, criterion, optimizer, num_epochs):\n",
        "\n",
        "    # epochのループ\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
        "        print('-------------')\n",
        "\n",
        "        # epochごとの学習と検証のループ\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                net.train()  # モデルを訓練モード\n",
        "            else:\n",
        "                net.eval()   # モデルを検証モード\n",
        "\n",
        "            epoch_loss = 0.0  # epochの損失和\n",
        "            epoch_corrects = 0  # epochの正解数\n",
        "\n",
        "            # 未学習時の検証性能を確かめるため、epoch=0の訓練は省略\n",
        "            if (epoch == 0) and (phase == 'train'):\n",
        "                continue\n",
        "\n",
        "            # データローダーからミニバッチを取り出す\n",
        "            #for inputs, labels in tqdm(dataloaders_dict[phase]):\n",
        "            # tqdm は要らん。冗長な出力になるだけ\n",
        "            for inputs, labels in dataloaders_dict[phase]:\n",
        "                # optimizerを初期化\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # 順伝搬（forward）計算\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = net(inputs)\n",
        "                    loss = criterion(outputs, labels)  # 損失を計算\n",
        "                    _, preds = torch.max(outputs, 1)  # ラベルを予測\n",
        "  \n",
        "                    # 訓練時はバックプロパゲーション\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                    # イタレーション結果の計算\n",
        "                    # lossの合計を更新\n",
        "                    epoch_loss += loss.item() * inputs.size(0)  \n",
        "                    # 正解数の合計を更新\n",
        "                    epoch_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            # epochごとのlossと正解率を表示\n",
        "            epoch_loss = epoch_loss / len(dataloaders_dict[phase].dataset)\n",
        "            epoch_acc = epoch_corrects.double(\n",
        "            ) / len(dataloaders_dict[phase].dataset)\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
        "                phase, epoch_loss, epoch_acc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7qL6zs4vNLv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 訓練実施前の動作確認として 1 エポックだけ実行\n",
        "for inputs, labels in dataloaders_dict['train']:\n",
        "    print(inputs.size(), labels)\n",
        "    output = net(inputs)\n",
        "    loss = criterion(output, labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3K7ebp4WvWVy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "# 学習・検証の実行\n",
        "num_epochs=50\n",
        "train_model(net, dataloaders_dict, criterion, optimizer, num_epochs=num_epochs)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iM1Nzul2vp89",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "saved_weight_file = '2020-0725tlpa_mnasnet_weights.pth'\n",
        "torch.save(net.state_dict(), saved_weight_file)\n",
        "load_weights = torch.load(saved_weight_file)\n",
        "net.load_state_dict(load_weights)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yavEodsCxYBe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#float_formatter = \"{:.3f}\".format\n",
        "#np.set_printoptions(formatter={'float_kind':float_formatter})\n",
        "# see https://note.nkmk.me/python-numpy-set-printoptions-float-formatter/\n",
        "np.set_printoptions(formatter={'int': '{:3d}'.format, 'float_kind':'{:.3f}'.format})\n",
        "\n",
        "def diagnose(no, display=False, n_best=5):\n",
        "    img, label = tlpa(no)\n",
        "    img = PILImage.open(img)   # [高さ][幅][色RGB]\n",
        "\n",
        "    # 元の画像の表示\n",
        "    #if display:\n",
        "    #    plt.imshow(img); plt.show()\n",
        "\n",
        "    # 画像の前処理と処理済み画像の表示\n",
        "    size = 224\n",
        "    mean = (0.485, 0.456, 0.406)\n",
        "    std = (0.229, 0.224, 0.225)\n",
        "\n",
        "    transform = ImageTransform(size, mean, std)\n",
        "    img_transformed = transform(img, phase=\"val\")  # torch.Size([3, 224, 224])\n",
        "\n",
        "    # (色、高さ、幅)を (高さ、幅、色)に変換し、0-1に値を制限して表示\n",
        "    if display:\n",
        "        img_transformed_ = img_transformed.numpy().transpose((1, 2, 0))\n",
        "        img_transformed_ = np.clip(img_transformed_, 0, 1)\n",
        "        plt.imshow(img_transformed_);plt.show()\n",
        "\n",
        "    # 認識の実施\n",
        "    inputs = transform(img, phase='val')\n",
        "    inputs_ = inputs.unsqueeze_(0)\n",
        "    out = net(inputs_)\n",
        "    outnp = out.detach().numpy()\n",
        "    ids = np.argsort( - outnp[0])\n",
        "    sftmx = softmax(-outnp[0])\n",
        "    #print(sftmx[ids[0]], sftmx[ids[1]], sftmx[ids[2]])\n",
        "    #print(np.sort(sftmx)[:5])\n",
        "\n",
        "    if no == ids[0]:\n",
        "        print('Hit ', end=\"\")\n",
        "    else:\n",
        "        print(colored('Miss', 'red'), end=\"\")\n",
        "\n",
        "    print(ids[:n_best], end=\" \")\n",
        "    for no in ids[:n_best]:\n",
        "        print(tlpa.data[no]['Name'], end=\" \")\n",
        "    print(- np.sort(-sftmx)[:n_best])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TI0mXdQOyocX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(tlpa.__len__()):\n",
        "#for i in [1,3, 8, 9, 10, 11, 15 ]:\n",
        "    diagnose(i, display=False, n_best=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eufqS24hytHL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}