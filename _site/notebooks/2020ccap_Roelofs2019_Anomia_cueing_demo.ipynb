{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "colab": {
      "name": "2020ccap_Roelofs2019_Anomia_cueing_demo.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/project-ccap/project-ccap.github.io/blob/master/notebooks/2020ccap_Roelofs2019_Anomia_cueing_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84bOkSoh91Xb"
      },
      "source": [
        "### 2020 CCAP (Computational Clinical Aphasia Project) demo program for anomia cuing\n",
        "\n",
        "* author: shin asakawa <asakawa@ieee.org>\n",
        "* filename: 2020ccap_Roelofs2019_Anomia_cueing_demo.ipynb\n",
        "* date: 2020-1204\n",
        "* updated: 2020-1207\n",
        "* This file will be uploaded as <https://github.com/project-ccap/project-ccap.github.io/blob/master/notebooks/2020ccap_Roelofs2019_Anomia_cueing_demo.ipynb>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3HtCHAoQ91Xc"
      },
      "source": [
        "#  Simulation of Word-Form Encoding in Speaking\n",
        "- paper tile: Phonological cueing of word finding in aphasia: insights from simulations of immediate and treatment effects\n",
        "- source code name: 'Anomia Cuing.c' from the archive of the Open Science Framework (<https://osf.io/ue4bn/>).\n",
        "- Journal: Aphasiology\n",
        "- author: Ardi Roelofs\n",
        "- date: September 2019       \n",
        "- DOI: https://doi.org/10.1080/02687038.2019.1686748\n",
        "\n",
        "---\n",
        "\n",
        "* **背景**: 言葉の発見が困難な場合は、すべての話者に見られることがあり、すべての失語症のタイプに共通して見られる。これらの問題を理解し、治療によって改善することは、基礎科学的にも臨床的にも重要である。音韻的手がかりは行動や神経測定において即効性と治療効果をもたらす。失語症における手がかり効果の場所と、その効果が健常話者の絵の命名における音韻的効果と同じ神経認知メカニズムから生じるかどうかについては意見が分かれている。\n",
        "* **研究の目的**: 本研究では、失語症患者の行動・神経測定における単語発見に対する即時効果と治療効果の理解を深め、健康と疾患における音韻効果の統一的な説明が可能かどうかを検討するために、コンピュータシミュレーションを実施した。\n",
        "* **方法と手順**: 聴覚的には，脳卒中後失語症の場合には，音韻の即時効果を考慮したWEAVERコンピュータモデルの画像命名課題を評価した。このモデルでは (1) 手がかり効果の音韻論的符号化位置、(2) 手がかり知覚におけるコホート機構、(3) 手がかりによる語彙・語彙下音韻レベルの活性化を想定した。\n",
        "* **成果と結果**: モデルは、実験での絵画呼称成績と神経測定において観察された効果をシミュレートすることに成功した。\n",
        "* **結論**: このシミュレーションは、失語症における音韻的手がかりの即時効果および治療効果が、健常話者における即時音韻的効果と同じ神経認知メカニズムに由来するという考えの概念実証を提供する。これにより、言葉の発見、関連する困難、治療による改善についての理解を深めることができる。\n",
        "\n",
        "Activation spread through the network according to a linear function with spreading rate $r$ and a decay factor $d$: \n",
        "$$\n",
        "a(m, t + \\Delta t) = a(m, t)(1 – d) + \\sum_n r\\, a(n, t).\n",
        "$$\n",
        "\n",
        "だが以下のコードを読んで実際にやっていることを書き下すと次のような漸化式\n",
        "$$\n",
        "a_{t+1} = (1-d) a_{t} + \\sum_i w x_i.\n",
        "$$\n",
        "\n",
        "ここで $a$ は任意のユニットの活性値，$d$ は崩壊係数 ($0\\le d\\le1$), $x_i$ は $i$ 番目の外部入力，$w$ は結合係数，オリジナルでは 結合係数はすべて同一である。\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kyxPz0q691Xc"
      },
      "source": [
        "# 0. 関連研究 related works\n",
        "\n",
        "* title: Less is more: neural mechanisms underlying anomia treatment in chronic aphasic patients\n",
        "* authro: Davide Nardo, Rachel Holland,  Alexander P. Leff, Cathy J. Price4 and Jennifer T. Crinion\n",
        "* jornal: BRAIN\n",
        "* year: 2017\n",
        "* Page: 1-16\n",
        "* DOI: doi:10.1093/brain/awx234\n",
        "* abstract:\n",
        "Previous research with aphasic patients has shown that picture naming can be facilitated by concurrent phonemic cueing [e.g. initial phoneme(s) of the word that the patient is trying to retrieve], both as an immediate word retrieval technique, and when practiced repeatedly over time as a long-term anomia treatment. \n",
        "Here, to investigate the neural mechanisms supporting word retrieval, we adopted—for the first time—a functional magnetic resonance imaging task using the same naming procedure as it occurs during the anomia treatment process. \n",
        "Before and directly after a 6-week anomia treatment programme, 18 chronic aphasic stroke patients completed our functional magnetic resonance imaging protocol—a picture naming task aided by three different types of phonemic cues (whole words, initial phonemes, final phonemes) and a noise-control condition. \n",
        "Patients completed a naming task based on the training materials, and a more general comprehensive battery of language tests both before and after the anomia treatment, to determine the effectiveness and specificity of the therapy. \n",
        "Our results demonstrate that the anomia treatment was effective and specific to speech production, significantly improving both patients’ naming accuracy and reaction time immediately post-treatment (unstandardized effect size: 29% and 17%, respectively; Cohen’s d: 3.45 and 1.83). \n",
        "Longer term gains in naming were maintained 3 months later. Functional imaging results showed that both immediate and long-term facilitation of naming involved a largely overlapping bilateral frontal network including the right anterior insula, inferior frontal and dorsal anterior cingulate cortices, and the left premotor cortex. \n",
        "These areas were associated with a neural priming effect (i.e. reduced blood oxygen level-dependent signal) during both immediate (phonemically-cued versus control-cue conditions), and long-term facilitation of naming (i.e. treated versus untreated items). \n",
        "Of note is that different brain regions were sensitive to different phonemic cue types. Processing of whole word cues was associated with increased activity in the right angular gyrus; whereas partial word cues (initial and final phonemes) recruited the left supplementary motor area, and right anterior insula, inferior frontal cortex, and basal ganglia. The recruitment of multiple and bilateral areas may help explain why phonemic cueing is such a successful behavioural facilitation tool for anomia treatment. Our results have important implications for optimizing current anomia treatment approaches, developing new treatments, and improving speech outcome for aphasic patients.\n",
        "\n",
        "これまでの失語症患者を対象とした研究では、絵画呼称課題成績は 同時に音韻手がかりを与えることで向上する。長期的な失語治療として繰り返し練習することで促進されることが示されている。\n",
        "ここでは、単語検索を支える神経機構を調べるために、治療時と同じ命名法を用いた機能的磁気共鳴イメージング課題を初めて採用した。18 名の慢性失語性脳卒中患者を対象に、6 週間の失語治療プログラムの前後に、機能的磁気共鳴画像法を用いて 3 種類の音素手がかり（単語全体、初期音素、最終音素）を用いた絵画命名課題とノイズコントロール条件を設定した。患者は 訓練教材に基づいた命名課題と 治療の前後に行われたより一般的な言語検査を完了し、治療の有効性と特異性を決定した。結果は 治療が効果的で音声生産に特異的であり、治療直後に患者の命名精度と反応時間の両方を有意に改善したことを示した（標準化無しの効果量で，各々  29％ と17％、Cohen's d：3.45と1.83）。命名の長期的な向上は 3ヵ月後も維持された。機能イメージングの結果は、命名の即時および長期的な円滑化の両方は、右前島皮質、下前頭前野と背側前帯状皮質、および左前頭前皮質を含む主に重複する両側の前頭前野ネットワークが関与していることを示した。これらの領域は、即時（音素的に手がかりを得た場合と対照的に手がかりを得た場合の両方）および長期的な成績の促進（すなわち、治療した場合と治療していない場合の両方）において、神経プライミング効果（すなわち、血中酸素濃度依存性信号の減少）と関連していた。また、音素手がかりの種類によって脳の領域が異なることにも注意が必要である。単語全体の処理は右角回の活動の増加と関連していたが、部分的な単語の手がかり（最初と最後の音素）は左補運動野、右前島皮質、下前頭前皮質、大脳基底核の活動を促進した。複数の領域と両側の領域から、なぜ音素性手がかりが治療のための行動促進材料として成功しているのかを説明するのに役立つかもしれない。我々の結果は、現在の失語症治療アプローチの最適化、新しい治療法の開発、失語症患者の言語転帰の改善に重要な意味を持っている。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sr6NPE-D91Xc"
      },
      "source": [
        "# 1. 準備 Preparations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tljRLGx91Xc"
      },
      "source": [
        "import numpy as np\n",
        "import sys\n",
        "import IPython\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gh1WlMup91Xc"
      },
      "source": [
        "<center>\n",
        "<img src=\"https://raw.githubusercontent.com/project-ccap/project-ccap.github.io/master/figures/2019Roelofs_Aphasiology_fig1.png\" style=\"width:49%\"><br/>\n",
        "<div align=\"left\" style=\"width:49%\">\n",
        "Roelofs (2019) Phonological cueing of word finding in aphasia: insights from simulations of immediate and treatment effects, APHASIOLOGY\n",
        "https://doi.org/10.1080/02687038.2019.1686748, Fig. 1<br/>\n",
        "</div>\n",
        "</center>\n",
        "\n",
        "<center>\n",
        "<img src=\"https://raw.githubusercontent.com/project-ccap/project-ccap.github.io/master/figures/2019Roelofs_Aphasiology_fig2.png\" style=\"width:49%\"><br/>\n",
        "<div align=\"left\" style=\"width:49%\">\n",
        "Roelofs (2019) Phonological cueing of word finding in aphasia: insights from simulations of immediate and treatment effects, APHASIOLOGY\n",
        "https://doi.org/10.1080/02687038.2019.1686748, Fig. 2<br/>\n",
        " </div>\n",
        "</center>\n",
        "\n",
        "<center>\n",
        "<img src=\"https://raw.githubusercontent.com/project-ccap/project-ccap.github.io/master/figures/2019Roelofs_Aphasiology_fig3.png\" style=\"width:49%\"><br/>\n",
        "<div align=\"left\" style=\"width:94%\">\n",
        "<font size=\"+2\" color=\"teal\">\n",
        "右上の図での数値は，<br/>\n",
        "Whole,Untreated:295, Whole,Treated: 268, \n",
        "Initial,Untreated:295, Intial,Treated:268,\n",
        "Final,Untreated:297, Final,Treated:268,\n",
        "Noise,Untreated:316, Noise,Treated,291<br/>\n",
        "このプログラムでは，右上図の結果をシミュレートすることを意図しています。\n",
        "</font><br/>\n",
        "From Roelofs (2019) Phonological cueing of word finding in aphasia: insights from simulations of immediate and treatment effects, APHASIOLOGY\n",
        "https://doi.org/10.1080/02687038.2019.1686748, Fig. 3<br/>\n",
        " </div>\n",
        "</center>\n",
        "\n",
        "\n",
        "次に，コホートサイズを変化させた場合のシュミュレーション結果:\n",
        "<center>\n",
        "<img src=\"https://raw.githubusercontent.com/project-ccap/project-ccap.github.io/master/figures/2019Roelofs_Aphasiology_fig4.png\" style=\"width:49%\"><br/>\n",
        "<div align=\"center\" style=\"width:49%\">\n",
        "Roelofs (2019) Phonological cueing of word finding in aphasia: insights from simulations of immediate and treatment effects, APHASIOLOGY\n",
        "https://doi.org/10.1080/02687038.2019.1686748, Fig. 4<br/>\n",
        " </div>\n",
        "</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BrqfYISN91Xc"
      },
      "source": [
        "----\n",
        "\n",
        "次に，元になった，実データを原著論文が引用している論文から：実験の設定と条件\n",
        "\n",
        "<center>\n",
        "<img src=\"https://raw.githubusercontent.com/project-ccap/project-ccap.github.io/master/figures/2017Nardo_fig2.png\" style=\"width:48%\"><br/>\n",
        "<div align=\"left\" style=\"width:49%\">\n",
        "実験設定: Nardo et al. (2017) Less is more: Neural mechanisms underlying anomia treatment in chronic aphasic patients, Brain, 1-16, Fig. 2 <br/>\n",
        "</div>\n",
        "</center>\n",
        "<br/><br/><br/><br/>\n",
        "\n",
        "\n",
        "結果: 図 A: 治療前(T1), 治療後(T2), 6ヶ月ののフォローアップ(T3) の正解率， 図　B は反応時間<br/>\n",
        "図 C: 手がかり条件ごとの正解率，全体キュー(W), 語頭キュー(I), 語尾キュー(F), ノイズ(N=コントロール)<br/>\n",
        "図 D: 手がかり条件ごとの反応時間\n",
        "<center>\n",
        "<img src=\"https://raw.githubusercontent.com/project-ccap/project-ccap.github.io/master/figures/2017Nardo_fig3.png\" style=\"width:49%\"><br/>\n",
        "<div align=\"left\" style=\"width:49%\">\n",
        "結果, Nardo et al. (2017) Less is more: Neural mechanisms underlying anomia treatment in chronic aphasic patients, Brain, 1-16, Fig. 3 <br/>\n",
        "</div>\n",
        "</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Df93uYk991Xc"
      },
      "source": [
        "# 2. 大域変数の設定 Settings for global variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PMD5J9fl91Xc"
      },
      "source": [
        "Y = 1.0   # /* forward connection present */\n",
        "N = 0.0   # /* forward connection absent */\n",
        "\n",
        "#  Simulation of Nardo, Holland, Leff, Price, & Crinion (2017, Brain) \n",
        "# /* names of cueing conditions */\n",
        "N_CCONDs= 4 #  Number of cue conditions: WHOLE, INITIAL, FINAL, NOISE \n",
        "names_of_cueing_conds = ['WHOLE', 'INITIAL', 'FINAL', 'NOISE']  # 手がかり \n",
        "cue_ = {x:i for i, x in enumerate(names_of_cueing_conds)}\n",
        "N_CCONDS = len(names_of_cueing_conds)\n",
        "\n",
        "#/* names of tests */\n",
        "N_TESTs = 2    #  Number of tests: BEFORE, AFTER treatment\n",
        "names_of_test = ['BEFORE', 'AFTER']\n",
        "test_ = {x:i for i, x in enumerate(names_of_test)}\n",
        "\n",
        "N_MORPHEMEs = 5  # 形態素数\n",
        "#/* names of morphemes */\n",
        "names_of_morphemes = ['mCAT', 'mDOG', 'mMAT', 'mFISH']\n",
        "morphemes_ = {x:i for i, x in enumerate(names_of_morphemes)}\n",
        "\n",
        "#/* names of phonemes */\n",
        "N_PHONEMEs = 10  # 音素数\n",
        "names_of_phonemes = ['pK', 'pE', 'pT', 'pD', 'pO', 'pG', 'pM', 'pF', 'pI', 'pS']\n",
        "phonemes_ = {x:i for i, x in enumerate(names_of_phonemes)}\n",
        "\n",
        "#/* names of syllable programs */\n",
        "N_SYLLABLE_PROGRAMs = 5  #  cat, dog, mat, fog, fish の 5 つ\n",
        "names_of_syllable_programs = ['sCAT', 'sDOG', 'sMAT', 'sFOG', 'sFISH']\n",
        "syllable_ = {x:i for i, x in enumerate(names_of_syllable_programs)}"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wO9vA4I291Xc"
      },
      "source": [
        "#/* connections between morpheme nodes and phoneme nodes */\n",
        "# 10 ユニットのうち ３ つだけ オン で ７ つは オフ。\n",
        "#global MP_con\n",
        "MP_con = np.array([\n",
        "    [Y, Y, Y, N, N, N, N, N, N, N], # <cat>\n",
        "    [N, N, N, Y, Y, Y, N, N, N, N], # <dog>\n",
        "    [N, Y, Y, N, N, N, Y, N, N, N], # <mat>\n",
        "    [N, N, N, N, Y, Y, N, Y, N, N], # <fog>\n",
        "    [N, N, N, N, N, N, N, Y, Y, Y]]  # <fish>\n",
        ")\n",
        "\n",
        "#/* connections between phoneme nodes and syllable program nodes */\n",
        "#global PS_con\n",
        "PS_con =  np.array([\n",
        "[Y,  N,  N,  N,  N], # /* K */\n",
        "[Y,  N,  Y,  N,  N], # /* E */  オランダ語では，猫のことを \"ケット\"と発音するのかしらね?\n",
        "[Y,  N,  Y,  N,  N], # /* T */\n",
        "[N,  Y,  N,  N,  N], # /* D */\n",
        "[N,  Y,  N,  Y,  N], # /* O */\n",
        "[N,  Y,  N,  Y,  N], # /* G */\n",
        "[N,  N,  Y,  N,  N], # /* M */\n",
        "[N,  N,  N,  Y,  Y], # /* F */\n",
        "[N,  N,  N,  N,  Y], # /* I */\n",
        "[N,  N,  N,  N,  Y]]  #\t/* S */\n",
        ")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mp3aaKiB91Xc"
      },
      "source": [
        "# 3. メイン関数の定義 Main()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pvdgNRSa91Xc"
      },
      "source": [
        "def main(params=None):\n",
        "    \"\"\"\n",
        "    * author: shin asakawa <asakawa@ieee.org>\n",
        "    * filename: 2020ccap_Roelofs2019_Anomia_cueing_demo.ipynb\n",
        "    * date: 2020-1204\n",
        "    * origina paper: Phonological cueing of word finding in aphasia: insights \n",
        "                    from simulations of immediate and treatment effects\n",
        "    * source code name: 'Anomia Cuing.c' <https://osf.io/ue4bn/>.\n",
        "    * Journal: Aphasiology\n",
        "    * author: Ardi Roelofs\n",
        "    * date: September 2019       \n",
        "    * DOI: https://doi.org/10.1080/02687038.2019.1686748\n",
        "    \"\"\" \n",
        "    if params == None:\n",
        "        # シミュレーションの挙動を決める大域パラメータの設定\n",
        "        # 各パラメータの意味は，実際のシミュレーションの後にあります\n",
        "        STEP_SIZE = 25\n",
        "        VER_TIME = 25\n",
        "        N_STEPs = int((1000 + STEP_SIZE) / STEP_SIZE)\n",
        "\n",
        "        hyper_params = {\n",
        "\n",
        "            'STEP_SIZE' : STEP_SIZE,           # duration time step in ms \n",
        "            'N_STEPs' : N_STEPs,               # Number of time steps\n",
        "            'LEX_rate': 0.0120 * STEP_SIZE,    # prop per step_size (ms)\n",
        "            'DECAY_rate': 0.0240 * STEP_SIZE,  #  prop per step_size (ms)\n",
        "            'EXTIN': 0.1965 * STEP_SIZE,       # act_units per step_size (ms),\n",
        "            'PHONEME_DURATION': 125,           # (ms)  125ms なので 1秒間に8ステップを仮定\n",
        "            'CORRECTION_MENTAL_SOA':100,       # (ms)\n",
        "            'VER_TIME': 25,                    # verification time, in ms \n",
        "            'FR': 0.10,                        # default 0.10; at 0.05 for Large cohort size    \n",
        "            # Pellet Cheneval, Glize, & Laganaro (2018, Aphasiology)  この論文は未入手 2020-1204 上間先生より\n",
        "            # The lexical or sub-lexical locus of facilitation by phonemic cueing in aphasic speakers: \n",
        "            # the effect of onset cohort size, 1468-1489.\n",
        "        \n",
        "            'THRESHOLD': 1.5, \n",
        "            'ANOMIA_REDUCTION': 0.5,           # default 0.5; for BOLD, range 0.6, 0.5, 0.43, 0.4, 0.38\n",
        "            'MORPH_DONE': False,\n",
        "            'SUPRA_DONE': False,\n",
        "            'SEG1_DONE': False, \n",
        "            'SEG2_DONE': False, \n",
        "            'SEG3_DONE': False,\n",
        "            'SYLL_DONE': False,  \n",
        "            'SYLLABIFIED': False,\n",
        "            'syllable_program_verification_time': VER_TIME,\n",
        "            'morph_verification_time': VER_TIME,\n",
        "            'seg1_verification_time': VER_TIME,\n",
        "            'seg2_verification_time': VER_TIME,\n",
        "            'seg3_verification_time': VER_TIME,\n",
        "            # 'cat' の 音韻として Onse, Vowel, Coda の 3つなので seg1, seg2, seg3 と 3 つあるのだろう\n",
        "            'syllabification_time': 2 * VER_TIME,\n",
        "            'syllabification_time': VER_TIME, \n",
        "            'syllable_program_verification_time': VER_TIME,\n",
        "        }\n",
        "    else:\n",
        "        hyper_params = params\n",
        "\n",
        "    # connections between morpheme nodes and phoneme nodes\n",
        "    # 10 ユニットのうち ３ つだけ オン で ７ つは オフ。\n",
        "    # 形態素層と音韻層との間の結合係数\n",
        "    MP_con = np.array([\n",
        "        [Y, Y, Y, N, N, N, N, N, N, N], # <cat>\n",
        "        [N, N, N, Y, Y, Y, N, N, N, N], # <dog>\n",
        "        [N, Y, Y, N, N, N, Y, N, N, N], # <mat>\n",
        "        [N, N, N, N, Y, Y, N, Y, N, N], # <fog>\n",
        "        [N, N, N, N, N, N, N, Y, Y, Y]] # <fish>\n",
        "    )\n",
        "\n",
        "    # connections between phoneme nodes and syllable program nodes\n",
        "    # 音韻層から音素層との間の結合係数\n",
        "    PS_con =  np.array([\n",
        "        [Y,  N,  N,  N,  N], # /* K */\n",
        "        [Y,  N,  Y,  N,  N], # /* E */  オランダ語では，猫のことを \"ケット\"と発音するのかしらね?\n",
        "        [Y,  N,  Y,  N,  N], # /* T */\n",
        "        [N,  Y,  N,  N,  N], # /* D */\n",
        "        [N,  Y,  N,  Y,  N], # /* O */\n",
        "        [N,  Y,  N,  Y,  N], # /* G */\n",
        "        [N,  N,  Y,  N,  N], # /* M */\n",
        "        [N,  N,  N,  Y,  Y], # /* F */\n",
        "        [N,  N,  N,  N,  Y], # /* I */\n",
        "        [N,  N,  N,  N,  Y]] # /* S */\n",
        "    )\n",
        "\n",
        "    M_node_act = np.zeros([N_MORPHEMEs,], dtype=np.float)         # 形態素層の活性値\n",
        "    P_node_act = np.zeros([N_PHONEMEs,], dtype=np.float)          # 音韻層の活性値\n",
        "    S_node_act = np.zeros([N_SYLLABLE_PROGRAMs], dtype=np.float)  # 音節層の活性値\n",
        "\n",
        "    # input buffer \n",
        "    input_M = np.zeros([N_MORPHEMEs,])                            # 形態素層の入力バッファ\n",
        "    input_P = np.zeros([N_PHONEMEs,])                             # 音韻層の入力バッファ\n",
        "    input_S = np.zeros([N_SYLLABLE_PROGRAMs,])                    # 音素層の入力バッファ\n",
        "    \n",
        "    N_STEPs = hyper_params['N_STEPs']\n",
        "    h = np.zeros([N_STEPs,])  # hazard\n",
        "    S = np.zeros([N_STEPs,])  # survival\n",
        "    f = np.zeros([N_STEPs,])  # ?\n",
        "    #  F = np.zeros([N_STEPs,])  # ? この変数は使っていない？\n",
        "\n",
        "    #global T, test, ccond\n",
        "    #int T;     /* time in ms */\n",
        "    #int test;        /* tests before vs. after treatment */\n",
        "    #int ccond;       /* cue condition: whole, initial, final, noise */\n",
        "    \n",
        "    # SIM_MEANS に書く条件ごとのシミュレーション結果の平均値が入る\n",
        "    SIM_MEANS = np.zeros([N_TESTs, N_CCONDs], dtype=np.float)\n",
        "    \n",
        "    for test in names_of_test:  \n",
        "        # BEFORE, then AFTER, 処置（訓練?）前と後での比較\n",
        "        \n",
        "        MP_con, PS_con = set_spreading_rates(test, MP_con, PS_con, hyper_params)\n",
        "        for ccond in names_of_cueing_conds:    \n",
        "            # キュー(音韻手がかり) 4 種類: 全体, 語頭，語尾，雑音をこの順番で実行する\n",
        "            # ccond: キュー（音韻手がかり)条件を表す変数: whole, initial, finish, noise \n",
        "            mean = compute_prob_functions(test, ccond,  f, h, S, #F, \n",
        "                                          M_node_act, P_node_act, S_node_act, \n",
        "                                          input_M, input_P, input_S,\n",
        "                                          MP_con, PS_con, hyper_params)\n",
        "            SIM_MEANS[test_[test], cue_[ccond]] = mean\n",
        "        MP_con, PS_con = reset_spreading_rates(test, MP_con, PS_con, hyper_params)\n",
        "\n",
        "    # 結果の印字\n",
        "    # 著作権，クレジットの表示\n",
        "    print(\"Simulation of Immediate and Treatment Effects of Phonological Cueing in Anomia (c) Ardi Roelofs\")\n",
        "    print_expectations_of_RT(SIM_MEANS, hyper_params) # シミュレーション結果表示    "
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FIJZgWZz91Xc"
      },
      "source": [
        "# 4. サブルーチン Subroutines"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3vXlZ3y91Xc"
      },
      "source": [
        "def compute_prob_functions(test, ccond, f, h, S, #F, \n",
        "                           M_node_act, P_node_act, S_node_act, \n",
        "                           input_M, input_P, input_S, \n",
        "                           MP_con, PS_con,\n",
        "                           params): \n",
        "    # この 'compute_prob_funcitions' 関数がシミュレーションの本体\n",
        "    # test:= {before, after} 処置の前後\n",
        "    # ccond:= {whole, initial, finish, noise} 手がかり条件\n",
        "    # params: 他の計算に必要なパラメータ集合の辞書\n",
        "    \n",
        "    M_node_act.fill(0.0); P_node_act.fill(0.0); S_node_act.fill(0.0)\n",
        "    params = reset_network(params)\n",
        "\n",
        "    #reset_f_h_S_()\n",
        "    h.fill(0.0); S.fill(0.0), f.fill(0.0) #, F.fill(0.0)\n",
        "  \n",
        "    STEP_SIZE = params['STEP_SIZE']\n",
        "    for T in range(0, 1000, STEP_SIZE):\n",
        "        h, params = compute_hazard_rate(T, h, M_node_act, P_node_act, S_node_act, params)\n",
        "        input_M, input_P, input_S, M_node_act, P_node_act, S_node_act =  update_network(T, ccond, \n",
        "                                                                                        input_M, input_P, input_S, \n",
        "                                                                                        M_node_act, P_node_act, S_node_act, \n",
        "                                                                                        MP_con, PS_con,\n",
        "                                                                                        params)\n",
        "    S = compute_cumul_survival_function(S, h, params)\n",
        "    f = compute_density_function(f, h, S, params)\n",
        "    mean = compute_expectation_of_RT_(f, params)\n",
        "    return mean\n",
        "\n",
        "\n",
        "# Notice: hazard rates are computed before updating the network, that\n",
        "# is, on the basis of the activation state of the network achieved at\n",
        "# the previous time step */\n",
        "\n",
        "#def reset_system(SIM_MEANS):\n",
        "#    SIM_MEANS.fill(0)\n",
        "\n",
        "def set_spreading_rates(test, MP_con, PS_con, params):\n",
        "    \n",
        "    ANOMIA_REDUCTION = params['ANOMIA_REDUCTION']\n",
        "    LEX_rate = params['LEX_rate']\n",
        "    MP_con *= LEX_rate\n",
        "    PS_con *= LEX_rate\n",
        "\n",
        "    if test == 'BEFORE':  # /* untreated */\n",
        "        #/* impairment in phonological encoding */\n",
        "        MP_con[morphemes_['mCAT'], phonemes_['pK']] *= ANOMIA_REDUCTION\n",
        "        MP_con[morphemes_['mCAT'], phonemes_['pE']] *= ANOMIA_REDUCTION\n",
        "        MP_con[morphemes_['mCAT'], phonemes_['pT']] *= ANOMIA_REDUCTION\n",
        "    return MP_con, PS_con\n",
        "\n",
        "\n",
        "def reset_spreading_rates(test, MP_con, PS_con, params):\n",
        "    LEX_rate  = params['LEX_rate']\n",
        "    \n",
        "    MP_con *= 1.0/LEX_rate\n",
        "    PS_con *= 1.0/LEX_rate\n",
        "    \n",
        "    if test == 'BEFORE':  # { /* untreated */\n",
        "        MP_con[morphemes_['mCAT']][phonemes_['pK']] = 1.0;\n",
        "        MP_con[morphemes_['mCAT']][phonemes_['pE']] = 1.0;\n",
        "        MP_con[morphemes_['mCAT']][phonemes_['pT']] = 1.0;\n",
        "        \n",
        "    return MP_con, PS_con\n",
        "\n",
        "\n",
        "def reset_network(params):\n",
        "    VER_TIME = params['VER_TIME']\n",
        "    params['MORPH_DONE'] = False\n",
        "    params['SYLL_DONE'] = False\n",
        "    params['SYLLABIFIED'] = False\n",
        "    params['SYLL_DONE'] = False\n",
        "    params['SYLLABIFIED'] = False\n",
        "    params['SEG1_DONE'] = False\n",
        "    params['SEG2_DONE'] = False\n",
        "    params['SEG3_DONE'] = False\n",
        "\n",
        "    params['morph_verification_time'] = VER_TIME\n",
        "    params['seg1_verification_time'] = VER_TIME\n",
        "    params['seg2_verification_time'] = VER_TIME\n",
        "    params['seg3_verification_time'] = VER_TIME\n",
        "    params['syllabification_time']  = 2 * VER_TIME\n",
        "    params['syllable_program_verification_time']  = VER_TIME\n",
        "    \n",
        "    return params\n",
        "    \n",
        "\n",
        "def compute_cumul_survival_function(S, h, params):\n",
        "    # NOTE: cum_survival or S[s] is upto and including s\n",
        "    \n",
        "    for s in range(params['N_STEPs']):\n",
        "        aux = 1.0\n",
        "        for j in range(s+1):\n",
        "            aux *=  (1.0 - h[j])\n",
        "        S[s] = aux;\n",
        "    return S\n",
        "\n",
        "\n",
        "def compute_density_function(f, h, S, params):\n",
        "    # S: 前時刻までに選択されなかった確率，すなわち残存，生き残っている確率\n",
        "    # NOTE: Prob(not selected before step s) equals S[s-1], that is\n",
        "    # surviving upto and including the previous time step \n",
        "\n",
        "    for s in range(params['N_STEPs']-1):\n",
        "        tau = s + 1\n",
        "        #f[s] = h[s] * S[s-1]\n",
        "        f[tau] = h[tau] * S[s]\n",
        "    # f[0]  は常に 0 なので計算不要\n",
        "    # NOTE: f[0] will always be 0, so is not computed\n",
        "    return f\n",
        "\n",
        "\n",
        "def compute_expectation_of_RT_(f, params):\n",
        "    N_STEPs = params['N_STEPs']\n",
        "    STEP_SIZE = params['STEP_SIZE']\n",
        "    \n",
        "    mean = 0.0\n",
        "    for s in range(N_STEPs):\n",
        "        mean += f[s] * s * STEP_SIZE\n",
        "    return mean;\n",
        "\n",
        "\n",
        "#def reset_f_h_S_(f, h, S, F):\n",
        "#    #global f, h, S, F\n",
        "#    for s in range(N_STEPs):\n",
        "#        f[s], h[s], S[s], F[s] = 0.0, 0.0, 0.0, 0.0"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AHQTi95P91Xc"
      },
      "source": [
        "## 4.1. ネットワーク更新ルーチン Network updating routines"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0yNJ8Zyd91Xc"
      },
      "source": [
        "#/*****************************\n",
        "# * NETWORK UPDATING ROUTINES *\n",
        "# *****************************/\n",
        "def update_network(T, ccond, input_M, input_P, input_S, \n",
        "                   M_node_act, P_node_act, S_node_act, \n",
        "                   MP_con, PS_con, params):\n",
        "    \"\"\"\n",
        "    ネットワークの活性値を更新する関数\n",
        "    入力: \n",
        "         input_M: morphological layer 形態素層への入力値\n",
        "         input_P: phonological layer  音韻層への入力値\n",
        "         input_S: syllable layer 音素層への入力値\n",
        "         M_node_act: 形態素層の活性値\n",
        "         P_node_act: 音韻層の活性値\n",
        "         S_node_act: 音素層の活性値，この値が発声と一対一対応している\n",
        "         MP_con: 形態素層と音韻層との結合係数\n",
        "         PS_con: 音韻層と音素層との結合係数\n",
        "    \"\"\"\n",
        "        \n",
        "    #set_input_to_zero()\n",
        "    input_M.fill(0.0);  input_P.fill(0.0);  input_S.fill(0.0)  # まずは入力値をゼロクリア\n",
        "\n",
        "    # 上でゼロクリアした各層に入力値をセット\n",
        "    input_M, input_P = get_external_input(ccond, T, input_M, input_P, params)\n",
        "\n",
        "    # 各層の値を更新\n",
        "    P, S = get_internal_input(M_node_act, P_node_act, MP_con, PS_con, params)\n",
        "    input_P = np.add(input_P, P)\n",
        "    input_S = np.add(input_S, S)\n",
        "    M_node_act, P_node_act, S_node_act = update_activation_of_nodes(M_node_act, P_node_act, S_node_act, \n",
        "                                                                    input_M, input_P, input_S, params)\n",
        "    return input_M, input_P, input_S, M_node_act, P_node_act, S_node_act\n",
        "\n",
        "\n",
        "#def set_input_to_zero():\n",
        "#    input_M.fill(0.0);  input_P.fill(0.0);  input_S.fill(0.0)\n",
        "\n",
        "\n",
        "def get_external_input(ccond, T, input_M, input_P, params):\n",
        "\n",
        "    CORRECTION_MENTAL_SOA = params['CORRECTION_MENTAL_SOA']\n",
        "    EXTIN = params['EXTIN']\n",
        "    PHONEME_DURATION = params['PHONEME_DURATION']\n",
        "    FR = params['FR']\n",
        "    \n",
        "    #/* target input */\n",
        "    if T >= CORRECTION_MENTAL_SOA:\n",
        "        # target gets input from lemma\n",
        "        # at 0.8 for Meteyard & Bose (2018, JSLHR) \n",
        "        # What does a cue do? Comparing phonological and semantic cues for picture naming in aphasia,\n",
        "        # Journal of Speech, Language, and Hearing Research, 61(3). pp. 658-674.\n",
        "        input_M[morphemes_['mCAT']] += 1.0 * EXTIN \n",
        "\n",
        "    #/* input from cue */\n",
        "    if ccond == 'WHOLE': \n",
        "        # Phoneme duration の 3 倍の期間, /K/, /E/, /T/ と順に入力される。\n",
        "        # 形態素層からはこの期間中，同じ入力が与えられる\n",
        "        if (0 <= T) and (T < PHONEME_DURATION):\n",
        "            input_P[phonemes_['pK']] += EXTIN\n",
        "            input_M[morphemes_['mCAT']] += FR * EXTIN\n",
        "\n",
        "        if (PHONEME_DURATION <= T) and (T < (2 * PHONEME_DURATION)):\n",
        "            input_P[phonemes_['pE']] += EXTIN\n",
        "            input_M[morphemes_['mCAT']] += FR * EXTIN\n",
        "\n",
        "        if (2 * PHONEME_DURATION <= T) and (T < (3 * PHONEME_DURATION)):\n",
        "            input_P[phonemes_['pT']] += EXTIN;\n",
        "            input_M[morphemes_['mCAT']] += FR * EXTIN;\n",
        "\n",
        "    if ccond == 'INITIAL':\n",
        "        # Phoneme duraion の 期間に /k/ の音，次の phoneme duration の期間 /E/ の音が聞こえる条件\n",
        "        if (0 <= T) and (T < PHONEME_DURATION):\n",
        "            input_P[phonemes_['pK']] += EXTIN;\n",
        "            input_M[morphemes_['mCAT']] += FR * EXTIN;\n",
        "        if (PHONEME_DURATION <= T) and  (T < (2 * PHONEME_DURATION)):\n",
        "            input_P[phonemes_['pE']] += EXTIN\n",
        "            input_M[morphemes_['mCAT']] += FR * EXTIN\n",
        "\n",
        "    if ccond == 'FINAL':\n",
        "        # phoneme duration の期間，語尾の音素 /E/ ，続いて /T/ が聞こえる条件\n",
        "        if (0 <= T) and (T < PHONEME_DURATION):\n",
        "            input_P[phonemes_['pE']] += EXTIN\n",
        "            input_M[morphemes_['mCAT']] += FR * EXTIN\n",
        "            input_M[morphemes_['mMAT']] += FR * EXTIN;\n",
        "\n",
        "        if (PHONEME_DURATION <= T) and (T < (2 * PHONEME_DURATION)):\n",
        "            input_P[phonemes_['pT']] += EXTIN\n",
        "            input_M[morphemes_['mCAT']] += FR * EXTIN\n",
        "            input_M[morphemes_['mMAT']] += FR * EXTIN;\n",
        "\n",
        "    return input_M, input_P\n",
        "\n",
        "\n",
        "def get_internal_input(M_node_act, P_node_act, MP_con, PS_con, params):\n",
        "    P = np.matmul(M_node_act, MP_con)\n",
        "    S = np.matmul(P_node_act, PS_con)\n",
        "    return P, S\n",
        "\n",
        "\n",
        "def update_activation_of_nodes(M_node_act, P_node_act, S_node_act, \n",
        "                               input_M, input_P, input_S, params):\n",
        "    DECAY_rate = params['DECAY_rate']\n",
        "\n",
        "    for i in range(N_MORPHEMEs):\n",
        "        M_node_act[i] = M_node_act[i] * (1.0 - DECAY_rate) + input_M[i]\n",
        "       \n",
        "    for i in range(N_PHONEMEs):\n",
        "        P_node_act[i] = P_node_act[i] * (1.0 - DECAY_rate) + input_P[i]\n",
        "       \n",
        "    for i in range(N_SYLLABLE_PROGRAMs):\n",
        "        S_node_act[i] = S_node_act[i] * (1.0 - DECAY_rate) + input_S[i]                         \n",
        "        \n",
        "    return M_node_act, P_node_act, S_node_act"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CLYlmDHO91Xc"
      },
      "source": [
        "## 4.2 ハザード関数，累積生存関数他 Hazard, Cumulative, and Probability Mass functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VbYCTBda91Xc"
      },
      "source": [
        "def compute_hazard_rate(T, h, M_node_act, P_node_act, S_node_act, params):\n",
        "    \"\"\"\n",
        "    この関数によって，どの音が発声されたかをコントロールする。\n",
        "    順番に onset, vowel, coda の順に，P_node_act[] が VER_TIME 時間活性化\n",
        "    していれば，発声終了とみなす。全ての音が発生し終わったら SYLL_DONE \n",
        "    フラグを立てる。\n",
        "    SYLL_DONE フラグが立っていたら，そのときの，正解，意味性，形式性，無関連，\n",
        "    などの錯誤の種類ごとの活性値と正解との差を h[] に代入する\n",
        "    # HAZARD-, CUMUL_SURVIVAL-, PROBABILITY MASS FUNCTION\n",
        "    #    h[1] denotes hazard rate at first time step,\n",
        "    #    h[2] denotes hazard rate at second time step, etc.,\n",
        "    #    where h[s] is a function (expressed by the Luce ratio) of the\n",
        "    #    activation levels at moment T equal to (s-1) * STEP_SIZE (where s=1,2,...)\n",
        "\n",
        "    #    f[1] denotes prob of selection at first time step, etc;\n",
        "    #    that is, f[s] is the probability that the retrieval latency\n",
        "    #    equals s x STEP_SIZE;\n",
        "    #    e.g., f[2] is the probability that the retrieval latency equals\n",
        "    #    2 x STEP_SIZE, i.e., 2 x 25 ms = 50 ms.\n",
        "    \"\"\"\n",
        "    THRESHOLD = params['THRESHOLD']\n",
        "    CORRECTION_MENTAL_SOA = params['CORRECTION_MENTAL_SOA']\n",
        "    SYLLABIFIED = params['SYLLABIFIED']\n",
        "    MORPH_DONE = params['MORPH_DONE']\n",
        "    SEG1_DONE = params['SEG1_DONE']\n",
        "    SEG2_DONE = params['SEG2_DONE']\n",
        "    SEG3_DONE = params['SEG3_DONE']\n",
        "    SYLL_DONE = params['SYLL_DONE']\n",
        "    SYLLABIFIED = params['SYLLABIFIED']\n",
        "    STEP_SIZE = params['STEP_SIZE']\n",
        "    syllabification_time = params['syllabification_time']\n",
        "    syllable_program_verification_time = params['syllable_program_verification_time']\n",
        "    morph_verification_time = params['morph_verification_time']\n",
        "    seg1_verification_time = params['seg1_verification_time']\n",
        "    seg2_verification_time = params['seg2_verification_time']\n",
        "    seg3_verification_time = params['seg3_verification_time']\n",
        "\n",
        "    if T > CORRECTION_MENTAL_SOA:\n",
        "        if S_node_act[syllable_['sCAT']] > THRESHOLD and SYLLABIFIED:\n",
        "            #/* Zero THRESHOLD for excluding locus in phonetic encoding */\n",
        "            syllable_program_verification_time -= STEP_SIZE;\n",
        "            params['syllable_program_verification_time'] = syllable_program_verification_time\n",
        "\n",
        "        if syllable_program_verification_time == 0:\n",
        "            SYLL_DONE = True;  \n",
        "            params['SYLL_DONE'] = SYLL_DONE\n",
        "        if SEG1_DONE and SEG2_DONE and SEG3_DONE:\n",
        "            syllabification_time -= STEP_SIZE\n",
        "            params['syllabification_time'] = syllabification_time\n",
        "        if syllabification_time == 0:\n",
        "            SYLLABIFIED = True\n",
        "            params['SYLLABIFIED'] = SYLLABIFIED\n",
        "        if (P_node_act[phonemes_['pT']] > THRESHOLD) and MORPH_DONE:\n",
        "            seg3_verification_time -= STEP_SIZE\n",
        "            params['seg3_verification_time'] = seg3_verification_time\n",
        "        if seg3_verification_time == 0:\n",
        "            SEG3_DONE = True\n",
        "            params['SEG3_DONE'] = SEG3_DONE\n",
        "        if (P_node_act[phonemes_['pE']] > THRESHOLD) and MORPH_DONE:\n",
        "            seg2_verification_time -= STEP_SIZE\n",
        "            params['seg2_verification_time'] = seg2_verification_time\n",
        "        if seg2_verification_time == 0:\n",
        "            SEG2_DONE = True\n",
        "            params['SEG2_DONE'] = SEG2_DONE\n",
        "        if (P_node_act[phonemes_['pK']])  > THRESHOLD and MORPH_DONE:\n",
        "            seg1_verification_time -= STEP_SIZE\n",
        "            params['seg1_verification_time'] = seg1_verification_time\n",
        "        if seg1_verification_time == 0:\n",
        "            SEG1_DONE = True\n",
        "            params['SEG1_DONE'] = SEG1_DONE\n",
        "        if M_node_act[morphemes_['mCAT']] > THRESHOLD:\n",
        "            #/* Zero THRESHOLD for excluding locus in morphological encoding */\n",
        "            morph_verification_time -= STEP_SIZE\n",
        "            params['morph_verification_time'] = morph_verification_time\n",
        "        if morph_verification_time == 0:\n",
        "            MORPH_DONE = True\n",
        "            params['MORPH_DONE'] = MORPH_DONE\n",
        "\n",
        "    if SYLL_DONE:\n",
        "        if T > CORRECTION_MENTAL_SOA:\n",
        "            # in denominator all syllable program nodes\n",
        "            # harard rate at 1.0 for excluding locus in phonetic encoding\n",
        "            syllables = ['sCAT', 'sDOG', 'sMAT', 'sFOG', 'sFISH']\n",
        "            __s = 0\n",
        "            for _s in syllables:\n",
        "                #print(_s, syllable_[_s], S_node_act[syllable_[_s]])\n",
        "                __s += S_node_act[syllable_[_s]]\n",
        "            __s = S_node_act[syllable_['sCAT']] / __s\n",
        "            h[int(T/STEP_SIZE)+1] = __s\n",
        "            #h[int(T/STEP_SIZE)+1] = S_node_act[syllable_['sCAT']]   / ( S_node_act[syllable_['sCAT']]  \n",
        "            #                                                        + S_node_act[syllable_['sDOG']]\n",
        "            #                                                        + S_node_act[syllable_['sMAT']]\n",
        "            #                                                        + S_node_act[syllable_['sFOG']]\n",
        "            #                                                        + S_node_act[syllable_['sFISH']])\n",
        "        else:\n",
        "            h[int(T/STEP_SIZE)+1] = 0.0\n",
        "            \n",
        "    return h, params\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UODpgfb791Xc"
      },
      "source": [
        "## 4.3. 結果の出力ルーチン I/O routines"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIAIjGVC91Xc"
      },
      "source": [
        "#/*****************\n",
        "# *  I/0 ROUTINES *\n",
        "# *****************/\n",
        "\n",
        "def print_heading():\n",
        "    print(\"Simulation of Immediate and Treatment Effects of Phonological Cueing in Anomia (c) Ardi Roelofs\")\n",
        "    print(\"\\nworking...\\n\")\n",
        "\n",
        "def print_expectations_of_RT(SIM_MEANS, params):\n",
        "    \n",
        "    print(\"             Untreated                    Treated\")\n",
        "    print(\"             Whole Initial Final Noise    Whole Initial Final Noise\")\n",
        "    print(\"              {0:4.0f}   {1:4.0f}   {2:4.0f}  {3:4.0f}     {4:4.0f}   {5:4.0f}   {6:4.0f}  {7:4.0f} [ms]\".format(\n",
        "        SIM_MEANS[test_['BEFORE'], cue_['WHOLE']],\n",
        "        SIM_MEANS[test_['BEFORE'], cue_['INITIAL']],\n",
        "        SIM_MEANS[test_['BEFORE'], cue_['FINAL']],\n",
        "        SIM_MEANS[test_['BEFORE'], cue_['NOISE']],\n",
        "        SIM_MEANS[test_['AFTER'],  cue_['WHOLE']],\n",
        "        SIM_MEANS[test_['AFTER'],  cue_['INITIAL']],\n",
        "        SIM_MEANS[test_['AFTER'],  cue_['FINAL']],\n",
        "        SIM_MEANS[test_['AFTER'],  cue_['NOISE']]))\n",
        "    \n",
        "    print(\"Cue effect:   {0:4.0f}   {1:4.0f}   {2:4.0f}           {3:4.0f}   {4:4.0f}   {5:4.0f}    \".format(\n",
        "        SIM_MEANS[test_['BEFORE'], cue_['WHOLE']]   - SIM_MEANS[test_['BEFORE'], cue_['NOISE']],\n",
        "        SIM_MEANS[test_['BEFORE'], cue_['INITIAL']] - SIM_MEANS[test_['BEFORE'], cue_['NOISE']],\n",
        "        SIM_MEANS[test_['BEFORE'], cue_['FINAL']]   - SIM_MEANS[test_['BEFORE'], cue_['NOISE']],\n",
        "        SIM_MEANS[test_['AFTER'],  cue_['WHOLE']]   - SIM_MEANS[test_['AFTER'],  cue_['NOISE']],\n",
        "        SIM_MEANS[test_['AFTER'],  cue_['INITIAL']] - SIM_MEANS[test_['AFTER'],  cue_['NOISE']],\n",
        "        SIM_MEANS[test_['AFTER'],  cue_['FINAL']]   - SIM_MEANS[test_['AFTER'],  cue_['NOISE']]))\n",
        "    print(\"Treatment effect:{0:3.0f} [ms]\".format(SIM_MEANS[test_['BEFORE'],cue_['NOISE']] - SIM_MEANS[test_['AFTER'],cue_['NOISE']]))\n",
        "    \n",
        "    print(\"\\nParameter values:\")\n",
        "    print(\"mental corr : {:6d} [ms]\".format(params['CORRECTION_MENTAL_SOA']))\n",
        "    print(\"lex_rate    : {:.4f} [prop per ms]\".format(params['LEX_rate']  / params['STEP_SIZE']))\n",
        "    print(\"exin        : {:.4f} [act_units per ms]\".format(params['EXTIN'] / params['STEP_SIZE']))\n",
        "    print(\"d           : {:.4f} [prop per ms]\".format(params['DECAY_rate'] / params['STEP_SIZE']))\n",
        "    print(\"phoneme_du  : {:6d} [ms]\".format(params['PHONEME_DURATION']))\n",
        "    #print(\"\\nPress <RET> to continue \")\n",
        "    #getchar(); "
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PbQc5ML991Xc"
      },
      "source": [
        "# 5. シミュレーションの実施 Execution of this simutaion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8lGs_LYY91Xc",
        "outputId": "b4e84a72-38f2-4ddc-bff5-5246aff91696"
      },
      "source": [
        "# シミュレーションを行うには，このセルを実行します。\n",
        "main()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Simulation of Immediate and Treatment Effects of Phonological Cueing in Anomia (c) Ardi Roelofs\n",
            "             Untreated                    Treated\n",
            "             Whole Initial Final Noise    Whole Initial Final Noise\n",
            "               296    295    297   317      269    269    271   292 [ms]\n",
            "Cue effect:    -21    -21    -20            -23    -23    -21    \n",
            "Treatment effect: 25 [ms]\n",
            "\n",
            "Parameter values:\n",
            "mental corr :    100 [ms]\n",
            "lex_rate    : 0.0120 [prop per ms]\n",
            "exin        : 0.1965 [act_units per ms]\n",
            "d           : 0.0240 [prop per ms]\n",
            "phoneme_du  :    125 [ms]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        },
        "id": "C5AALc7d91Xd",
        "outputId": "961c3ba0-b124-41aa-d570-a06665dbd990"
      },
      "source": [
        "# このセルはおまけです。図を描画しているだけです\n",
        "x = [[296, 295, 297, 317],\n",
        "     [269, 269, 271, 292]]\n",
        "xx = np.array([0,1,2,3])\n",
        "X = np.arange(4)\n",
        "fig = plt.figure()\n",
        "ax = fig.add_axes([0,0,1,1])\n",
        "#ax.set_xticklabels(names_of_cueing_conds)\n",
        "ax.set_xticklabels(['', 'whole','','initial','','final', '', 'noise'])\n",
        "#ax.xlabels = \n",
        "ax.bar(xx - 0.125, x[0], color = 'r', width = 0.25)\n",
        "ax.bar(X + 0.125, x[1], color = 'w', edgecolor='black', width = 0.25)\n",
        "plt.ylim(250,350)\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(250.0, 350.0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rrABxpOy91Xd"
      },
      "source": [
        "# 6. オリジナルの出力例 Original outpus to be displayed\n",
        "('Anomia cuing.c') の実行結果\n",
        "\n",
        "```bash\n",
        "Simulation of Immediate and Treatment Effects of Phonological Cueing in Anomia (c) Ardi Roelofs\n",
        "\n",
        "working...\n",
        "             Untreated                     Treated  \n",
        "             Whole Initial Final Noise     Whole Initial Final Noise \n",
        "             295    295    297     316     268    268    270     291  [ms]\n",
        "Cue effect:  -21    -21    -19             -23    -23    -21    \n",
        "Treatment effect:   25 [ms]  \n",
        "\n",
        "Parameter values:\n",
        "mental corr :    100 [ms]\n",
        "lex_rate    : 0.0120 [prop per ms]\n",
        "exin        : 0.1965 [act_units per ms]\n",
        "d           : 0.0240 [prop per ms]\n",
        "phoneme_du  :    125 [ms]\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6gFr20iB91Xd"
      },
      "source": [
        "# 追加のシミュレーション"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QKxx-PjV91Xd",
        "outputId": "70013188-7bd4-4529-c8fa-4d49dfe2259e"
      },
      "source": [
        "# 上記のように，何も指定しないで main() を実行するとオリジナルの論文どおりの結果が得られます。\n",
        "# 以下では条件を少し変更して実行しています。\n",
        "# そのためには hyper_params内の値を変更してから main() を実行します。\n",
        "\n",
        "STEP_SIZE = 25\n",
        "VER_TIME = 25\n",
        "N_STEPs = int((1000 + STEP_SIZE) / STEP_SIZE)\n",
        "\n",
        "hyper_params = {\n",
        "    'STEP_SIZE': STEP_SIZE,           # duration time step in ms \n",
        "    # 時刻の刻み幅 数学的な表記はしばしば $\\Delta t$ と表記される\n",
        "    'N_STEPs' : N_STEPs,               # Number of time steps\n",
        "    # compute_prob_functions() 内で (1000 / STEP_SIZE) +1 回 繰り返される総ステップ数\n",
        "    'LEX_rate': 0.0120 * STEP_SIZE,    # prop per step_size (ms)\n",
        "    'DECAY_rate': 0.0024 * STEP_SIZE,  #  prop per step_size (ms)\n",
        "    #'DECAY_rate': 0.0240 * STEP_SIZE,  #  prop per step_size (ms)\n",
        "    'EXTIN': 0.1965 * STEP_SIZE,       # act_units per step_size (ms),\n",
        "    'PHONEME_DURATION': 125,           # (ms)  125ms なので 1秒間に8ステップを仮定\n",
        "    'CORRECTION_MENTAL_SOA':100,       # (ms)\n",
        "    'VER_TIME': 25,                    # verification time, in ms \n",
        "    'FR': 0.10,                        # default 0.10; at 0.05 for Large cohort size    \n",
        "    # Pellet Cheneval, Glize, & Laganaro (2018, Aphasiology)  この論文は未入手 2020-1204 上間先生より\n",
        "    # The lexical or sub-lexical locus of facilitation by phonemic cueing in aphasic speakers: \n",
        "    # the effect of onset cohort size, 1468-1489.\n",
        "    'THRESHOLD': 1.5, \n",
        "    'ANOMIA_REDUCTION': 0.5,           # default 0.5; for BOLD, range 0.6, 0.5, 0.43, 0.4, 0.38\n",
        "    'MORPH_DONE': False,\n",
        "    'SUPRA_DONE': False,\n",
        "    'SEG1_DONE': False, \n",
        "    'SEG2_DONE': False, \n",
        "    'SEG3_DONE': False,\n",
        "    'SYLL_DONE': False,  \n",
        "    'SYLLABIFIED': False,\n",
        "    'syllable_program_verification_time': VER_TIME,\n",
        "    'morph_verification_time': VER_TIME,\n",
        "    'seg1_verification_time': VER_TIME,\n",
        "    'seg2_verification_time': VER_TIME,\n",
        "    'seg3_verification_time': VER_TIME,\n",
        "    # 'cat' の 音韻として Onse, Vowel, Coda の 3つなので seg1, seg2, seg3 と 3 つあるのだろう\n",
        "    'syllabification_time': 2 * VER_TIME,\n",
        "    'syllabification_time': VER_TIME, \n",
        "    'syllable_program_verification_time': VER_TIME,\n",
        "}\n",
        "\n",
        "main(params=hyper_params)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Simulation of Immediate and Treatment Effects of Phonological Cueing in Anomia (c) Ardi Roelofs\n",
            "             Untreated                    Treated\n",
            "             Whole Initial Final Noise    Whole Initial Final Noise\n",
            "               258    258    274   292      260    260    273   292 [ms]\n",
            "Cue effect:    -34    -34    -17            -32    -32    -19    \n",
            "Treatment effect:  0 [ms]\n",
            "\n",
            "Parameter values:\n",
            "mental corr :    100 [ms]\n",
            "lex_rate    : 0.0120 [prop per ms]\n",
            "exin        : 0.1965 [act_units per ms]\n",
            "d           : 0.0024 [prop per ms]\n",
            "phoneme_du  :    125 [ms]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Gw-bY-l91Xd"
      },
      "source": [
        "# 7. シュミュレーションで使用されている変数の説明\n",
        "\n",
        "* STEP_SIZE:= 25, 1 step size で 25 ms \n",
        "* N_STEPs:\n",
        " = int((1000 + STEP_SIZE) / STEP_SIZE)) だから 41，すなわち 1 秒間(=1000ms) では 1000/STEP_SIZE だけステップが刻まれるが，1 秒間であること保証するために 1 秒 + 1 ステップ 経過する時間だけシミュレーションを繰り返す\n",
        "ことを意味している\n",
        "\n",
        "* LEX_rate: 語彙率ということかな（？）。シミュレーションでは 0.0120 * STEP_SIZE = 0.3 である。\n",
        "1 ステップ毎に 0.3 だけ変化する。\n",
        "\n",
        "`set_spreading_rates()` の中で `MP_con`, `PS_con` が以下のような影響を受ける。\n",
        "MP_con, PS_con とは，形態層と音韻層とのコネクション，音韻層と音素層とのコネクション, respectively である。\n",
        "MP_con, PS_con とも，最初は 0, 1 でつながっているが，LEX_rate (=0.3)が掛けられることで変化する。\n",
        "\n",
        "* `set_spreading_rates()` で `MP_con *= LEX_rate; PS_con *= LEX_rate` し，かつ，\n",
        "* `reset_spreding_rates()` で `MP_con *= 1.0/LEX_rate; PS_con *= 1.0/LEX_rate` で戻している。\n",
        "\n",
        "すなわち 形態素層と音韻層との結合係数を $0.3$ にセットし，同じく，音韻層と音素層との結合係数を同じく $0.3$ にセットしている\n",
        "\n",
        "* DECAY_rate: 崩壊率 0.024 * STEP_SIZE = 0.6 だから，LEX_rate の 2 倍である。\n",
        "`update_activation_of_nodes()` 内で\n",
        "$$\n",
        "x_i = x_i * (1-\\text{DECAY_rate}) + \\text{input} \n",
        "$$\n",
        "\n",
        "* EXTIN: `0.1965 * STEP_SIZE = 4.9125` なので 1 ステップあたりおよそ 4.9 \n",
        "`get_external_input()` の中で，形態素層の値を加算する:\n",
        "\n",
        "```python\n",
        "if T >= CORRECTION_MENTAL_SOA:\n",
        "\tinput_M['mCAT'] += 1.0 * EXTIN\n",
        "```\n",
        "\n",
        "ターゲットである \"cat\" だけ形態素層の活性化が一時刻あたり 4.9125 だけ増加する。\n",
        "さらに，同じく `get_external_input()` 内でキュー条件に応じて，音韻層と形態素層のターゲットユニット (cat に相当する）\n",
        "に対して，一時刻あたり `FR * EXTIN` だけ加算させる\n",
        "```python\n",
        "input_P['target'] += EXTIIN\n",
        "input_M['target'] += FR * EXTIN\n",
        "```\n",
        "\n",
        "* PHONEME_DURATION: 125 \n",
        "音韻期間は，4 期間に分割されている。\n",
        "1. 0 < T < PHONEME_DURATION: すなわち，最初の音韻期間は，onset と vowel /k/ と /a/ が EXTIN 分だけ増加\n",
        "2. PHONEME_DURATION < T < 2 * PHONEME_DURATION は，coda /t/ が EXTIN 分だけ増加\n",
        "3. それ以外は何もしない\n",
        "\n",
        "* CORRECTION_MENTAL_SOA: 100. 心的刺激オンセット修正\n",
        "`get_external_input()` 内で\n",
        "```python\n",
        "if T>= CORRECTION_MENTAL_SOA: \n",
        "\tinput_M['target'] += 1.0 * EXTIN\n",
        "```\n",
        "なので，最初から形態素層に入力があるのではなく，`CORRECTION_MENTAL_SOA` 時刻以後に形態素層への入力が加わるという意味である。\n",
        "\n",
        "* THRESHOLD: 1.5\n",
        "`compute_hazard_rate()` 内での計算に使われる。メンタル，刺激オンセット時刻以降で，音素層のターゲット活性値がこの閾値以上でああって，\n",
        "かつ，発語がなされている `SYLLABIFIED=True` であれば，一時刻分，時間を引き算する\n",
        "\n",
        "```python\n",
        " if T > CORRECTION_MENTAL_SOA:\n",
        "        if S_node_act[syllable_['sCAT']] > THRESHOLD and SYLLABIFIED:\n",
        "            #/* Zero THRESHOLD for excluding locus in phonetic encoding */\n",
        "            syllable_program_verification_time -= STEP_SIZE;\n",
        "```\n",
        "\n",
        "引き算した結果 `syllable_program_verification_time == 0` になれば `SYLL_DONE` フラグを立てて，発語終了と見なす。\n",
        "発語終了時に音素層 `S_node_act` の活性値を計算して $\\text{ターゲットの活性値}/\\text{全活性値の総和}$ を計算して，$h[T]$ に代入する\n",
        "\n",
        "* ANOMIA_REDUCTION: 0.5 失語症による形態素層から音韻層への結合係数の減衰率\n",
        "処置前 `BEFORE` のとき `set_spreding_rates()` 内で，ターゲット語 cat から音素 /c/, /a/, /t/ へ向けての結合係数が，`ANOMIA_REDUCTION` だけ減衰する。\n",
        "`reset_spreading_rates()` でこれらの値をもとに戻している。\n",
        "このことから `ANOMIA_REDUCTION` は損傷程度を表すと考えられる。\n",
        "\n",
        "* `compute_hazard_rate()` 内で行わていること\n",
        "1. メンタルSOA 以上の時刻が経過していたら\n",
        "2. ターゲットの形態素が活性化していれば，1 ステップ単位ずつ `morph_verification_time` を減じる\n",
        "3. `morph_verification_time` が 0 になれば `MORPH_DONE` フラグを立てて形態素処理を終了する\n",
        "4. 形態素処理が終了していて，かつ，音素 /k/ が活性化していれば，`seg1_verification_time` を減じる\n",
        "5. 形態素処理が終了していて，かつ，音素 /a/ が活性化していれば，`seg2_verification_time` を減じる\n",
        "6. 形態素処理が終了していて，かつ，音素 /t/ が活性化していれば，`seg3_verification_time` を減じる\n",
        "7. 全ての seg1, seg2, seg3 が終了していれば `SYLL_DONE` フラグを立てる\n",
        "\n",
        "<!--\n",
        "# f:  [0:T] 各時刻での選択確率\n",
        "#    f[1] denotes prob of selection at first time step, etc;\n",
        "#    that is, f[s] is the probability that the retrieval latency\n",
        "#    equals s x STEP_SIZE;\n",
        "#    e.g., f[2] is the probability that the retrieval latency equals\n",
        "#    2 x STEP_SIZE, i.e., 2 x 25 ms = 50 ms.\n",
        "\n",
        "# h: [0:T] 各時刻でのハザード率\n",
        "#    h[1] denotes hazard rate at first time step,\n",
        "#    h[2] denotes hazard rate at second time step, etc.,\n",
        "#    where h[s] is a function (expressed by the Luce ratio) of the\n",
        "#    activation levels at moment T equal to (s-1) * STEP_SIZE (where s=1,2,...)\n",
        "\n",
        "# S: 累積生存関数を格納する\n",
        "# f: \n",
        "# [M,P,S]_node_act: 各ニューロンの活性値\n",
        "# [M,P,S]_input: 各ニューロンへの入力\n",
        "-->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6kn6ts9591Xd"
      },
      "source": [
        "---\n",
        "\n",
        "# Appendix\n",
        "\n",
        "- ここから下はシミュレーションとは無関係です。\n",
        "- 覚書のメモと検討のための資料として載せいてるだけです。無視しても問題ありません。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wvTYFKFh91Xd"
      },
      "source": [
        "## A.1. WEAVER++ in detail\n",
        "\n",
        "以下は，ソースコード中に出てくるハザード関数 $h$, 生存関数 $S$, $f$ などの根拠となる原典を知る必要がありました。\n",
        "WEAVER モデルが詳細に記述されたのは，Roelofs(1992)が最初のようです。\n",
        "ですが，以下では WEAVER++ 論文 (Levelt, Roelofs, Meyer, 1999) の付録の記述を引用します。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vRhoMQws91Xd"
      },
      "source": [
        "The equations for the spreading of activation and the selection ratio are as follows (see Roelofs 1992a; 1993; 1994; 1996b;[@1999Levert_WEAVER++;@1997Roelofs_WEAVER]) \n",
        "\n",
        "Activation spreads according to\n",
        "$$\n",
        "a(k,t+\\Delta t) = a(k,t)(1-d) + \\sum_n r a(n,t),\n",
        "$$\n",
        "where $a(k,t)$ is the activation level of node $k$ at point in time $t$, $d$ is a decay rate ($0< d <1$), and $\\Delta t$ is the duration of a time step (in msec). \n",
        "The rightmost term denotes the amount of activation that $k$ receives between $t$ and $t+\\Delta t$, where $a(n,t)$ is the output of node $n$ directly connected to $k$ (the output of $n$ is equal to its level of activation).\n",
        "The factor $r$ indicates the spreading rate. \n",
        "\n",
        "The probability that a target node $m$ will be selected at $t< T\\le t+\\Delta t$ given that it has not been selected at $T\\ge t$, and provided that the selection conditions for a node are met, is given by the ratio:\n",
        "$$\n",
        "\\frac{a(m,t)}{\\sum_i a(i,t)},\n",
        "$$\n",
        "\n",
        "For lemma retrieval, the index $i$ ranges over the lemma nodes in the network. \n",
        "The selection ratio equals the hazard rate $h_m(s)$ of the retrieval of lemma $m$ at time step $s$, where $t=(s-1)\\Delta t$, and $s=1, 2,\\ldots,$.\n",
        "The expected latency of lemma retrieval, $E(T)$, is\n",
        "$$\n",
        "E(T)=\\sum_{s=1}^{\\infty}h_m(s)\\left(\\prod_{j=0}^{s-1}\\left[1-h_m(j)\\right]\\right)s\\Delta t.\n",
        "$$\n",
        "\n",
        "For word form encoding, the index $i$ in the selection ratio ranges over the syllable program nodes in the network. \n",
        "The selection ratio then equals the hazard rate $h_m(s)$ of the process of the encoding of syllable $m$ (up to the access of the syllabary) at time step $s$.\n",
        "The equation expressing the expected latency of word form encoding for monosyllables is the same as that for lemma retrieval.\n",
        "In encoding the form of a disyllabic word, there are two target syllable program nodes, syllable 1 and syllable 2. \n",
        "The probability p(word form encoding completes at $s$) for a disyllabic word equals:\n",
        "\n",
        "$$\n",
        "\\left[h_1(s)V_1(s-1)\\right]\\sum_{j=0}^{s-1}\\left(h_2(j)V_2(j-1)\\right) +\n",
        "$$\n",
        "$$\n",
        "\\left[h_2(s)V_2(s-1)\\right]\\sum_{j=0}^{s-1}\\left(h_1(j)V_1(j-1)\\right) +\n",
        "$$\n",
        "$$\\left[h_1(s)V_1(s-1)\\right]\\left[h_2(s)V_2(s-1)\\right]$$\n",
        "$$= f_1(s)\\sum_{j=0}^{s-1} f_2(s) + f_2(s)\\sum_{j=0}^{s-1} f_1(s) + f_1(s) f_2(s),$$\n",
        "where $h_1(s)$ and $h_2(s)$ are the hazard rates of the encoding of syllable 1 and 2, respectively, $V_1(s)$ and $V_2(s)$ the corresponding cumulative survivor functions, and $f_1(s)$ and $f_2(s)$ the probability mass functions. \n",
        "For the expectation of $T$ holds,\n",
        "\n",
        "$$\n",
        "E(T)=\\sum_{s=1}^{\\infty}\n",
        "\\left(f_1(s)\\sum_{j=0}^{s-1}f_2(s)\\sum_{j=0}^{s-1}f_1(s)+f_1(s) f_2(s) \\right)\n",
        "s\\Delta t.\n",
        "$$\n",
        "\n",
        "The estimates for the parameters in these equations were as follows. \n",
        "The spreading rate $r$ within the conceptual, lemma, and form strata was $0.0101$, $0.0074$, and $0.0120\\text{msec}^{-1}$, respectively, and the overall decay rate $d$ was $0.0240\\text{msec}^{-1}$.\n",
        "The duration of basic events such as the time for the activation to cross a link, the latency of a verification procedure, and the syllabification time per syllable equalled $\\Delta t=25$ msec. \n",
        "For details of the simulations, we refer the reader to the original publications (Roelofs 1992a; 1993; 1994; 1996b; 1997c)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQimCXzm91Xd"
      },
      "source": [
        "<!--\n",
        "## A.2. Reolefs (1997) p. 262\n",
        "### 3.2. Computer simulations\n",
        "I now discuss how WEAVER accounts for the patterns of effects. \n",
        "I first describe a simple implementation of the model for the picture-word interference paradigm. \n",
        "Next, I present the results of computer simulations. \n",
        "\n",
        "シミュレーションは小規模ネットワークと大規模ネットワークを用いて行った。\n",
        "小規模ネットワークには実験に必要な最小限の単語が含まれている。\n",
        "小規模ネットワークには、抽象 CVC と CV.CVC の形態素、セグメント、音節プログラムノードがある。\n",
        "\n",
        "The simulations were run using both small and large networks. \n",
        "The small network  contained the words minimally needed to simulate the experiments. \n",
        "There were morpheme, segment, and syllable program nodes for abstract CVCs and CV.CVCs.\n",
        "These items represented, for example, boek (target), boeg (begin-related), doek (end-related), meeuw (name of another picture), meer (begin-unrelated for boek), leeuw (end-unrelated for boek), and all the disyllables needed. \n",
        "There was no segmental overlap between the forms other than that required for the simulation of the various distractor conditions.\n",
        "\n",
        "To examine whether the size and the scope of the network influenced the outcomes, the simulations were run using larger networks. \n",
        "These networks contained the critical monosyllables and disyllables plus several other words. \n",
        "From the Dutch part of the CELEX lexical database (Baayen et al., 1995), I obtained (1) the forms of 50 nouns of highest frequency, and (2) the forms of 50 randomly selected nouns.\n",
        "Appendices B and C list the targets, distractors, and the other words for the larger networks. \n",
        "The outcomes for the small and the two large networks were the same (the Pearson product-moment correlations between the SOA curves obtained with the small and the two large simulations were, respectively, $r(48)= 0.98$ \n",
        "and $r(48)=0.99$, both $Ps<0.001$).\n",
        "\n",
        "The encoding of the target word-form was simulated following the encoding algorithm described above. \n",
        "For the distractor word, the following extremely simplifying assumptions were made. \n",
        "The spoken distractor word activated a cohort of compatible elements in the output form-lexicon, analogous to what Marslen-Wilson and Welsh (1978) proposed for the input lexicon. \n",
        "Two levels of representation were involved: the morphological and the segmental layer (see Fig. 2). \n",
        "The processing of the speech signal from the beginning of the word to its end had a direct counterpart in the activation of the network. \n",
        "For example, for the first $\\lambda$ ms, the speech segment  [b] of distractor [bux] activated the segment node /b/, and somewhat less the morpheme nodes, \\<boek\\>. and \\<boeg\\>; during the next $\\lambda$ ms, the /u/, and somewhat less the morpheme nodes /boek/ and /boeg/; and during the final $\\lambda$ ms, the [x] part activated the segment node /x/ and somewhat less the morpheme node \\<boeg\\>, but not \\<boek\\> anymore. \n",
        "Current models of word recognition do not take such an all-or-none view of cohort membership. \n",
        "Note, however, that the cohort assumption in the simulations concerns the production lexicon, not the perception lexicon. \n",
        "-->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ruq7K4ob91Xd"
      },
      "source": [
        "<!--\n",
        "## A.3. Revelt, Reolofs, Mayer, WEVER++ (1999)\n",
        "\n",
        "### 3. The theory in outline\n",
        "#### 3.1. Processing stages\n",
        "\n",
        "The flow diagram presented in Figure 1 shows the theory in outline. \n",
        "<center>\n",
        "<img src=\"https://raw.githubusercontent.com/project-ccap/project-ccap.github.io/master/figures/1999Levelt_WEAVER++_fig1.svg\" style=\"width:49%\"><br/>\n",
        "Fig. 1\n",
        "</center>\n",
        "The production of words is conceived as a staged process, leading from conceptual preparation to the initiation of articulation. \n",
        "Each stage produces its own characteristic output representation. \n",
        "These are, respectively, lexical concepts, lemmas, morphemes, phonological words, and phonetic gestural scores (which are executed during articulation).\n",
        "In the following it will be a recurring issue whether these stages overlap in time or are strictly sequential, but here we will restrict ourselves to a summary description of what each of these processing stages is supposed to achieve. \n",
        "-->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iu_PV7Tt91Xe"
      },
      "source": [
        "<!--\n",
        "### A.3.1.1. Conceptual preparation. \n",
        "All open class words and most closed class words are meaningful. \n",
        "The intentional production of a meaningful word always involves the activation of its lexical concept. \n",
        "The process leading up to the activation of a lexical concept is called \"conceptual preparation.\" \n",
        "However, there are many roads to Rome. \n",
        "In everyday language use, a lexical concept is often activated as part of a larger message that captures the speaker’s communicative intention (Levelt 1989). \n",
        "If a speaker intends to refer to a female horse, he may effectively do so by producing the word \"mare,\" which involves the activation of the lexical concept MARE(X). \n",
        "But if the intended referent is a female elephant, the English speaker will resort to a phrase, such as \"female elephant,\" because there is no unitary lexical concept available for the expression of that notion. \n",
        "A major issue, therefore, is how the speaker gets from the notion/information to be expressed to a message that consists of lexical concepts (here message is the technical term for the conceptual structure that is ultimately going to be formulated).\n",
        "This is called the verbalization problem, and there is no simple one-to-one mapping of notions-to-be-expressed onto messages (Bierwisch & Schreuder 1992).\n",
        "Even if a single lexical concept is formulated, as is usually the case in object naming, this indeterminacy still holds, because there are multiple ways to refer to the same object.\n",
        "In picture naming, the same object may be called “animal,” “horse,” “mare,” or what have you, depending  set of alternatives and on the task. \n",
        "This is called perspective taking. \n",
        "There is no simple, hard-wired connection between percepts and lexical concepts. \n",
        "That transition is always mediated by pragmatic, context-dependent considerations. \n",
        "Our work on perspective taking has, until now, been limited to the lexical expression of spatial notions (Levelt 1996), but see E. Clark (1997) for a broader discussion.\n",
        "Apart from these distal, pragmatic causes of lexical concept activation, our theory recognizes more proximal, semantic causes of activation. \n",
        "This part of the theory has been modeled by way of a conceptual network (Roelofs 1992a; 1992b), to which we will return in sections 3.2 and 4.1. \n",
        "The top level in Figure 2 represents a fragment of this network. \n",
        "<center>\n",
        "<img src=\"https://raw.githubusercontent.com/project-ccap/project-ccap.github.io/master/figures/1999Levelt_WEAVER++_fig2.svg\" style=\"width:49%\"><br/>\n",
        "Fig. 2\n",
        "</center>\n",
        "\n",
        "It depicts a concept node, escort(x, y), which stands for the meaning of the verb “escort.” \n",
        "It links to other concept nodes, such as accompany $(x,y$), and the links are labeled to express the character of the connection – in this case, is-to, because to escort $(x,y)$ is to accompany $(x,y)$. \n",
        "In this network concepts will spread their activation via such links to semantically related concepts. \n",
        "This mechanism is at the core of our theory of lexical selection, as developed by Roelofs (1992a). \n",
        "A basic trait of this theory is its nonde compositional character. \n",
        "Lexical concepts are not represented by sets of semantic features because that creates a host of counterintuitive problems for a theory of word production. \n",
        "One is what Levelt (1989) has called the hyperonym problem. \n",
        "When a word’s semantic features are active, then, per definition, the feature sets for all of its hyperonyms r superordinates are active (they are subsets). \n",
        "Still, there is not the slightest evidence that speakers tend to produce hyperonyms of intended target words. \n",
        "\n",
        "Another problem is the nonexistence of a semantic complexity effect. \n",
        "It is not the case that words with more complex feature sets are harder to access in production than words with simpler feature sets (Levelt et al. 1978). \n",
        "These and similar problems vanish when lexical concepts are represented as undivided wholes.\n",
        "\n",
        "The conceptual network’s state of activation is also measurably sensitive to the speaker’s auditory or visuaword input (Levelt & Kelter 1982). \n",
        "This is, clearly, another source of lexical concept activation. \n",
        "This possibility has been exploited in many of our experiments, in which a visual or auditory distractor word is presented while the subject is naming a picture.\n",
        "\n",
        "Finally, Dennett (1991) suggested a pandemonium-like spontaneous activation of words in the speaker’s mind. \n",
        "Although  we have not modeled this, there are three ways to implement such a mechanism. \n",
        "The first would be to add spontaneous, statistical activation to lexical concepts in the network. \n",
        "The second would be to do the same at the level of lemmas, whose activation can be spread back to the conceptual level (see below). \n",
        "The third would be to implement spontaneous activation of word forms; their resulting morphophonological encoding would then feed back as internal speech (see Fig. 1) and activate the corresponding lexical concepts.\n",
        "-->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tiihi-X191Xe"
      },
      "source": [
        "<!--\n",
        "### A.3.1.2. Lexical selection. \n",
        "Lexical selection is retrieving a word, or more specifically a lemma, from the mental lexicon, given a lexical concept to be expressed. \n",
        "In normal speech, we retrieve some two or three words per second from a lexicon that contains tens of thousands of items. \n",
        "This high-speed process is surprisingly robust; errors of lexical selection occur in the one per one thousand range. \n",
        "Roelofs (1992a) modeled this process by attaching a layer of lemma nodes to the conceptual network, one lemma node for each lexical concept. \n",
        "An active lexical concept spreads some of its activation to “its” lemma node, and lemma selection is a statiical mechanism, which favors the selection of the highest activated lemma. \n",
        "Although this is the major selection mechanism, the theory does allow for the selection of function words on purely syntactic grounds (as in “John said that ...”, where the selection of that is not conceptually but syntactically driven). \n",
        "Upon selection of a lemma, its syntax becomes available for further grammatical encoding, that is, creating the appropriate syntactic environment for the word. \n",
        "For instance, retrieving the lemma escort will make available that this is a transitive verb [node $V_t(x,y)$ in Fig. 2] with two argument positions (x and y), corresponding to the semantic arguments $X$ and $Y$, and so on.\n",
        "\\footnote{The syntactic representation of escort in Figure 2 is , admittedly, quite simplified.}\n",
        "\n",
        "\n",
        "Many lemmas have so-called diacritic parameters that have to be set. \n",
        "For instance, in English, verb lemmas have features for number, person, tense, and mood (see Fig. 2).\n",
        "It is obligatory for further encoding that these features are valued. \n",
        "The lemma escort, for instance, will be phonologically realized as escort, escorts, escorted, escorting, depen\n",
        "ding on the values of its diacritic features. \n",
        "The values of these features will in part derive from the conceptual representation.\n",
        "For example, tense being an obligatory feature in English, the speaker will always have to check the relevant \n",
        "temporal properties of the state of affairs being expressed.\n",
        "Notice that this need not have any communicative function. \n",
        "Still, this extra bit of thinking has to be done in preparation of any tensed expression. \n",
        "Slobin (1987) usefully called this “thinking for speaking.” \n",
        "For another part, these diacritic feature values will be set during grammatical encoding. \n",
        "A verb’s number feature, for instance, is set by agreement, in dependence on the sentence subject’s number fture. \n",
        "Here we must refrain from discussing these mechanisms of grammatical encoding (but see Bock & Levelt 1994; Boc\n",
        "k & Miller 1991; and Levelt 1989 for details).\n",
        "-->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "470_tMou91Xe"
      },
      "source": [
        "<!--\n",
        "### A.3.1.3. Morphophonological encoding and syllabification.\n",
        "After having selected the syntactic word or lemma, the speaker is about to cross the rift mentioned above, going from the conceptual/syntactic domain to the phonological/articulatory domain. \n",
        "The task is now to prepare the appropriate articulatory gestures for the selected word in its prosodic context, and the first step here is to retrieve the word’s phonological shape from the mental lexicon. \n",
        "Crossing the rift is not an entirely trivial matter. \n",
        "The tip-of-thetongue phenomenon is precisely the momentary inability to retrieve the word form, given a selected lemma. \n",
        "Levelt (1989) predicted that in a tip-of-the tongue state the word’s syntactic features should be available in spite of the blockage, because they are lemma properties. \n",
        "In particular, a Dutch or an Italian speaker should know the grammatical gender of the target word. \n",
        "This has recently been experimentally demonstrated by Vigliocco et al. (1997) for Italian speakers. \n",
        "Similarly, certain types of anomia involve the same inability to cross this chasm. \n",
        "Badecker et al. (1995) showed this to be the case for an Italian anomic patient, who could hardly name any picture, but always knew the target word’s grammatical gender. \n",
        "However, even if word form access is unhampered, production is much harder for infrequent words than for frequent words; the difference in naming latency easily amounts to 50–100 msec. \n",
        "Jescheniak and Levelt (1994) showed that word form access is the major, and probably unique, locus of the word frequency effect (discovered by Oldfield & Wingfield 1965).\n",
        "\n",
        "According to the theory, accessing the word form means activation of three kinds of information, the word’s mrphological makeup, its metrical shape, and its segmental makeup. \n",
        "For example, if the lemma is escort, diacritically marked for progressive tense, the first step is to access the two morphemes, \\<escort\\>. and \\<ing\\>. (see Fig. 2). \n",
        "Then, the metrical and segmental properties of these morphemes will be \"spelled out.\" For escort, the metrical  information involves that the morpheme is iambic, that is, that it is disyllabic and stress-final, and that it can be a phonological word ($\\mathbf{\\omega}$) itself. \n",
        "For \\<ing\\> the spelled out metrical information is that it is a monosyllabic, unstressed morpheme, which cannot be an independent phonological word (i.e., it must become attached to a phonological head, which in this case will be escort). \n",
        "The segmental spell out for \\<escort\\>  will be /e/, /s/, /k/, /c/, /r/, /t/, and for \\<ing\\> it will be /I/, \n",
        "/ng/ (see Fig. 2). \n",
        "Notice that there are no syllables at this level. \n",
        "The syllabification of the phonological word escort is e-scort, but this is not stored in the mental lexicon. \n",
        "\n",
        "In the theory, syllabification is a late process, because it often depends on the word’s phonological environent. \n",
        "In escorting, for instance, the syllabification is different: e-scor-ting, where the syllable ting straddles the two morphemes escort and ing. \n",
        "One might want to argue that the whole word form escorting is stored, including its syllabification. \n",
        "However, syllabification can also transcend lexical word boundaries.\n",
        "In the sentence \"He’ll escort us\", the syllabification will usually be e-scor-tus. \n",
        "It is highly unlikely that this cliticized form is stored in the mental lexicon. \n",
        "An essential part of the theory, then, is its account of the syllabification process. \n",
        "We have modeled this process by assuming that a morpheme’s segments or phonemes become simultaneously availabe, but with labeled links indicating their correct ordering (see Fig. 2). \n",
        "The word’s metrical template may stay as it is, or be modified in the context. \n",
        "In the generation of escorting (or escort us, for that matter), the “spelled out” metrical templates for \\<eort\\>, $\\mathbf{sigma\\sigma}'$, and for <ing\\> (or \\<us\\>), $\\mathbf{\\sigma}$, will merge to form the trisyllab\n",
        "ic template $\\mathbf{\\sigma\\sigma'\\sigma}$. \n",
        "The spelled out segments are successively inserted into the current metrical template, forming phonological sy\n",
        "llables “on the fly”: e-scor-ting (or e-scor-tus). \n",
        "This process follows quite universal rules of syllabification (such as maximization of onset and sonority grad\n",
        "ation; see below) as well as language-specific rules. \n",
        "There can be no doubt that these rules are there to create maximally pronounceable syllables. \n",
        "The domain of syllabification is called the “phonological” or “prosodic word” ($\\mathbf{\\omega}$). \n",
        "Escort, escorting, and escortus can be phonological words, that is, domains of syllabification. \n",
        "Some of the phonological syllables in which escort, in different contexts, can participate are represented in \n",
        "Figure 2.\n",
        "If the current phonological word is escorting, the relevant phonological syllables, e, scor, and ting, with wo\n",
        "rd accent on scor, will activate the phonetic syllable scores [c], [skcr], and [tng].\n",
        "-->\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KC3EB0TV91Xe"
      },
      "source": [
        "<!--\n",
        "### A.3.1.4. Phonetic encoding. \n",
        "The theory has an only partial account of phonetic encoding. \n",
        "The theoretical aim is to explain how a phonological word’s gestural score is computed.\n",
        "It is a specification of the articulatory task that will produce the word, in the sense of Browman and Goldste\n",
        "in (1992).\n",
        "This is a (still rather abstract) representation of the articulatory gestures to be performed at different art\n",
        "iculatory tiers, a glottal tier, a nasal tier, and an oral tier. \n",
        "One task, for instance, on the oral tier would be to close the lips (as should be done in a word such as apple\n",
        "). \n",
        "The gestural score is abstract in that the way in which a task is performed is highly context dependent. \n",
        "Closing the lips after [ae], for instance,  is a quite different gesture than closing the lips after rounded [\n",
        "u].\n",
        "\n",
        "Our partial account involves the notion of a syllabary. \n",
        "We assume that a speaker has access to a repository of gestural scores for the frequently used syllables of th\n",
        "e language.\n",
        "Many, though by no means all, of the coarticulatory properties of a word are syllable-internal. \n",
        "There is probably more gestural dependence within a word’s syllables than between its syllables (Browman & Godstein 1988; Byrd 1995; 1996). \n",
        "More importantly, as we will argue, speakers of English or Dutch – languages with huge numbers of syllables do most of their talking with no more than a few hundred syllables. \n",
        "Hence, it would be functionally advantageous for a speaker to have direct access to these frequently used and \n",
        "probably internally coherent syllabic scores. \n",
        "In this theory they are highly overlearned gestural patterns, which need not be recomputed time and again.\n",
        "Rather, they are ready-made in the speaker’s syllabary. \n",
        "In our computational model, these syllabic scores are activated by the segments of the phonological syllables.\n",
        " \n",
        "For instance, when the active /t/ is the onset of the phonological syllable /tià/, it will activate all syllales in the syllabary that contain [t], and similarly for the other segments of /tià/. \n",
        "A statistical procedure will now favor the selection of the gestural score [tià] among all active gestural scres (see sect. 6.3), whereas selection failures are prevented by the model’s binding-by-checking mechanism (sct. 3.2.3). \n",
        "As phonological syllables are successively composed (as discussed in the previous section), the corresponding \n",
        "gestural scores are successively retrieved. \n",
        "According to the present, partial, theory, the phonological word’s articulation can be initiated as soon as al of its syllabic scores have been retrieved.\n",
        "\n",
        "This, obviously, cannot be the full story. \n",
        "First, the speaker can compose entirely new syllables (e.g., in reading aloud a new word or nonword). \n",
        "It should be acknowledged, though, that it is a very rare occasion indeed when an adult speaker of English pro\n",
        "duces a new syllable. \n",
        "Second, there may be more phonetic interaction between adjacent syllables within a word than between the same \n",
        "adjacent syllables that cross a word boundary. \n",
        "Explaining this would either require larger, word-size stored gestural scores or an additional mechanism of ph\n",
        "onetic composition (or both).\n",
        "-->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lmGaYwFy91Xe"
      },
      "source": [
        "<!--\n",
        "### A.3.1.5. Articulation. \n",
        "The phonological word’s gestural score is, finally, executed by the articulatory system. \n",
        "The functioning of this system is beyond our present theory. \n",
        "The articulatory system is, of course, not just the muscular machinery that controls lungs, larynx, and vocal tract; it is as much a computational neural system that controls the execution of abstract gestural scores by this highly complex motor system (see Levelt 1989, for a review of motor control theories of speech production  and Jeannerod, 1994, for a neural control theory of motor action).\n",
        "-->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o6r0-6y_91Xe"
      },
      "source": [
        "<!--\n",
        "### A.3.1.6. Self-monitoring. \n",
        "The person to whom we listen most is ourself. \n",
        "We can and do monitor our overt speech output. \n",
        "Just as we can detect trouble in our interlocutor’s speech, we can discover errors, dysfluencies, or other prblems of delivery in our own overt speech. \n",
        "This, obviously, involves our normal perceptual system (see Fig. 1). \n",
        "So far, this ability is irrelevant for the present purposes. \n",
        "Our theory extends to the initiation of articulation, not beyond. \n",
        "However, this is not the whole story. \n",
        "It is apparent from spontaneous self-repairs that we can also monitor our “internal speech” (Levelt 1983), tt is, we can monitor some internal representation as it is produced during speech encoding. \n",
        "This might have some relevance for the latency of spoken word production because the process of self-monitorin\n",
        "g can affect encoding duration. \n",
        "In particular, such self-monitoring processes may be more intense in experiments in which auditory distractors\n",
        " are presented to the subject. \n",
        "More important, though, is the possibility to exploit this internal self-monitoring ability to trace the proce\n",
        "ss of phonological encoding itself. \n",
        "A crucial issue here is the nature of “internal speech.” \n",
        "What kind of representation or code is it that we have access to when we monitor our “internal speech”? \n",
        "Levelt (1989) proposed that it is a phonetic representation, the output of phonetic encoding. \n",
        "Wheeldon and Levelt (1995), however, obtained experimental evidence for the speaker’s ability also to monitora slightly more abstract, phonological representation (in accordance with an earlier suggestion by Jackendoff \n",
        "1987). \n",
        "If this is correct, it gives us an additional means of studying the speaker’s syllabification process (see set. 9), but it also forces us to modify the original theory of self-monitoring, which involved phonetic represe\n",
        "ntations and overt speech.\n",
        "-->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v8ZNTsvD91Xe"
      },
      "source": [
        "<!--\n",
        "### A.3.2. General design properties\n",
        "-->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-1vYQN7i91Xe"
      },
      "source": [
        "<!--\n",
        "#### A.3.2.1. Network structure. \n",
        "As is already apparent from Figure 2, the theory is modeled in terms of an essentially feedforward activation-\n",
        "spreading network. \n",
        "In particular, Roelofs (1992a; 1993; 1994; 1996a; 1996b; 1997c) instantiated the basic assumptions of the theo\n",
        "ry in a computational model that covers the stages from lexical selection to syllabary access. The word-form e\n",
        "ncoding part of this computational model is called weaver (for Word-form Encoding by Activation and VERificati\n",
        "on; see Roelofs 1996a; 1996b; 1997c), whereas the full model, including lemma selection,\n",
        "is now called weaver++.\n",
        "\n",
        "weaver++ integrates a spreading–activation-based network with a parallel object-oriented production system, i the tradition of Collins and Loftus (1975). \n",
        "The structure of lexical entries in weaver++ was already illustrated in Figure 2 for the word escort. \n",
        "There are three strata of nodes in the network. \n",
        "The first is a conceptual stratum, which contains concept nodes and labeled conceptual links. \n",
        "A subset of these concepts consists of lexical concepts; they have links to lemma nodes in the next stratum. \n",
        "Each lexical concept, for example $\\text{escort}(x,y)$, is represented by an independent node. \n",
        "The links specify conceptual relations, for example, between a concept and its superordinates, such as is-to-a\n",
        "ccompany(x, y). \n",
        "A word’s meaning or, more precisely, sense is represented by the total of the lexical concept’s labeled linkto other concept nodes. \n",
        "Although the modeling of the conceptual stratum is highly specific to this model, no deep ontological claims a\n",
        "bout “network semantics” are intended. \n",
        "We need only a mechanism that ultimately provides us with a set of active, nondecomposed lexical concepts.\n",
        "\n",
        "The second stratum contains lemma nodes, such as escort; syntactic property nodes, such as $V_t(x,y)$; and labeled links between them. Each word in the mental lexicon, simple or complex, content word or function word, is represented by a lemma node. \n",
        "The word’s syntax is represented by the labeled links of its lemma to the syntax nodes.\n",
        "Lemma nodes have diacritics, which are slots for the specification of free parameters, such as person, number, mood, or tense, that are valued during the process of grammatical encoding. \n",
        "More generally, the lemma stratum is linked to a set of procedures for grammatical encoding (not discussed herein).\n",
        "\n",
        "After a lemma’s selection, its activation spreads to the third stratum, the word-form stratum. \n",
        "The word-form stratum contains morpheme nodes and segment nodes. \n",
        "Each morpheme node is linked to the relevant segment nodes. \n",
        "Notice that links to segments are numbered (see Fig. 2).\n",
        "The segments linked to escort are also involved in the spellout of other word forms, for instance, Cortes, but  then the links are numbered differently. \n",
        "The links between segments and syllable program nodes specify possible syllabifications.\n",
        "A morpheme node can also be specified for its prosody, the stress pattern across syllables. \n",
        "Related to this morpheme/segment stratum is a set of procedures that generate a phonological word’s syllabifiation, given the syntactic/phonological context. \n",
        "There is no fixed syllabification for a word, as was discussed above. \n",
        "Figure 2 represents one possible syllabification of escort, but we could have chosen another; /sk°rt/, for intance would have been a syllable in the citation form of escort. \n",
        "The bottom nodes in this stratum represent the syllabary addresses. \n",
        "Each node corresponds to the gestural score of one particular syllable. For escorting, these are the phonetic syllables [ƒ], [sk°r] and [tIà].\n",
        "\n",
        "What is a “lexical entry” in this network structure? \n",
        "Keeping as close as possible to the definition given by Levelt (1989, p. 182), a lexical entry is an item in the mental lexicon, consisting of a lemma, its lexical concept (if any), and its morphemes (one or more) with their segmental and metrical properties.\n",
        "-->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vUqXs7qM91Xe"
      },
      "source": [
        "<!--\n",
        "#### A.3.2.2. Competition but no inhibition. \n",
        "There are no inhibitory links in the network, either within or between strata. \n",
        "That does not mean that node selection is not subject to competition within a stratum. \n",
        "At the lemma and syllable levels the state of activation of nontarget nodes does affect the latency of target node selection, following a simple mathematical rule (see Appendix).\n",
        "-->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gX_WyX_N91Xe"
      },
      "source": [
        "<!--\n",
        "#### A.3.2.3. Binding. \n",
        "Any theory of lexical access has to solve a binding problem. \n",
        "If the speaker is producing the sentence Pages escort kings, at some time the lemmas page and king will be selected. \n",
        "How to prevent the speaker from erroneously producing Kings escort pages? \n",
        "The selection mechanism should, in some way, bind a selected lemma to the appropriate concept. \n",
        "Similarly, at some later stage, the segments of the word forms \\<king\\> and \\<page\\> are spelled out. \n",
        "How to prevent the speaker from erroneously producing Cages escort pings? \n",
        "The system must keep track of /p/ belonging to pages and /k/ belonging to kings. \n",
        "In most existing models of word access (in particular that of Dell 1988 and Dell et al. 1993), the binding problem is solved by timing. \n",
        "The activation/deactivation properties of the lexical network guarantee that, usually, the “intended” elemenis the most activated one at the crucial moment.\n",
        "Exceptions precisely explain the occasional speech errors. \n",
        "Our solution (Roelofs 1992a; 1993; 1996b; 1997c) is a different one. \n",
        "It follows Bobrow and Winograd’s (1977) “procedural attachment to nodes.” \n",
        "Each node has a procedure attached to it that checks whether the node, when active, links up to the appropriate active node one level up. \n",
        "This mechanism will, for instance, discover that the activated syllable nodes [pIàz] and [k#I] do not correspnd to the word form nodes \\<kings\\> and \\<pages\\>, and hence should not be selected.\n",
        "For example, in the phonological encoding of kings, the /k/ but not the /p/ will be selected and syllabified, \n",
        "because /k/ is linked to \\<king\\> in the network and /p/ is not. \n",
        "In phonetic encoding, [kIàz] will be selected, because the links in the network between [kIàz] and its segmes correspond with the syllable positions assigned to these segments during phonological encoding.\n",
        "For instance, /k/ will be syllabified as onset, which corresponds to the link between /k/ and [kIàz] in the ntwork. \n",
        "We will call this “binding-by-checking” as opposed to “binding-by-timing.”\n",
        "\n",
        "A major reason for implementing binding-by-checking is the recurrent finding that, during picture naming, distractor stimuli hardly ever induce systematic speech errors.\n",
        "When the speaker names the picture of a king, and simultaneously hears the distractor word page, he or she will produce neither the semantic error page, nor the phonological error ping, although both the lemma page and the phoneme /p/ are strongly activated by the distractor. \n",
        "This fact is more easily handled by binding-by-checking than through binding-by-timing. \n",
        "A perfect binding-by-checking mechanism will, of course, prevent any speech error. \n",
        "A systematic  account of speech errors will require our theory to allow for lapses of binding, as in Shattuck-Hufnagel’s (1979)“ check off” approach.\n",
        "-->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1yWlGf9r91Xe"
      },
      "source": [
        "## A.4. Cohort size について Cheneval (2018)\n",
        "シミュレーション中では 変数 **FR** で扱われる"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nVsg1rWW91Xe"
      },
      "source": [
        "- 出典: The lexical or sub-lexical locus of facilitation by phonemic cueing in aphasic speakers: the effect of onset cohort size\n",
        "- author: Pauline Pellet Cheneval, Bertrand Glize, and Marina Laganaroa\n",
        "- journal: APHASIOLOGY\n",
        "- year: 2018\n",
        "- doi: <https://doi.org/10.1080/02687038.2017.1423273>\n",
        "\n",
        "### A.4.1. Materials and procedure\n",
        "Thirty-eight black-and-white line drawings of common objects and their corresponding nouns were selected from two French databases (Alario & Ferrand, 1999; Bonin, Peereman, Malardier, Méot, & Chalard, 2003) according to the word-onset phoneme. \n",
        "All items corresponded to bisyllabic words and were selected depending on the size of the lexical cohort of nouns beginning with the target phoneme: 19 items had a high noun-onset token frequency phoneme (over 19,000 nouns, “large noun onset cohort”) and 19 items started with a low noun-onset token-frequency phoneme (less than 15,200 nouns, “small noun onset cohort”) (Table 3). \n",
        "The two lists differ significantly only on noun onset cohort size ($t(7)=3.23$; $p=0.017$) and were balanced by picture-word name agreement, imageability, familiarity with the object, visual complexity of the corresponding picture, age of acquisition, lexical frequency, and phonological neighborhood (Appendix A). \n",
        "The items and the cueing conditions were pseudorandomly presented in three order of presentation and order were counter balanced across participants.\n",
        "\n",
        "ということなので，2音節のフランス語単語，38 語，19 語づつ，頻度大と頻度小\n",
        "\n",
        "<center>\n",
        "Appendix A. Description of the stimuli psycholinguistic characteristics by noun onset cohort size group.\n",
        "\n",
        "| |Name Agreement (%) |Imageability |Familiarity|Visual Complexity|Image variability |Age of Aquisition|Lexical Frequency|Phonological neighborhood |\n",
        "|---|---:|---:|---:|---:|---:|---:|---:|---:|    \n",
        "|Large word onset cohort|94.28 |3.71 |2.81 |2.88 |2.83 |2.16 |2082.26|19.21|\n",
        "|Small word onset cohort|93.36 |3.60 |2.61 |3.18 |2.96 |2.28 |1711.28|12.68|\n",
        "|t Test p-value |0.89 |0.85 |0.72 |0.75 |0.9 |0.93| 0.68| 0.37|\n",
        "</center>\n",
        "\n",
        "Appendix B. List of items and onset cohort size associated.\n",
        "* Target onset cohort size : small\n",
        "* Item: \n",
        "balai, ballon, banane, bougie, boussole, \n",
        "bouteille, bouton, fenêtre, flamand, fléchette, \n",
        "fusée, gâteau, grenouille, gant, tambour, \n",
        "tomate, tortue, toupie, tracteur\n",
        "\n",
        "ほうき, バルーン, バナナ, キャンドル, コンパス, \n",
        "ボトル, ボタン, ウィンドウ, フレミッシュ, ダーツ, \n",
        "ロケット, ケーキ, カエル, グローブ, ドラム, \n",
        "トマト, タートル, スピニングトップ, トラクター\n",
        "\n",
        "* Taget onset cohort size: large\n",
        "cactus, cigarette, cochon, collier, couronne,\n",
        "couteau, croissant, cuillère, dauphin, drapeau\n",
        "dindon, palmier, panier, poubelle, poumons\n",
        "poupée, seringue, serpent, souris\n",
        "\n",
        "サボテン、タバコ、豚、ネックレス、王冠、\n",
        "ナイフ、クロワッサン、スプーン、イルカ、旗\n",
        "七面鳥、ヤシの木、バスケット、ゴミ箱、肺\n",
        "人形、注射器、ヘビ、マウス\n",
        "\n",
        "<center>\n",
        "Table. 3 Distribution of stimuli according to the associated word-onset cohort size\n",
        "\n",
        "|   |Word-onset phoneme| Noun-onset cohort (per million nouns)|\n",
        "|---|--:|--:|\n",
        "|Large noun-onset cohort | k (N = 7) | 25ʹ120 |\n",
        "|   |p (N = 5) |33ʹ894|\n",
        "|   |s (N = 4) |21ʹ572|\n",
        "|   |d (N = 3) |19ʹ129|\n",
        "|   |  |(mean = 24ʹ929)|\n",
        "|Small noun-onset cohort| t (N = 5)| 15ʹ008|\n",
        "|   |b (N = 7) |15ʹ181|\n",
        "|   |f (N = 4) |13ʹ539|\n",
        "|   |g (N = 3) |6ʹ485|\n",
        "|   |          |(mean = 12ʹ553)|\n",
        "</center>\n",
        "\n",
        "\n",
        "<center>\n",
        "Table 2. Error rates and error distribution for each participant in all conditions.\n",
        "\n",
        "Lexico-semantic error\n",
        "\n",
        "|   |Errors % | Non-response | Phonological | Semantic | Error difference | |\n",
        "|---|---:|---:|---:|---:|---:|--:|\n",
        "|Subject|(N = 114)|errors % |errors %| errors % | (phono-sem)| |\n",
        "|P01|12% |44%| 0% |56% |−56%|\n",
        "|P05|20% |60%| 0% |40% |−40%||\n",
        "|P14| 8% |50%| 0%| 33% |−33%||\n",
        "|P11| 22%|12%|29%| 59% |−29%||\n",
        "|P02| 9% |43%|14%| 43% |−29%||\n",
        "|P09| 26%|35%|20%| 45% |−25%||\n",
        "|P04| 41%|77%| 0%| 23% |−23%||\n",
        "|*Mean*| 19.6%| 46%| 9%| 43%| −34%||\n",
        "\n",
        "Phonological error\n",
        "\n",
        "|   |Errors % | Non-response | Phonological | Semantic | Error difference | |\n",
        "|---|---:|---:|---:|---:|---:|--:|\n",
        "|P08| 39%| 43%| 33%| 23%| 10% |\n",
        "|P10| 33%| 48%| 32%| 20%| 12%|\n",
        "|P07| 29%| 68%| 23%| 9% | 14%|\n",
        "|P12| 7% | 80%| 20%| 0% | 20%|\n",
        "|P03| 13%| 20%| 50%| 30%| 20%|\n",
        "|P13| 9% | 43%| 43%| 14%| 29%|\n",
        "|P06| 9% | 29%| 71%| 0% |71%|\n",
        "|*Mean* |20%| 47%| 39%| 14%| 25%|\n",
        "    \n",
        "</center>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KL_UwUQI91Xe"
      },
      "source": [
        "<center>\n",
        "<img src=\"https://raw.githubusercontent.com/project-ccap/project-ccap.github.io/master/figures/2018Cheneval_fig3.svg\" style=\"width:66%\"><br/>\n",
        "    <div align=\"left\" style=\"width:66%\">\n",
        "    平均エラー率: 左2つの図は，意味性錯語，右は音韻性錯語，最左は低頻度，その右は高頻度。\n",
        "    中央左は，低頻度，最右は高頻度。 Cheneval(2018) Fig. 3\n",
        "    </div>\n",
        "</center>\n",
        "\n",
        "3 つの条件は以下:\n",
        "1. The **congruent cueing** condition: a video clip of a male person’s face pronouncing the word-onset phoneme of the picture-label word was displayed at the center of the screen before the picture. Each video clip lasted 1000 ms, including the initial closed-lip posture and the return to this lip configuration.\n",
        "2. The **incongruent cueing** condition: the items were preceded by a cue which was mismatched with the onset of the picture name. The incongruent cue was one of the phoneme associated with a small noun-onset cohort for items from the large noun-onset cohort and vice versa.\n",
        "3. The **control cueing** condition: a clip of the static face of a man was presented simultaneously with white noise for 1000 ms before the picture to be named.\n",
        "\n",
        "<center>\n",
        "<img src=\"https://raw.githubusercontent.com/project-ccap/project-ccap.github.io/master/figures/2018Cheneval_fig4.svg\" style=\"width:66%\"><br/>\n",
        "<center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2f3cTnCa91Xe"
      },
      "source": [
        "---\n",
        "\n",
        "# B. オリジナルソースコード  Original source code (Reolofs, 2019)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rdj4iUeh91Xe"
      },
      "source": [
        "```\n",
        "/***************************************************\n",
        " *                                                 *\n",
        " *  ANOMIA CUEING.C                                *\n",
        " *                                                 *\n",
        " *  SIMULATION OF WORD-FORM ENCODING IN SPEAKING   *\n",
        " *                                                 *\n",
        " *  Simulation of immediate and treatment effects  *\n",
        " *  of phonological cueing in anomia               *\n",
        " *                                                 *\n",
        " *  Journal: Aphasiology                           *\n",
        " *                                                 *\n",
        " *  Ardi Roelofs, September 2019                   *\n",
        " *                                                 *\n",
        " *  (C) Copyright DCC                              *\n",
        " *                                                 *\n",
        " ***************************************************/\n",
        "\n",
        " /*\n",
        "  A brief note on C and programming style:\n",
        "\n",
        "  This program is written in the C programming language, which is\n",
        "  described by Kernighan and Ritchie (1988) and many others. C was\n",
        "  chosen because it is among the most widely and frequently used\n",
        "  programming languages, and C programs can be compiled (using\n",
        "  freeware C and C++ compilers) for all main computer platforms\n",
        "  and operating systems.\n",
        "\n",
        "  Following Kernighan and Plauger's (1978) maxim \"write clearly\n",
        "  -- don't be too clever\", I avoided the use of pointers\n",
        "  and other initially somewhat obscure constructs to help readers\n",
        "  unfamiliar with C. Given that the program is rather small\n",
        "  (everything is in one file), I chose for external variables\n",
        "  that are globally accessible to all functions rather than\n",
        "  using function arguments and return values for communicating\n",
        "  data between functions. External variables are more convenient\n",
        "  and efficient here than long argument lists.\n",
        "\n",
        "  Kernighan, B.W., & Plauger, P.J. (1978). The Elements of\n",
        "  Programming Style (Second Edition). New York: McGraw Hill.\n",
        "\n",
        "  Kernighan, B.W., & Ritchie, D.M. (1988). The C Programming Language\n",
        "  (Second Edition). Englewood Cliffs, NJ: Prentice Hall.\n",
        " */\n",
        "\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <float.h>\n",
        "\n",
        "#define STEP_SIZE 25      /* duration time step in ms */\n",
        "#define N_STEPs  (1000+STEP_SIZE)/STEP_SIZE  \n",
        "                    /* Number of time steps: trunc after 41 steps */\n",
        "\n",
        "        /* Simulation of Nardo, Holland, Leff, Price, & Crinion (2017, Brain) */\n",
        "#define N_TESTs 2   /* Number of tests: BEFORE, AFTER treatment */\n",
        "#define N_CCONDs 4  /* Number of cue conditions: WHOLE, INITIAL, FINAL, NOISE */\n",
        "\n",
        "/* form network */\n",
        "#define N_MORPHEMEs 5\n",
        "#define N_PHONEMEs 10\n",
        "#define N_SYLLABLE_PROGRAMs 5\n",
        "#define Y 1.0    /* forward connection present */\n",
        "#define N 0.0    /* forward connection absent */\n",
        "\n",
        "/* names of cueing conditions */\n",
        "#define WHOLE 0\n",
        "#define INITIAL 1\n",
        "#define FINAL 2\n",
        "#define NOISE 3\n",
        "\n",
        "/* names of tests */\n",
        "#define BEFORE 0\n",
        "#define AFTER 1\n",
        "\n",
        "/* names of morphemes */\n",
        "#define mCAT 0\n",
        "#define mDOG 1\n",
        "#define mMAT 2\n",
        "#define mFOG 3\n",
        "#define mFISH 4\n",
        "\n",
        "/* names of phonemes */\n",
        "#define pK 0\n",
        "#define pE 1\n",
        "#define pT 2\n",
        "#define pD 3\n",
        "#define pO 4\n",
        "#define pG 5\n",
        "#define pM 6\n",
        "#define pF 7\n",
        "#define pI 8\n",
        "#define pS 9\n",
        "\n",
        "/* names of syllable programs */\n",
        "#define sCAT 0\n",
        "#define sDOG 1\n",
        "#define sMAT 2\n",
        "#define sFOG 3\n",
        "#define sFISH 4\n",
        "\n",
        "\n",
        " /* connections between morpheme nodes and phoneme nodes */\n",
        "double MP_con[N_MORPHEMEs][N_PHONEMEs] = {\n",
        "\t                 /* K  E  T  D  O  G  M  F  I  S */\n",
        "\t/* <cat>   */   {   Y, Y, Y, N, N, N, N, N, N, N },\n",
        "\t/* <dog>   */   {   N, N, N, Y, Y, Y, N, N, N, N },\n",
        "\t/* <mat>   */   {   N, Y, Y, N, N, N, Y, N, N, N },\n",
        "\t/* <fog>   */   {   N, N, N, N, Y, Y, N, Y, N, N },\n",
        "\t/* <fish>  */   {   N, N, N, N, N, N, N, Y, Y, Y }\n",
        "\n",
        "};\n",
        "\n",
        "\n",
        "/* connections between phoneme nodes and syllable program nodes */\n",
        "double PS_con[N_PHONEMEs][N_SYLLABLE_PROGRAMs] = {\n",
        "\t       /* Cat Dog  Mat Fog  Fish */\n",
        "\t/* K */ { Y,   N,   N,  N,   N },\n",
        "\t/* E */ { Y,   N,   Y,  N,   N },\n",
        "\t/* T */ { Y,   N,   Y,  N,   N },\n",
        "\t/* D */ { N,   Y,   N,  N,   N },\n",
        "\t/* O */ { N,   Y,   N,  Y,   N },\n",
        "\t/* G */ { N,   Y,   N,  Y,   N },\n",
        "\t/* M */ { N,   N,   Y,  N,   N },\n",
        "\t/* F */ { N,   N,   N,  Y,   Y },\n",
        "\t/* I */ { N,   N,   N,  N,   Y },\n",
        "\t/* S */ { N,   N,   N,  N,   Y }\n",
        "};\n",
        "\n",
        "\n",
        "\n",
        " double M_node_act[N_MORPHEMEs];\n",
        " double P_node_act[N_PHONEMEs]; \n",
        " double S_node_act[N_SYLLABLE_PROGRAMs]; \n",
        "\n",
        " /* input buffer */ \n",
        " double input_M[N_MORPHEMEs];\n",
        " double input_P[N_PHONEMEs];\n",
        " double input_S[N_SYLLABLE_PROGRAMs];\n",
        " \n",
        " int T;     /* time in ms */\n",
        "\n",
        " int test;        /* tests before vs. after treatment */\n",
        " int ccond;       /* cue condition: whole, initial, final, noise */\n",
        "\n",
        " /* parameter values */\n",
        " double LEX_rate = 0.0120 * STEP_SIZE;    /* prop per step_size ms */\n",
        " double DECAY_rate = 0.0240 * STEP_SIZE;  /* prop per step_size ms */\n",
        " double EXTIN = 0.1965 * STEP_SIZE;       /* act_units per step_size ms*/\n",
        " int    PHONEME_DURATION = 125;           /* ms */\n",
        " int    CORRECTION_MENTAL_SOA = 100;      /* ms */\n",
        " int    VER_TIME = 25;                    /* verification time, in ms */\n",
        " double FR = 0.10;  /* default 0.10; at 0.05 for Large cohort size\n",
        "\t\t\t\t\t   Pellet Cheneval, Glize, & Laganaro (2018, Aphasiology) */\n",
        " double THRESHOLD = 1.5;\n",
        "\n",
        " double ANOMIA_REDUCTION = 0.5; /* default 0.5; for BOLD, range 0.6, 0.5, 0.43, 0.4, 0.38 */\n",
        "\n",
        " int SIM_MEANS[N_TESTs][N_CCONDs];\n",
        "\n",
        "  \n",
        " int MORPH_DONE, SUPRA_DONE, SEG1_DONE, SEG2_DONE, SEG3_DONE;\n",
        " int SYLL_DONE, SYLLABIFIED;\n",
        "\n",
        " int morph_verification_time;\n",
        " int seg1_verification_time;\n",
        " int seg2_verification_time;\n",
        " int seg3_verification_time;\n",
        " int syllabification_time;\n",
        " int syllable_program_verification_time;\n",
        "\n",
        " double h[N_STEPs];\n",
        " double S[N_STEPs];\n",
        " double f[N_STEPs];\n",
        " double F[N_STEPs];\n",
        "\n",
        "\n",
        "void reset_network();\n",
        "void set_spreading_rates();\n",
        "void reset_spreading_rates();\n",
        "void update_network();\n",
        "void set_input_to_zero();\n",
        "void get_external_input();\n",
        "void get_internal_input();\n",
        "void update_activation_of_nodes();\n",
        "\n",
        "void reset_system();\n",
        "void reset_f_h_S_();\n",
        "void compute_prob_functions();\n",
        "void compute_hazard_rate();\n",
        "void compute_cumul_survival_function();\n",
        "void compute_density_function();\n",
        "double compute_expectation_of_RT_();\n",
        "\n",
        "void print_heading();\n",
        "void print_expectations_of_RT();\n",
        "\n",
        "\n",
        "/*****************\n",
        " * MAIN ROUTINES *\n",
        " *****************/\n",
        "\n",
        "main()\n",
        "{\n",
        "\treset_system();\n",
        "\n",
        "\tfor (test = 0; test < N_TESTs; test++) {\n",
        "\n",
        "\t\tset_spreading_rates();\n",
        "\n",
        "\t\tfor (ccond = 0; ccond < N_CCONDs; ccond++) {\n",
        "\n",
        "\t\t\tcompute_prob_functions();\n",
        "\t\t}\n",
        "\n",
        "\t    reset_spreading_rates();\n",
        "    }\n",
        "\n",
        "\tprint_heading();\n",
        "\tprint_expectations_of_RT();\n",
        "\n",
        " }\n",
        "\n",
        "\n",
        " void compute_prob_functions()\n",
        " {\n",
        "      reset_network();\n",
        "      reset_f_h_S_();\n",
        "\t   for(T = 0; T < 1000; T += STEP_SIZE) { \n",
        "\t     compute_hazard_rate();                 \n",
        "\t     update_network();\n",
        "\t     }              \n",
        "      compute_cumul_survival_function();\n",
        "      compute_density_function();\n",
        "      SIM_MEANS[test][ccond]= (int) compute_expectation_of_RT_();\n",
        "\n",
        " }\n",
        "\n",
        " /* Notice: hazard rates are computed before updating the network, that\n",
        "    is, on the basis of the activation state of the network achieved at\n",
        "    the previous time step */\n",
        "\n",
        "\n",
        "\n",
        " void reset_system()\n",
        " {\n",
        "     int h,i;\n",
        "\n",
        "\t for (h = 0; h < N_TESTs; h++)\n",
        "\t\t for (i = 0; i < N_CCONDs; i++)\n",
        "\t                  SIM_MEANS[h][i]=0;\n",
        " }\n",
        "\n",
        "\n",
        "\n",
        " void set_spreading_rates()\n",
        " {\n",
        "\t int i, j;\n",
        "\n",
        "\t for (i = 0; i < N_MORPHEMEs; i++)\n",
        "\t\t for (j = 0; j < N_PHONEMEs; j++)\n",
        "\t\t\t MP_con[i][j] *= LEX_rate;\n",
        "\n",
        "\n",
        "\t for (i = 0; i < N_PHONEMEs; i++)\n",
        "\t\t for (j = 0; j < N_SYLLABLE_PROGRAMs; j++)\n",
        "\t\t\t PS_con[i][j] *= LEX_rate;\n",
        "\n",
        "\t if (test == BEFORE) { /* untreated */\n",
        "\t\t /* impairment in phonological encoding */\n",
        "\t\t MP_con[mCAT][pK] *= ANOMIA_REDUCTION;\n",
        "\t\t MP_con[mCAT][pE] *= ANOMIA_REDUCTION;\n",
        "\t\t MP_con[mCAT][pT] *= ANOMIA_REDUCTION;\n",
        "\n",
        "     }\n",
        "\n",
        " }\n",
        "\n",
        "\n",
        " void reset_spreading_rates()\n",
        " {\n",
        "\n",
        "   int i,j;\n",
        "\n",
        "  for(i=0;i<N_MORPHEMEs;i++)\n",
        "     for(j=0;j<N_PHONEMEs;j++) \n",
        "\tMP_con[i][j]*=(1.0/LEX_rate);\n",
        " \n",
        "\n",
        "  for(i=0;i<N_PHONEMEs;i++)\n",
        "     for(j=0;j<N_SYLLABLE_PROGRAMs;j++) \n",
        "\tPS_con[i][j]*=(1.0/LEX_rate);\n",
        "  \n",
        "  \n",
        "  if (test == BEFORE) { /* untreated */\n",
        "\n",
        "\t  MP_con[mCAT][pK] = 1.0;\n",
        "\t  MP_con[mCAT][pE] = 1.0;\n",
        "\t  MP_con[mCAT][pT] = 1.0;\n",
        "  }\n",
        "\n",
        " }\n",
        "\n",
        "\n",
        " void reset_network()\n",
        " {\n",
        "   int i;\n",
        "\n",
        "   MORPH_DONE = 0;\n",
        "   SEG1_DONE = 0;\n",
        "   SEG2_DONE = 0;\n",
        "   SEG3_DONE = 0;\n",
        "   SYLL_DONE = 0;\n",
        "   SYLLABIFIED = 0;\n",
        "\n",
        "   morph_verification_time = VER_TIME;\n",
        "   seg1_verification_time = VER_TIME;\n",
        "   seg2_verification_time = VER_TIME;\n",
        "   seg3_verification_time = VER_TIME;\n",
        "   syllabification_time = 2 * VER_TIME;\n",
        "   syllable_program_verification_time = VER_TIME;\n",
        "\n",
        "\n",
        "  for(i=0;i<N_MORPHEMEs;i++) \n",
        "     M_node_act[i]=0.0;\n",
        "  \n",
        "   for(i=0;i<N_PHONEMEs;i++) \n",
        "     P_node_act[i]=0.0;\n",
        "   \n",
        "   for(i=0;i<N_SYLLABLE_PROGRAMs;i++) \n",
        "     S_node_act[i]=0.0;\n",
        "\n",
        " }\n",
        "\n",
        "\n",
        "/*****************************\n",
        " * NETWORK UPDATING ROUTINES *\n",
        " *****************************/\n",
        "\n",
        " void update_network()\n",
        " {\n",
        "   set_input_to_zero();\n",
        "   get_external_input();\n",
        "   get_internal_input();\n",
        "   update_activation_of_nodes();\n",
        " }\n",
        "\n",
        "\n",
        " void set_input_to_zero()\n",
        " {\n",
        "   int i;\n",
        "\n",
        "   for(i=0;i<N_MORPHEMEs;i++) \n",
        "       input_M[i]=0.0;\n",
        " \n",
        "   for(i=0;i<N_PHONEMEs;i++) \n",
        "       input_P[i]=0.0;\n",
        "\n",
        "   for(i=0;i<N_SYLLABLE_PROGRAMs;i++) \n",
        "       input_S[i]=0.0;\n",
        "\n",
        " }\n",
        "\n",
        "\n",
        " void get_external_input()\n",
        " {\n",
        "\n",
        "    /* target input */\n",
        "    if(T >= CORRECTION_MENTAL_SOA ) {\n",
        "\n",
        "\t/* target gets input from lemma */\n",
        "\t   input_M[mCAT]+= 1.0 * EXTIN; /* at 0.8 for Meteyard & Bose (2018, JSLHR) */\n",
        "    } \n",
        "\n",
        " \n",
        "\n",
        "    /* input from cue */\n",
        "\n",
        "    if(ccond==WHOLE) {\n",
        " \n",
        "      if((0 <= T) && (T < PHONEME_DURATION)) {\n",
        "\n",
        "\t         input_P[pK]+=EXTIN;\n",
        "             input_M[mCAT]+= FR * EXTIN;\n",
        "      }\n",
        "\n",
        "      if((PHONEME_DURATION <= T) \n",
        "          && (T < (2 * PHONEME_DURATION))) {\n",
        "\n",
        "\t         input_P[pE]+=EXTIN;\n",
        "             input_M[mCAT]+= FR * EXTIN;\n",
        "      }\n",
        "\n",
        "\n",
        "     if((2 * PHONEME_DURATION <= T) \n",
        "         && (T < (3 * PHONEME_DURATION))) {\n",
        " \n",
        "\t         input_P[pT]+= EXTIN;\n",
        "             input_M[mCAT]+= FR * EXTIN;\n",
        "      }\n",
        "\n",
        "    }\n",
        "\n",
        "\n",
        "\tif (ccond == INITIAL) {\n",
        "\n",
        "\t\tif ((0 <= T) && (T < PHONEME_DURATION)) {\n",
        "\n",
        "\t\t\t\tinput_P[pK] += EXTIN;\n",
        "\t\t\t\tinput_M[mCAT] += FR * EXTIN;\n",
        "\t\t}\n",
        "\n",
        "\t\tif ((PHONEME_DURATION <= T)\n",
        "\t\t\t&& (T < (2 * PHONEME_DURATION))) {\n",
        "\n",
        "\t\t\t\tinput_P[pE] += EXTIN;\n",
        "\t\t\t\tinput_M[mCAT] += FR * EXTIN;\n",
        "\t\t}\n",
        "\n",
        "\t}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\tif (ccond == FINAL) {\n",
        "\n",
        "\t\tif ((0 <= T) && (T < PHONEME_DURATION)) {\n",
        "\n",
        "\t\t\t\tinput_P[pE] += EXTIN;\n",
        "\t\t\t\tinput_M[mCAT] += FR * EXTIN;\n",
        "\t\t\t\tinput_M[mMAT] += FR * EXTIN;\n",
        "\t\t}\n",
        "\n",
        "\t\tif ((PHONEME_DURATION <= T)\n",
        "\t\t\t&& (T < (2 * PHONEME_DURATION))) {\n",
        "\n",
        "\t\t\t\tinput_P[pT] += EXTIN;\n",
        "\t\t\t\tinput_M[mCAT] += FR * EXTIN;\n",
        "\t\t\t\tinput_M[mMAT] += FR * EXTIN;\n",
        "\t\t}\n",
        "\n",
        "\t}\n",
        "\n",
        "\n",
        "\n",
        " }\n",
        "\n",
        "\n",
        " void get_internal_input()\n",
        " {\n",
        "   int i,j;\n",
        "\n",
        "   for(i=0;i<N_MORPHEMEs;i++)\n",
        "     for(j=0;j<N_PHONEMEs;j++) \n",
        "\tinput_P[j]+=( M_node_act[i] * MP_con[i][j] );\n",
        "\n",
        " \n",
        "  for(i=0;i<N_PHONEMEs;i++)\n",
        "     for(j=0;j<N_SYLLABLE_PROGRAMs;j++) \n",
        "\tinput_S[j]+=( P_node_act[i] * PS_con[i][j] );\n",
        " }\n",
        "\n",
        "\n",
        " void update_activation_of_nodes()\n",
        " {\n",
        "   int i;\n",
        "\n",
        "   for(i=0;i<N_MORPHEMEs;i++) \n",
        "       M_node_act[i]=((M_node_act[i] * (1.0 - DECAY_rate)) + input_M[i]);\n",
        "       \n",
        "    for(i=0;i<N_PHONEMEs;i++) \n",
        "       P_node_act[i]=((P_node_act[i] * (1.0 - DECAY_rate)) + input_P[i]);\n",
        "       \n",
        "   for(i=0;i<N_SYLLABLE_PROGRAMs;i++) \n",
        "       S_node_act[i]=((S_node_act[i] * (1.0 - DECAY_rate)) + input_S[i]);\n",
        "\n",
        " }\n",
        "\n",
        "\n",
        "/*********************************************************\n",
        " *  HAZARD-, CUMUL_SURVIVAL-, PROBABILITY MASS FUNCTION  *\n",
        " *********************************************************/\n",
        "\n",
        "/*\n",
        "    h[1] denotes hazard rate at first time step,\n",
        "    h[2] denotes hazard rate at second time step, etc.,\n",
        "    where h[s] is a function (expressed by the Luce ratio) of the\n",
        "    activation levels at moment T equal to (s-1) * STEP_SIZE (where s=1,2,...)\n",
        "\n",
        "    f[1] denotes prob of selection at first time step, etc;\n",
        "    that is, f[s] is the probability that the retrieval latency\n",
        "    equals s x STEP_SIZE;\n",
        "    e.g., f[2] is the probability that the retrieval latency equals\n",
        "    2 x STEP_SIZE, i.e., 2 x 25 ms = 50 ms.\n",
        "*/\n",
        "\n",
        " void compute_hazard_rate()\n",
        " {\n",
        "     \n",
        " \n",
        "  if( T > CORRECTION_MENTAL_SOA) { \n",
        "\n",
        "                   if( S_node_act[sCAT] > THRESHOLD && SYLLABIFIED )\n",
        "\t\t\t  /* Zero THRESHOLD for excluding locus in phonetic encoding */\n",
        "                       syllable_program_verification_time -= STEP_SIZE;\n",
        "                       if(syllable_program_verification_time == 0)    \n",
        "                         SYLL_DONE = 1;\n",
        "\n",
        "                  if( SEG1_DONE && SEG2_DONE && SEG3_DONE)\n",
        "                       syllabification_time -= STEP_SIZE;\n",
        "                       if(syllabification_time == 0) \n",
        "                         SYLLABIFIED = 1;\n",
        "\n",
        "                   if( P_node_act[pT] > THRESHOLD && MORPH_DONE)\n",
        "                       seg3_verification_time -= STEP_SIZE;\n",
        "                       if(seg3_verification_time == 0)    \n",
        "                         SEG3_DONE = 1;\n",
        "\n",
        "                   if( P_node_act[pE] > THRESHOLD && MORPH_DONE)    \n",
        "                       seg2_verification_time -= STEP_SIZE;\n",
        "                       if(seg2_verification_time == 0)    \n",
        "                         SEG2_DONE = 1;\n",
        "\n",
        "                   if( P_node_act[pK] > THRESHOLD && MORPH_DONE)    \n",
        "                       seg1_verification_time -= STEP_SIZE;\n",
        "                       if(seg1_verification_time == 0)    \n",
        "                         SEG1_DONE = 1;\n",
        "\n",
        "\n",
        "\n",
        "                   if(M_node_act[mCAT] > THRESHOLD) \n",
        "\t\t\t    /* Zero THRESHOLD for excluding locus in morphological encoding */\n",
        "                       morph_verification_time -= STEP_SIZE;\n",
        "                       if(morph_verification_time == 0)\n",
        "                         MORPH_DONE = 1;\n",
        "\n",
        "  }\n",
        "\n",
        "\n",
        "   if(SYLL_DONE) {\n",
        "\n",
        "       if(T > CORRECTION_MENTAL_SOA)\n",
        "\n",
        "\t     /* in denominator all syllable program nodes */\n",
        "\t\t   /* harard rate at 1.0 for excluding locus in phonetic encoding */\n",
        "\t    h[(T/STEP_SIZE)+1] = S_node_act[sCAT]  /\n",
        "\t\t\t       ( S_node_act[sCAT]\n",
        "\t\t\t       + S_node_act[sDOG]\n",
        "\t\t\t       + S_node_act[sMAT]\n",
        "\t\t\t       + S_node_act[sFOG] \n",
        "                   + S_node_act[sFISH] );\n",
        "\n",
        "\t else\n",
        "\t    h[(T/STEP_SIZE)+1] = 0.0;\n",
        "    }  \n",
        " }\n",
        "\n",
        "\n",
        " void compute_cumul_survival_function()\n",
        " {\n",
        "     int j,s;\n",
        "     double aux;\n",
        "\n",
        "     /* NOTE: cum_survival or S[s] is upto and including s */\n",
        "\n",
        "     for(s=0;s<N_STEPs;s++) {\n",
        "       for(j=0, aux=1.0;j<=s;j++)\n",
        "\t  aux*=(1.0-h[j]);\n",
        "       S[s]=aux;\n",
        "       }\n",
        " }\n",
        "\n",
        " void compute_density_function()\n",
        " {\n",
        "     int s;\n",
        "\n",
        "     /* NOTE: Prob(not selected before step s) equals S[s-1], that is\n",
        "\tsurviving upto and including the previous time step */\n",
        "\n",
        "     for(s=1;s<N_STEPs;s++)\n",
        "       f[s]=h[s] * S[s-1];\n",
        "\n",
        "     /* NOTE: f[0] will always be 0, so is not computed */\n",
        "\n",
        " \n",
        "}\n",
        "\n",
        "\n",
        " double compute_expectation_of_RT_()\n",
        " {\n",
        "     int s;\n",
        "     double mean=0.0;\n",
        "\n",
        "     for(s=0;s<N_STEPs;s++)\n",
        "\t  mean+=f[s] * s * STEP_SIZE;\n",
        "\n",
        "     return mean;\n",
        " }\n",
        "\n",
        "\n",
        " void reset_f_h_S_()\n",
        " {\n",
        "    int s;\n",
        "\n",
        "    for(s=0;s<N_STEPs;s++) {\n",
        "      f[s]=0.0;\n",
        "      h[s]=0.0;\n",
        "      S[s]=0.0;\n",
        "      F[s]=0.0;\n",
        "      }\n",
        " }\n",
        "\n",
        "\n",
        "\n",
        "/*****************\n",
        " *  I/0 ROUTINES *\n",
        " *****************/\n",
        "\n",
        " void print_heading()\n",
        " {\n",
        "\tprintf(\"\\nSimulation of Immediate and Treatment Effects of Phonological Cueing in Anomia (c) Ardi Roelofs\\n\");\n",
        "\tprintf(\"\\nworking...\\n\");\n",
        " }\n",
        "\n",
        "\n",
        " void print_expectations_of_RT()\n",
        " {\n",
        "\n",
        "\n",
        "\t\t  printf(\"             Untreated                     Treated  \\n\");\n",
        "\t\t  printf(\"             Whole Initial Final Noise     Whole Initial Final Noise \\n\");\n",
        "\n",
        "\t\t  printf(\"            %4d   %4d   %4d    %4d    %4d   %4d   %4d    %4d  [ms]\\n\",\n",
        "\t\t\t  SIM_MEANS[BEFORE][WHOLE],\n",
        "\t\t\t  SIM_MEANS[BEFORE][INITIAL],\n",
        "\t\t\t  SIM_MEANS[BEFORE][FINAL],\n",
        "\t\t\t  SIM_MEANS[BEFORE][NOISE],\n",
        "\t\t\t  SIM_MEANS[AFTER][WHOLE],\n",
        "\t\t\t  SIM_MEANS[AFTER][INITIAL],\n",
        "\t\t\t  SIM_MEANS[AFTER][FINAL],\n",
        "\t\t\t  SIM_MEANS[AFTER][NOISE]);\n",
        "\n",
        "\t\t  printf(\"Cue effect: %4d   %4d   %4d            %4d   %4d   %4d    \\n\",\n",
        "\n",
        "\t\t\t  SIM_MEANS[BEFORE][WHOLE] - SIM_MEANS[BEFORE][NOISE],\n",
        "\t\t\t  SIM_MEANS[BEFORE][INITIAL] - SIM_MEANS[BEFORE][NOISE],\n",
        "\t\t\t  SIM_MEANS[BEFORE][FINAL] - SIM_MEANS[BEFORE][NOISE],\n",
        "\t\t\t  SIM_MEANS[AFTER][WHOLE] - SIM_MEANS[AFTER][NOISE],\n",
        "\t\t\t  SIM_MEANS[AFTER][INITIAL] - SIM_MEANS[AFTER][NOISE],\n",
        "\t\t\t  SIM_MEANS[AFTER][FINAL] - SIM_MEANS[AFTER][NOISE]);\n",
        "\n",
        "\t  \n",
        "\t\t  printf(\"Treatment effect: %4d [ms]  \\n\", SIM_MEANS[BEFORE][NOISE] - SIM_MEANS[AFTER][NOISE]);\n",
        "\n",
        "\n",
        "\n",
        "     printf(\"\\nParameter values:\\n\");\n",
        "     printf(\"mental corr : %6d [ms]\\n\", CORRECTION_MENTAL_SOA);\n",
        "     printf(\"lex_rate    : %.4f [prop per ms]\\n\",LEX_rate /STEP_SIZE);\n",
        "     printf(\"exin        : %.4f [act_units per ms]\\n\",EXTIN / STEP_SIZE);\n",
        "     printf(\"d           : %.4f [prop per ms]\\n\",DECAY_rate / STEP_SIZE);\n",
        "     printf(\"phoneme_du  : %6d [ms]\\n\",PHONEME_DURATION );\n",
        "\n",
        "\n",
        "\n",
        "     printf(\"\\nPress <RET> to continue \");\n",
        "\n",
        "     getchar(); \n",
        " }\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJyOwtF_91Xe"
      },
      "source": [
        ""
      ],
      "execution_count": 11,
      "outputs": []
    }
  ]
}