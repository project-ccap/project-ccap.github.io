{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "colab": {
      "name": "2021Roelofs_Conceptual_bias.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/project-ccap/project-ccap.github.io/blob/master/notebooks/2021Roelofs_Conceptual_bias.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YBenXQFRqOW5"
      },
      "source": [
        "- title: A unified computational account of cumulative semantic, semantic blocking, and semantic distractor effects in picture naming\n",
        "- Journal: Cognition\n",
        "- author: Ardi Roelofs\n",
        "- date: November 2017\n",
        "- doi: <https://doi.org/10.1016/j.cognition.2017.12.007>\n",
        "- Original filename: CONCEPTUAL BIAS.C\n",
        "- url: https://osf.io/6ysp2/\n",
        "\n",
        "\n",
        "# 概念バイアスシミュレーション, Roelofs (2017)\n",
        "\n",
        "- original source: Conceptual_Bias.c\n",
        "- filename: 2021Roelofs_Conceptual_bias.ipynb\n",
        "- date: 2020-0101\n",
        "- author: Shin Asakawa <asakawa@ieee.org>\n",
        "\n",
        "## 概要\n",
        "\n",
        "絵画命名課題における語彙選択の反応時間のシミュレーションモデルを 3 つの課題で検証: \n",
        "1. 連続命名課題\n",
        "2. 条件群ごと命名課題\n",
        "3. 絵画-言語 意味干渉課題\n",
        "上記 3 課題の統一的な計算論的説明を WEAVER++ モデル(Levelt, Roelofs, & Meyer, 1999) を用いて試みた。\n",
        "概念バイアスを含めることで、意味干渉効果，累積的な意味効果，意味的ブロッキング効果を説明。\n",
        "\n",
        "前提：\n",
        "* 競争による語彙選択\n",
        "* 意味的効果の概念的起源と語彙的機嫌\n",
        "心理実験データと神経画像学的証拠を取り上げ，3 課題の意味効果の統一的な説明\n",
        "\n",
        "- note: SIMULATION OF LEMMA RETRIEVAL IN SPEAKING,  Simulation of cumulative semantic and semantic blocking effects\n",
        "- 要約:\n",
        "    > 音声言語生成における語彙選択の計算モデルは，連続呼称，ブロック循環呼称，画像-単語干渉の各パラダイムで得られた画像-単語呼称応答時間における意味干渉効果に適用されてきた。\n",
        "しかし，この 3 つのパラダイムの効果に関する統一的な計算論的説明は欠如している。\n",
        "ここでは，WEAVER++ モデル (Levelt, Roelofs, & Meyer, 1999) に概念的バイアスを含めることで，意味的混乱効果に関するモデルの説明を維持したまま，意味累積効果および意味ブロック効果を説明できることを示す。\n",
        "このモデルの主要な仮定は以下の通りである。\n",
        "(1) 競合による語彙選択 (2) 意味効果の概念的起源と語彙的位置。\n",
        "この説明の概念実証として，コンピュータ・シミュレーションの結果を報告し，行動学的，神経画像学的な証拠に言及する。\n",
        "この仮定は，この分野の悲観的な見解に反して，3 つのパラダイムにおける意味効果の統一的な説明として十分である。\n",
        "\n",
        "<!-- Computational models of lexical selection in spoken word production have been applied to semantic interference effects in picture naming response times obtained with continuous naming, blocked-cyclic naming, and picture-word interference paradigms. \n",
        "However, a unified computational account of the effects in the three paradigms is lacking. \n",
        "Here, I show that the inclusion of conceptual bias in the WEAVER++ model (Levelt, Roelofs, & Meyer, 1999) explains cumulative semantic and semantic blocking effects while preserving the model's account of semantic distractor effects. \n",
        "The key assumptions of the account are \n",
        "(1) lexical selection by competition, and (2) a conceptual origin and lexical locus of the semantic effects. \n",
        "I provide a proof of concept of the account by reporting computer simulation results, addressing behavioral and neuroimaging evidence. \n",
        "The assumptions are sufficient for a unified account of semantic effects in the three paradigms, contrary to pessimistic views of this area.-->\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8MjOQOFTqOXB"
      },
      "source": [
        "import numpy as np\n",
        "import sys\n",
        "import os\n",
        "\n",
        "# 表示精度桁数の設定\n",
        "np.set_printoptions(suppress=False, formatter={'float': '{:7.4f}'.format})\n",
        "np.set_printoptions(suppress=False, formatter={'float': '{:6.3f}'.format})\n",
        "np.set_printoptions(suppress=False, formatter={'float': '{:4.2f}'.format})\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from IPython.display import SVG, display\n",
        "#display(SVG(filename='../figures/2018Roelofs_fig1.svg'))\n",
        "#display(SVG(filename='../figures/2018Roelofs_fig3.svg'))\n",
        "\n",
        "print('概念モデル')\n",
        "display(SVG(url='https://raw.githubusercontent.com/project-ccap/project-ccap.github.io/master/figures/2018Roelofs_fig3.svg'))\n",
        "\n",
        "print('\\n\\n\\n実験手続きの外観')\n",
        "display(SVG(url='https://raw.githubusercontent.com/project-ccap/project-ccap.github.io/master/figures/2018Roelofs_fig1.svg'))\n",
        "\n",
        "\n",
        "#display(SVG(url='https://raw.githubusercontent.com/project-ccap/project-ccap.github.io/master/figures/2018Roelofs_fig4ab.svg'))\n",
        "#display(SVG(url='https://raw.githubusercontent.com/project-ccap/project-ccap.github.io/master/figures/2018Roelofs_fig4cd.svg'))\n",
        "#display(SVG(url='https://raw.githubusercontent.com/project-ccap/project-ccap.github.io/master/figures/2018Roelofs_fig5.svg'))\n",
        "\n",
        "\n",
        "print('以下に元となった Blake (2013) の実験結果を示す')\n",
        "display(SVG(url='https://raw.githubusercontent.com/project-ccap/project-ccap.github.io/master/figures/2013Belke_fig2.svg'))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5JeOF6xqOXC"
      },
      "source": [
        "STEP_SIZE = 25\n",
        "N_STEPs = int((1000+STEP_SIZE)/STEP_SIZE)  # /* trunc after 41 steps */\n",
        "N_CONCEPTs = 6  # fork, spoon, cup, glass, knife, manmade \n",
        "N_LEMMAs = 6    # Gabel, Loffel, Tasse, Glas, Messer, KUENSTLICH\n",
        "N_GENDERs = 3   # 男性，女性，中性\n",
        "N_BUTTONs = 2   # 人工物，自然物\n",
        "N_TASKs = 5     # 絵画命名，絵画分類，単語命名，冠詞付き単語命名，絵画命名fMRI\n",
        "N_POSs = 5      # ordinal position\n",
        "Y = 1.0         # connection present\n",
        "N = 0.0         # connection absent\n",
        "PICTURE_NAMING = 0          # Belke (2013, JML), Exp 1.\n",
        "PICTURE_CLASSIFICATION = 1  # manmade, natural\n",
        "WORD_NAMING = 2\n",
        "WORD_NAMING_WITH_DET = 3\n",
        "PICTURE_NAMING_fMRI = 4 # BOLD response, Canini et al. (2016, HBM)\n",
        "task_l = ('PICTURE_NAMING',  'PICTURE_CLASSIFICATION',  'WORD_NAMING',\\\n",
        "          'WORD_NAMING_WITH_DET', 'PICTURE_NAMING_fMRI')\n",
        "\n",
        "#PICTURE_NAMING, PICTURE_CLASSIFICATION, WORD_NAMING, \\\n",
        "#WORD_NAMIMG_WITH_DET, PICTURE_NAMING_fMRI = 0, 1, 2, 3, 4\n",
        "tasks = ('PICTURE_NAMING', 'PICTURE_CLASSIFICATION', 'WORD_NAMING', \n",
        "         'WORD_NAMIMG_WITH_DET', 'PICTURE_NAMING_fMRI')\n",
        "\n",
        "\n",
        "# Labeling network nodes\n",
        "# Concepts\n",
        "FORK, SPOON, CUP, GLASS, KNIFE, MANMADE = 0, 1, 2, 3, 4, 5\n",
        "concept_l = ('FORK', 'SPOON', 'CUP', 'GLASS', 'KNIFE', 'MANMADE')\n",
        "\n",
        "# German lemmas\n",
        "#fork, sppon,    cup, glass, knife, manmake\n",
        "GABEL, LOFFEL, TASSE, GLAS, MESSER, KUENSTLICH = 0, 1, 2, 3, 4, 5\n",
        "lemma_l = ('GABEL', 'LOFFEL', 'TASSE', 'GLAS', 'MESSER', 'KUENSTLICH')\n",
        "\n",
        "# Grammatical genders\n",
        "# masculine, feminine, neuter\n",
        "MASC, FEM, NEUTER = 0, 1, 2\n",
        "gender_l = ('MASC', 'FEM', 'NEUTER')\n",
        "\n",
        "# /* Button nodes */\n",
        "B_MANMADE, B_NATURAL = 0, 1  # Button 1: manmade, Button 2: natural\n",
        "button_l = ('B_MANMADE', 'B_NATURAL')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TTy-QYITqOXC"
      },
      "source": [
        "def make_weights(N_CONCEPTs=N_CONCEPTs):\n",
        "    CONC_con = np.zeros((N_CONCEPTs, N_CONCEPTs), dtype=np.float)  # double CONC_con[N_CONCEPTs][N_CONCEPTs];\n",
        "\n",
        "    # Connections conceptual network for categorical relations\n",
        "    CATEG_con = np.array([\n",
        "        [N, Y, Y, Y, Y, Y],  # FORK\n",
        "        [Y, N, Y, Y, Y, Y],  # SPOON\n",
        "        [Y, Y, N, Y, Y, Y],  # CUP\n",
        "        [Y, Y, Y, N, Y, Y],  # GLASS\n",
        "        [Y, Y, Y, Y, N, Y],  # KNIFE\n",
        "        [Y, Y, Y, Y, Y, N]   # MANMADE\n",
        "    ])\n",
        "\n",
        "    # Connections conceptual network for thematic relations\n",
        "    ASSOC_con = np.array([\n",
        "        [N, N, N, N, N, Y],  # CHURCH\n",
        "        [N, N, N, N, N, Y],  # RING \n",
        "        [N, N, N, N, N, Y],  # DRESS\n",
        "        [N, N, N, N, N, Y],  # CAKE\n",
        "        [N, N, N, N, N, Y],  # BOUQUET\n",
        "        [Y, Y, Y, Y, Y, N],  # WEDDING\n",
        "    ])\n",
        "\n",
        "    # Connections between concept and lemma nodes\n",
        "    # Lemma nodes are Gabel, Loffel, Tasse, Glas, Messer (and kuenstlich [manmade]) \n",
        "    # for the category \"tableware\" of Belke (2013, JML), \n",
        "    # and Kirche, Ring, Brautkleid, Torte, Blumenstrauss (and Hochzeit) for the theme \"wedding\"\n",
        "    # of Rose & Abdel Rahman (2016, Cognition)\n",
        "    LEM_con = np.array([\n",
        "        [Y, N, N, N, N, N],  # Gabel フォーク  ，教会\n",
        "        [N, Y, N, N, N, N],  # Loffel スプーン ，指輪\n",
        "        [N, N, Y, N, N, N],  # Tasse カップ   ，ドレス\n",
        "        [N, N, N, Y, N, N],  # Glas グラス    ，ケーキ\n",
        "        [N, N, N, N, Y, N],  # Messer ナイフ  ，花束\n",
        "        [N, N, N, N, N, Y],  # Kuenstlich 人工物，結婚式\n",
        "    ])\n",
        "\n",
        "    # Connections between lemma and gender nodes\n",
        "    GEN_con = np.array([ # MASC, FEM, NEUTER\n",
        "        [N, Y, N],  # GABEL フォークは女性\n",
        "        [Y, N, N],  # LOFFEL スプーンは男性\n",
        "        [N, Y, N],  # TASSE  カップは女性\n",
        "        [N, N, Y],  # GLAS   グラスは中性\n",
        "        [N, N, Y],  # MESSER ナイフは中性\n",
        "        [N, N, N],  # KUENSTLICH\n",
        "    ])\n",
        "\n",
        "    # Connections between concept and button nodes\n",
        "    BUTTON_con = np.array([ # B_MANMADE B_NATURAL\n",
        "        [N, N], # Fork\n",
        "        [N, N], # Spoon\n",
        "        [N, N], # Cup\n",
        "        [N, N], # Glass\n",
        "        [N, N], # Knife\n",
        "        [Y, N], # Manmade\n",
        "    ])\n",
        "    \n",
        "    weights = {'CONC': CONC_con,\n",
        "               'CATEG': CATEG_con,\n",
        "               'ASSOC': ASSOC_con,\n",
        "               'LEM': LEM_con,\n",
        "               'GEN': GEN_con,\n",
        "               'BUTTON': BUTTON_con}\n",
        "    \n",
        "    return weights\n",
        "\n",
        "\n",
        "def make_layers():\n",
        "    return {'concept': node(N_CONCEPTs), \n",
        "            'lemma': node(N_LEMMAs), \n",
        "            'gender': node(N_GENDERs), \n",
        "            'button': node(N_BUTTONs)}\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "27gZlo72qOXD"
      },
      "source": [
        "pos = 0  # int pos;   /* ordinal position, i.e., 1 to 5 (in C is 0 to 4) */\n",
        "T = 0    # int T;     /* time in ms */\n",
        "#task = 0 # int task;  /* PICTURE NAMING, PICTURE CLASSIFICATION, WORD NAMING, \n",
        "#         # WORD NAMIMG WITH DET, PICTURE_NAMING_fMRI */\n",
        "\n",
        "# Parameter set plus values\n",
        "CONC_rate = 0.5 * 0.0101 * STEP_SIZE  # double CONC_rate = 0.5 * 0.0101 * STEP_SIZE;   \n",
        "                                      # 0.5 of default prop per step_size ms \n",
        "                                      # because of the increased size of conceptual\n",
        "                                      # network, cf. Roelofs (2003, Psych. Rev.) */\n",
        "LEM_rate = 0.0074 * STEP_SIZE   # prop per step_size ms\n",
        "DECAY_rate = 0.0240 * STEP_SIZE # prop per step_size ms\n",
        "EXTIN = 0.1965 * STEP_SIZE      # act_units per step_size ms\n",
        "CRIT_DIFF = 0.0                 # act_units\n",
        "BIAS = 2.5                      #\n",
        "BLOCKED_CYCLIC = False          # 1 = run for blocked-cyclic naming\n",
        "PREV_BIAS = 0.0                 # previous bias\n",
        "# The PREV_BIAS parameter is needed for simulating blocked-cyclic\n",
        "# naming, because the bias increase during a cycle is also present \n",
        "# during the next cycle. To run the model for blocked-cyclic naming,\n",
        "# set the PREV_BIAS values by hand for each new cycle.\n",
        "# Previous bias in \n",
        "# cycle 1: 0.0, \n",
        "# cycle 2: 2.5, \n",
        "# cycle 3: 5.0, \n",
        "# cycle 4: 7.5, \n",
        "# cycle 5: 10.0, \n",
        "# cycle 6: 12.5\n",
        "# The semantic blocking effect in a cycle is the mean increase over\n",
        "# ordinal positions relative to the first position. The effect of bias\n",
        "# for the first ordinal position is the same for the homogeneous and \n",
        "# the heterogeneous conditions. For later ordinal positions, the bias \n",
        "# effect will differ between conditions because the position effect\n",
        "# occurs only within categories or themes (thus only in the homogeneous\n",
        "# condition).\n",
        "\n",
        "class node():\n",
        "    \"\"\"# Here a network node is defined, having an activation level,\n",
        "    # and an input buffer; its output is equal to its activation\n",
        "    # struct node { \n",
        "    #\t double act;    # 出力\n",
        "    #\t double input;  # 入力\n",
        "    # } concept[N_CONCEPTs], lemma[N_LEMMAs], gender[N_GENDERs], button[N_BUTTONs];\n",
        "    \"\"\"\n",
        "    def __init__(self, n):\n",
        "        self.input = np.zeros((n,), dtype=np.float)\n",
        "        self.output = np.zeros((n,), dtype=np.float)\n",
        "\n",
        "    def update(self, decay=DECAY_rate):\n",
        "        self.output = (1.0 - decay) * self.output + self.input\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.input)\n",
        "    \n",
        "    def clear_all(self):\n",
        "        self.input.fill(0.)\n",
        "        self.output.fill(0.)\n",
        "        \n",
        "    def clear_output(self):\n",
        "        self.output.fill(0.)\n",
        "        \n",
        "    def clear_input(self):\n",
        "        self.input.fill(0.)\n",
        "        \n",
        "\n",
        "#TAXONOMIC = 1  # categorical relatedness, Belke (2013, Journal of Memory and Language)\n",
        "#THEMATIC = 0   # thematic relatedness, Rose & Abdel Rahman (2016, Cognition)\n",
        "\n",
        "# The parameter values for the critical difference [selection threshold] \n",
        "# for the different tasks: default: all values the same\n",
        "CRITICAL_DIFFS = {\n",
        "    'CD_PN': 1.6,  # Picture naming\n",
        "    'CD_PC': 1.6,  # Picture classification\n",
        "    'CD_WR': 1.6,  # Word reading  \n",
        "}\n",
        "#CD_PN = 1.6  # Picture nameing\n",
        "#CD_PC = 1.6  # Picture classification\n",
        "#CD_WR = 1.6  # Word reading "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_tzbqlvNqOXF"
      },
      "source": [
        "#/*****************\n",
        "# * MAIN ROUTINES *\n",
        "# *****************/\n",
        "def main(relation='TAXONOMIC', Critical_Diffs=CRITICAL_DIFFS, graph=False):  \n",
        "    # relation = {'TAXONOMIX' or 'THEMATIC'}\n",
        "    # TAXONOMIC: categorical relatedness, Belke (2013, Journal of Memory and Language)\n",
        "    # THEMATIC: thematic relatedness, Rose & Abdel Rahman (2016, Cognition)\n",
        "    \n",
        "    # The parameter values for the critical difference [selection threshold] \n",
        "    # for the different tasks: default: all values the same\n",
        "    # CRITICAl_DIFFS = {\n",
        "    #  'CD_PN': 1.6,  # Picture naming\n",
        "    #  'CD_PC': 1.6,  # Picture classification\n",
        "    #  'CD_WR': 1.6,  # Word reading  \n",
        "    # }\n",
        "\n",
        "    SIM = np.zeros((N_TASKs, N_POSs), dtype=np.float)\n",
        "    BOLD = np.zeros((N_TASKs, N_POSs), dtype=np.float)\n",
        "    \n",
        "    # control flags for production rule application, \n",
        "    # cf. EPIC, Meyer & Kieras, Psych. Rev. 1997\n",
        "    flags = {'CONCEPT': False, \n",
        "             'ENHANCE_CONCEPT': False, \n",
        "             'LEMMA': False, \n",
        "             'GENDER': False, \n",
        "             'CATEGORY_CONCEPT': False, \n",
        "             'BUTTON_NODE': False }\n",
        "    \n",
        "    W = make_weights()\n",
        "    Layers = make_layers()\n",
        "    \n",
        "    for task in tasks:\n",
        "        i_task = tasks.index(task)\n",
        "        # 課題 task を順に実行\n",
        "        #print_heading()\n",
        "        \n",
        "        # 課題ごとのパラメータ設定\n",
        "        # CRIT_DIFF: Critical difference の意味\n",
        "        CRIT_DIFF = set_task_dependent_parameters(task, Critical_Diffs)\n",
        "        #SIM, BOLD = reset_system(task, SIM, BOLD)\n",
        "        SIM[i_task].fill(0); BOLD[i_task].fill(0.)\n",
        "        \n",
        "        # 結合係数行列の設定\n",
        "        W = set_spreading_rates(W, relation='TAXONOMIC')\n",
        "        \n",
        "        # シミュレーション本体\n",
        "        SIM, BOLD = compute_POS_functions(task, Layers, W, flags, SIM, BOLD, CRIT_DIFF)\n",
        "        print_expectations_of_RT(task, SIM, BOLD, graph=graph)\n",
        "        \n",
        "        # 結合係数行列をリセット\n",
        "        W = reset_spreading_rates(W, CONC_rate, LEM_rate)\n",
        "\n",
        "\n",
        "def compute_POS_functions(task, Layers, W, flags, SIM, BOLD, CRIT_DIFF):\n",
        "    \"\"\"シミュレーション本体\"\"\"\n",
        "    mass = np.zeros((N_STEPs,), dtype=np.float)\n",
        "    hazard = np.zeros((N_STEPs,), dtype=np.float)\n",
        "    Survival = np.zeros((N_STEPs,), dtype=np.float)\n",
        "    \n",
        "    i_task = tasks.index(task)\n",
        "\n",
        "    for pos in range(N_POSs):  # 各位置ごとに繰り返す\n",
        "        mass, hazard, Survival = reset_f_h_S_(mass, hazard, Survival)\n",
        "        Layers = reset_network(Layers)\n",
        "        flags = reset_production_rule_system(flags)\n",
        "        \n",
        "        # stop for lemma retrieval latency > 1000 ms\n",
        "        for T in range(0, 1000, STEP_SIZE):\n",
        "            hazard = compute_hazard_rate(T, task, flags, Layers, W, hazard, CRIT_DIFF)\n",
        "            Layers = update_network(task, pos, Layers, W, flags)\n",
        "            flags = apply_production_rules(task, flags, Layers)\n",
        "        \n",
        "        Survival = compute_cumul_survival_function(hazard, Survival)\n",
        "        mass = compute_mass_function(mass, hazard, Survival)\n",
        "        SIM[i_task][pos] = compute_expectation_of_RT_(mass)\n",
        "\n",
        "    if task == 'PICTURE_NAMING_fMRI':\n",
        "        BOLD = compute_BOLD(task, SIM, BOLD)\n",
        "    return SIM, BOLD\n",
        "\n",
        "    \n",
        "def reset_system(task, SIM, BOLD):\n",
        "    i = task_l.index(task)\n",
        "    for j in range(N_POSs):\n",
        "        SIM[i][j] = 0\n",
        "\n",
        "    for j in range(N_POSs):\n",
        "        BOLD[i][j] = 0.0\n",
        "        \n",
        "    return SIM, BOLD\n",
        "\n",
        "\n",
        "def set_spreading_rates(W, relation='TAXONOMIC'):\n",
        "\n",
        "    # Sets the conceptual connections for categorical reations\n",
        "    if relation == 'TAXONOMIC':\n",
        "        W['CONC'] = np.copy(W['CATEG'])\n",
        "\n",
        "    # Sets the conceptual connections for thematic reations\n",
        "    if relation == 'THEMATIC':\n",
        "        W['CONC'] = np.copy(W['ASSOC'])\n",
        "\n",
        "    # Sets the strengths of the connections\n",
        "    W['CONC'] *= CONC_rate\n",
        "    W['LEM'] *= LEM_rate\n",
        "    W['GEN'] *= LEM_rate\n",
        "    W['BUTTON'] *= LEM_rate\n",
        "    \n",
        "    return W\n",
        "\n",
        "\n",
        "def set_task_dependent_parameters(task, Critical_Diffs):\n",
        "\n",
        "    if task == 'PICTURE_NAMING':\n",
        "        return Critical_Diffs['CD_PN']\n",
        "    elif task == 'PICTURE_CLASSIFICATION':\n",
        "        return Critical_Diffs['CD_PC']\n",
        "    elif task == 'WORD_NAMING':\n",
        "        return Critical_Diffs['CD_WR']\n",
        "    elif task == 'WORD_NAMING_WITH_DET':\n",
        "        return Critical_Diffs['CD_WR']\n",
        "    elif task == 'PICTURE_NAMING_fMRI':\n",
        "        return Critical_Diffs['CD_PN']\n",
        "\n",
        "\n",
        "def reset_spreading_rates(W, CONC_rate, LEM_rate):\n",
        "    \"\"\"\n",
        "    Needed, because otherwise in later tasks rates become a \n",
        "    proportion of earlier ones; this routine keeps them fixed\n",
        "    \"\"\"\n",
        "    W['CONC'] *= 1.0/CONC_rate\n",
        "    W['LEM'] *= 1.0/LEM_rate\n",
        "    W['GEN'] *= 1.0/LEM_rate\n",
        "    W['BUTTON'] *= 1.0/LEM_rate\n",
        "    \n",
        "    return W\n",
        "        \n",
        "\n",
        "def reset_network(Layers):\n",
        "    for x in Layers:\n",
        "        Layers[x].clear_output()\n",
        "    return Layers\n",
        "\n",
        "\n",
        "def reset_production_rule_system(flags):\n",
        "    \"\"\"reset control flags in working memory\"\"\"\n",
        "    flags['CONCEPT'] = False\n",
        "    flags['ENHANCE_CONCEPT'] = False\n",
        "    flags['LEMMA'] = False\n",
        "    flags['GENDER'] = False\n",
        "    flags['CATEGORY_CONCEPT'] = False\n",
        "    flags['BUTTON_NODE'] = False\n",
        "    return flags\n",
        "\n",
        "\n",
        "def apply_production_rules(task, flags, Layers):\n",
        "\n",
        "    # Production rule application for picture naming\n",
        "    # here the lemma of Gabel for the selected concept FORK is flagged\n",
        "    if (task=='PICTURE_NAMING' or task=='PICTURE_NAMING_fMRI') \\\n",
        "    and flags['CONCEPT'] and (Layers['lemma'].output[GABEL] > 0):\n",
        "        flags['LEMMA'] = True\n",
        "\n",
        "    # here the concept FORK is flagged for selection and enhancement \n",
        "    #          cf. P1 in Roelofs, 2003, Psych. Rev., p. 100\n",
        "    if (task=='PICTURE_NAMING' or task=='PICTURE_NAMING_fMRI') \\\n",
        "    and Layers['concept'].output[FORK]:\n",
        "        flags['CONCEPT'] = True\n",
        "        flags['ENHANCE_CONCEPT'] = True\n",
        "\n",
        "    # production rule application for picture classification \n",
        "    # here the button node for the category concept MAN-MADE is flagged \n",
        "    if task=='PICTURE_CLASSIFICATION' and flags['CATEGORY_CONCEPT'] \\\n",
        "    and (Layers['button'].output[B_MANMADE] > 0):\n",
        "        flags['BUTTON_NODE'] = True\n",
        "\n",
        "    # here the category concept MAN-MADE for the concept FORK is flagged \n",
        "    if task=='PICTURE_CLASSIFICATION' \\\n",
        "    and flags['CONCEPT'] \\\n",
        "    and (Layers['concept'].output[MANMADE] > 0):\n",
        "        flags['CATEGORY_CONCEPT'] = True\n",
        "\n",
        "    # here the concept FORK is flagged\n",
        "    if task=='PICTURE_CLASSIFICATION' \\\n",
        "    and (Layers['concept'].output[FORK] > 0):\n",
        "        flags['CONCEPT'] = True\n",
        "\n",
        "    # Production rule application for word reading \n",
        "    # here the lemma of Gabel is flagged \n",
        "    if task=='WORD_NAMING' and (Layers['lemma'].output[GABEL] > 0):\n",
        "        flags['LEMMA'] = True\n",
        "\n",
        "    # Production rule application for word reading with gender-marked determiner \n",
        "    # here the gender of the lemma of Gabel is flagged \n",
        "    if task=='WORD_NAMING_WITH_DET' \\\n",
        "    and flags['LEMMA'] \\\n",
        "    and (Layers['gender'].output[FEM] > 0):\n",
        "        flags['GENDER'] = True\n",
        "\n",
        "    # here the lemma of Gabel is flagged\n",
        "    if task=='WORD_NAMING_WITH_DET' \\\n",
        "    and (Layers['lemma'].output[GABEL] > 0):\n",
        "        flags['LEMMA'] = True\n",
        "        \n",
        "    return flags\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YfKTefF0qOXH"
      },
      "source": [
        "#/*********************\n",
        "# * UPDATING ROUTINES *\n",
        "# *********************/\n",
        "def update_network(task, pos, Layers, W, flags):\n",
        "    \n",
        "    for x in Layers.keys():\n",
        "        Layers[x].clear_input()\n",
        "\n",
        "    Layers = get_external_input(task, pos, Layers, W, flags)\n",
        "    Layers = get_internal_input(Layers, W)\n",
        "    Layers = update_activation_of_nodes(Layers, W)\n",
        "    return Layers\n",
        "\n",
        "\n",
        "def set_input_to_zero(concept, lemma, gender, button):\n",
        "    concept.clear_input()\n",
        "    lemma.clear_input()\n",
        "    gender.clear_input()\n",
        "    button.clear_input()\n",
        "    \n",
        "    return concept, lemma, gender, button\n",
        "\n",
        "\n",
        "def get_external_input(task, pos, Layers, W, flags):\n",
        "    \n",
        "    # picture input\n",
        "    if pos==0 and (task=='PICTURE_NAMING' or task=='PICTURE_CLASSIFICATION' or task=='PICTURE_NAMING_fMRI'):\n",
        "        Layers['concept'].input[FORK] += PREV_BIAS + EXTIN\n",
        "\n",
        "    if pos==1 and (task=='PICTURE_NAMING' or task=='PICTURE_CLASSIFICATION' or task=='PICTURE_NAMING_fMRI'):\n",
        "        Layers['concept'].input[FORK]  += PREV_BIAS + EXTIN\n",
        "        Layers['concept'].input[SPOON] += PREV_BIAS + BIAS   # bias position \"2\"\n",
        "\n",
        "    if pos==2 and (task=='PICTURE_NAMING' or task=='PICTURE_CLASSIFICATION' or task=='PICTURE_NAMING_fMRI'):\n",
        "        Layers['concept'].input[FORK] += PREV_BIAS + EXTIN\n",
        "        Layers['concept'].input[SPOON] += PREV_BIAS + BIAS   # bias position \"2\"\n",
        "        Layers['concept'].input[CUP] += (PREV_BIAS + BIAS)   # bias position \"3\"\n",
        "\n",
        "    if pos==3 and (task=='PICTURE_NAMING' or task=='PICTURE_CLASSIFICATION' or task=='PICTURE_NAMING_fMRI'):\n",
        "        Layers['concept'].input[FORK] += PREV_BIAS + EXTIN\n",
        "        Layers['concept'].input[SPOON] += PREV_BIAS + BIAS  # bias position \"2\"\n",
        "        Layers['concept'].input[CUP] += PREV_BIAS + BIAS    # bias position \"3\"\n",
        "        Layers['concept'].input[GLASS] += PREV_BIAS + BIAS  # bias position \"4\"\n",
        "\n",
        "    if pos==4 and (task=='PICTURE_NAMING' or task=='PICTURE_CLASSIFICATION' or task=='PICTURE_NAMING_fMRI'): \n",
        "        Layers['concept'].input[FORK] += PREV_BIAS + EXTIN\n",
        "        Layers['concept'].input[SPOON] += PREV_BIAS + BIAS    # bias position \"2\"\n",
        "        Layers['concept'].input[CUP] += PREV_BIAS + BIAS      # bias position \"3\"\n",
        "        Layers['concept'].input[GLASS] += PREV_BIAS + BIAS    # bias position \"4\"\n",
        "        Layers['concept'].input[KNIFE] += PREV_BIAS + BIAS    # bias position \"5\"\n",
        "\n",
        "    # Target concept gets activation enhancement\n",
        "    if (task=='PICTURE_NAMING' or task=='PICTURE_NAMING_fMRI') and flags['ENHANCE_CONCEPT']:\n",
        "        Layers['concept'].input[FORK] += 1.0 * EXTIN\n",
        "\n",
        "    # word input\n",
        "    if task=='WORD_NAMING' or task=='WORD_NAMING_WITH_DET':\n",
        "        Layers['lemma'].input[GABEL] += EXTIN\n",
        "\n",
        "    if pos==1 and task=='WORD_NAMING_WITH_DET':\n",
        "        Layers['concept'].input[SPOON] += BIAS  # bias position \"2\"\n",
        "\n",
        "    if pos==2 and task=='WORD_NAMING_WITH_DET':\n",
        "        Layers['concept'].input[SPOON] += BIAS  # bias position \"2\"\n",
        "        Layers['concept'].input[CUP] += BIAS    # bias position \"3\"\n",
        "\n",
        "    if pos==3 and task=='WORD_NAMING_WITH_DET':\n",
        "        Layers['concept'].input[SPOON] += BIAS  # bias position \"2\"\n",
        "        Layers['concept'].input[CUP] += BIAS    # bias position \"3\"\n",
        "        Layers['concept'].input[GLASS] += BIAS  # bias position \"4\"\n",
        "\n",
        "    if pos==4 and task=='WORD_NAMING_WITH_DET':\n",
        "        Layers['concept'].input[SPOON] += BIAS  # bias position \"2\"\n",
        "        Layers['concept'].input[CUP] += BIAS    # bias position \"3\"\n",
        "        Layers['concept'].input[GLASS] += BIAS  # bias position \"4\"\n",
        "        Layers['concept'].input[KNIFE] += BIAS  # bias position \"5\"\n",
        "\n",
        "    return Layers\n",
        "\n",
        "\n",
        "def get_internal_input(Layers, W):\n",
        "\n",
        "    for i in range(N_CONCEPTs):\n",
        "        for j in range(N_CONCEPTs):\n",
        "            Layers['concept'].input[i] +=  (Layers['concept'].output[j] * W['CONC'][j][i]) + (Layers['lemma'].output[j] * W['LEM'][j][i]) \n",
        "\n",
        "    #print('lemma    input', end=\"\"); print(Layers['lemma'].input)\n",
        "    #print('lemma   output', end=\"\"); print(Layers['lemma'].output)\n",
        "    #print('concept  input', end=''); print(Layers['concept'].input)\n",
        "    #print('concept output', end=''); print(Layers['concept'].output)\n",
        "    #print('W:\\n', W['LEM'])\n",
        "    for i in range(N_LEMMAs):\n",
        "        for j in range(N_CONCEPTs):\n",
        "            Layers['lemma'].input[i] += Layers['concept'].output[j] * W['LEM'][j][i]\n",
        "\n",
        "    #print('lemma    input', end=\"\"); print(Layers['lemma'].input)\n",
        "    #print('lemma   output', end=\"\"); print(Layers['lemma'].output)\n",
        "\n",
        "    for i in range(N_GENDERs):\n",
        "        for j in range(N_LEMMAs):\n",
        "            Layers['gender'].input[i] += Layers['lemma'].output[j] * W['GEN'][j][i]\n",
        "\n",
        "    for i in range(N_BUTTONs):\n",
        "        for j in range(N_CONCEPTs):\n",
        "            Layers['button'].input[i] += Layers['concept'].output[j] * W['BUTTON'][j][i]\n",
        "\n",
        "    return Layers\n",
        "\n",
        "\n",
        "def update_activation_of_nodes(Layers, W):\n",
        "    Layers['concept'].update()\n",
        "    Layers['lemma'].update()\n",
        "    Layers['gender'].update()\n",
        "    Layers['button'].update()\n",
        "    \n",
        "    return Layers\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WDnbYJy9qOXI"
      },
      "source": [
        "#/*********************************************************\n",
        "# *  HAZARD-, CUMUL_SURVIVAL-, MASS-FUNCTION ROUTINES     *\n",
        "# *********************************************************/\n",
        "\n",
        "def compute_hazard_rate(T, task, flags, Layers, W, hazard, CRIT_DIFF):\n",
        "\n",
        "    if T >= 0:\n",
        "        tau = int(T/STEP_SIZE) + 1\n",
        "\n",
        "        if task=='PICTURE_NAMING' or task=='PICTURE_NAMING_fMRI':\n",
        "            if flags['LEMMA'] \\\n",
        "            and ((Layers['lemma'].output[GABEL] - Layers['lemma'].output[LOFFEL]) > CRIT_DIFF) \\\n",
        "            and ((Layers['lemma'].output[GABEL] - Layers['lemma'].output[TASSE]) > CRIT_DIFF) \\\n",
        "            and ((Layers['lemma'].output[GABEL] - Layers['lemma'].output[GLAS])  > CRIT_DIFF) \\\n",
        "            and ((Layers['lemma'].output[GABEL] - Layers['lemma'].output[MESSER]) > CRIT_DIFF):\n",
        "                hazard[tau] = Layers['lemma'].output[GABEL] / Layers['lemma'].output.sum()\n",
        "                # the denominator consists of semantic cohort memmbers\n",
        "            else:\n",
        "                hazard[tau] = 0.\n",
        "\n",
        "        elif task == 'WORD_NAMING':\n",
        "            if flags['LEMMA'] \\\n",
        "            and ((Layers['lemma'].output[GABEL] - Layers['lemma'].output[LOFFEL]) > CRIT_DIFF) \\\n",
        "            and ((Layers['lemma'].output[GABEL] - Layers['lemma'].output[TASSE]) > CRIT_DIFF) \\\n",
        "            and ((Layers['lemma'].output[GABEL] - Layers['lemma'].output[GLAS])  > CRIT_DIFF) \\\n",
        "            and ((Layers['lemma'].output[GABEL] - Layers['lemma'].output[MESSER]) > CRIT_DIFF):\n",
        "                hazard[tau] = Layers['lemma'].output[GABEL] / Layers['lemma'].output.sum()\n",
        "                # the denominator consists of semantic cohort memmbers \n",
        "            else:\n",
        "                hazard[tau] = 0.\n",
        "\n",
        "        elif task == 'WORD_NAMING_WITH_DET':\n",
        "            if (flags['LEMMA'] and flags['GENDER']) \\\n",
        "            and ((Layers['lemma'].output[GABEL] - Layers['lemma'].output[LOFFEL]) > CRIT_DIFF) \\\n",
        "            and ((Layers['lemma'].output[GABEL] - Layers['lemma'].output[TASSE]) > CRIT_DIFF) \\\n",
        "            and ((Layers['lemma'].output[GABEL] - Layers['lemma'].output[GLAS]) > CRIT_DIFF) \\\n",
        "            and ((Layers['lemma'].output[GABEL] - Layers['lemma'].output[MESSER]) > CRIT_DIFF) \\\n",
        "            and ((Layers['gender'].output[FEM]) > CRIT_DIFF):\n",
        "                hazard[tau] = Layers['lemma'].output[GABEL] / Layers['lemma'].output.sum()\n",
        "            else:\n",
        "                hazard[tau] = 0.\n",
        "\n",
        "\n",
        "        elif task == 'PICTURE_CLASSIFICATION':\n",
        "            if flags['BUTTON_NODE'] \\\n",
        "            and (Layers['button'].output[B_MANMADE] - Layers['button'].output[B_NATURAL] > CRIT_DIFF):\n",
        "                # In simulating picture classification with vocal\n",
        "                # responding (Riley et al. 2015, FiP), the buttons would\n",
        "                # become the corresponding lemmas\n",
        "                hazard[tau] = 1.\n",
        "            else:\n",
        "                hazard[tau] = 0.\n",
        "            \n",
        "    return hazard\n",
        "\n",
        "\n",
        "def compute_cumul_survival_function(hazard, Survival):\n",
        "    \"\"\"NOTE: cum_survival or S[s] is upto and including s\"\"\"\n",
        "    for s in range(N_STEPs):\n",
        "        aux = 1.0\n",
        "        for j in range(s+1):\n",
        "            aux *= (1.0 - hazard[j])\n",
        "        Survival[s] = aux\n",
        "    return Survival\n",
        "\n",
        "\n",
        "def compute_mass_function(mass, hazard, Survival):\n",
        "    \"\"\"\n",
        "    NOTE: Prob(not selected before step s) equals S[s-1], that is\n",
        "    surviving upto and including the previous time step\n",
        "    \"\"\"\n",
        "    # NOTE: f[0] will always be 0, so does not have to be computed\n",
        "    for s in range(1, N_STEPs):\n",
        "        mass[s] = hazard[s] * Survival[s-1]\n",
        "    return mass\n",
        "\n",
        "\n",
        "def compute_expectation_of_RT_(mass):\n",
        "    mean = 0.\n",
        "    for s in range(N_STEPs):\n",
        "        mean += mass[s] * s * STEP_SIZE\n",
        "\n",
        "    return mean\n",
        "\n",
        "\n",
        "def reset_f_h_S_(mass_f, hazard, Survival):\n",
        "    mass_f.fill(0.); hazard.fill(0.); Survival.fill(0.)\n",
        "    #for s in range(N_STEPs):\n",
        "    #    f[s] = 0.0\n",
        "    #    h[s] = 0.0\n",
        "    #    S[s] = 0.0\n",
        "    return mass_f, hazard, Survival\n",
        "\n",
        "        \n",
        "def compute_BOLD(task, SIM, BOLD):\n",
        "    i_task = tasks.index(task)\n",
        "    for j in range(N_POSs):\n",
        "        # 6.0 means the intercept estimated from Canini et al. (2016)\n",
        "        # 4.5 means slope estimated from Canini et al. (2016)\n",
        "        BOLD[i_task][j] = 6.0 + (SIM[i_task][j] - SIM[i_task][0]) * 4.5 / (SIM[i_task][4] - SIM[i_task][0])\n",
        "    \n",
        "    return BOLD"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x6xipjqIqOXI"
      },
      "source": [
        "#/*****************\n",
        "# *  I/0 ROUTINES *\n",
        "# *****************/\n",
        "def print_heading():\n",
        "    print(\"Simulation of Lemma Retrieval in Speaking  (c) Ardi Roelofs\")\n",
        "    #print(\"working...\\n\")\n",
        "\n",
        "\n",
        "def print_expectations_of_RT(task, SIM, BOLD, BLOCKED_CYCLIC=False, graph=False):\n",
        "\n",
        "    if task == 'PICTURE_NAMING': \n",
        "        print(\"# Picture Naming\", task)\n",
        "    elif task == 'PICTURE_CLASSIFICATION': \n",
        "        print(\"\\n# Picture - Semantic Classification\", task)\n",
        "    elif task == 'WORD_NAMING': \n",
        "        print(\"\\n# Word Naming\", task)\n",
        "    elif task == 'WORD_NAMING_WITH_DET':\n",
        "        print(\"\\n# Word Naming With Gender-Marked Determiner (Transfer)\", task)\n",
        "    elif task == 'PICTURE_NAMING_fMRI': \n",
        "        print(\"\\n# Picture Naming fMRI\", task)\n",
        "\n",
        "    i_task = tasks.index(task)\n",
        "    print(\"  POSITION   LATENCY    EFFECT\")\n",
        "    for j in range(N_POSs):\n",
        "        print('{:6d} '.format(j+1), end='')\n",
        "        print(\"       {0:3.0f}        {1:3.0f}\".format(SIM[i_task][j], SIM[i_task][j] - SIM[i_task][0]))\n",
        "    \n",
        "    tot_latency = 0.\n",
        "    tot_effect = 0.\n",
        "    if BLOCKED_CYCLIC:\n",
        "        for j in range(N_POSs):\n",
        "            tot_latency += SIM[i_task][j]\n",
        "            tot_effect += SIM[i_task][j] - SIM[i_task][0]\n",
        "        #print(\"Cycle mean  {0:6d}    {1:6d}\".format(tot_latency/5, tot_effect/5)) \n",
        "        print(\"Cycle mean  {0}    {1}\".format(tot_latency/5, tot_effect/5)) \n",
        "\n",
        "    if task == 'PICTURE_NAMING_fMRI':\n",
        "        print(\"  POSITION   BOLD\")\n",
        "        for j in range(N_POSs):\n",
        "            print(\"{:6d}\".format(j+1), end=\"\")\n",
        "            print(\"     {:6.2f}\".format(BOLD[i_task][j]))\n",
        "\n",
        "    if task == 'PICTURE_NAMING':\n",
        "        print(\"\\n  Parameter values:\")\n",
        "        print(\"  concept_rate  : {:.4f} [prop/ms]\".format(CONC_rate/STEP_SIZE))\n",
        "        print(\"  lemma_rate    : {:.4f} [prop/ms]\".format(LEM_rate/STEP_SIZE))\n",
        "        print(\"  external input: {:.4f} [act_units/ms]\".format(EXTIN/STEP_SIZE))\n",
        "        print(\"  decay rate    : {:.4f} [prop/ms]\".format(DECAY_rate/STEP_SIZE))\n",
        "        print(\"  crit_diff     : {:.4f} [act_units]\".format(CRIT_DIFF))\n",
        "        print(\"  bias          : {:.4f} [act_units]\".format(BIAS))\n",
        "        \n",
        "        \n",
        "    if graph:\n",
        "        X = np.zeros((N_POSs), dtype=np.int)\n",
        "        _max, _min = np.iinfo(np.uint64).min, np.iinfo(np.uint64).max\n",
        "        for j in range(N_POSs):\n",
        "            _X = SIM[i_task][j] - SIM[i_task][0]\n",
        "            if _X > _max:\n",
        "                _max = _X\n",
        "            if _X < _min:\n",
        "                _min = _X\n",
        "            X[j] = _X\n",
        "        #print('X:', X)\n",
        "        plt.plot(X, '-', X, 'go')\n",
        "        plt.axis([-0.5, 4.5, _min-50, _max+50])\n",
        "        plt.ylabel('Latency effect (ms)')\n",
        "        plt.xlabel('Ordinal postion within category')\n",
        "        plt.title('{0:}'.format(task))\n",
        "        #plt.legend()\n",
        "        plt.show()\n",
        "        \n",
        "    #printf(\"\\npress any key to continue \");\n",
        "    #getchar();\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uAOO0xQQqOXI"
      },
      "source": [
        "#CRITICAL_DIFFS['CD_PN'] = 0.1\n",
        "#CRITICAL_DIFFS['CD_PC'] = 0.2\n",
        "#CRITICAL_DIFFS['CD_WN'] = 0.01\n",
        "#CRITICAL_DIFFS\n",
        "#main(Critical_Diffs=CRITICAL_DIFFS, graph=True)\n",
        "main(graph=True)\n",
        "#main()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NWj02PeXqOXI"
      },
      "source": [
        "# output expected\n",
        "```text\n",
        "Simulation of Lemma Retrieval in Speaking  (c) Ardi Roelofs\n",
        "\n",
        "  Picture Naming\n",
        "\n",
        "  POSITION   LATENCY    EFFECT\n",
        "     1         106         0\n",
        "     2         119        13\n",
        "     3         130        24\n",
        "     4         141        35\n",
        "     5         150        44\n",
        "\n",
        "Parameter values:\n",
        "conc_rate : 0.0050 [prop/ms]\n",
        "lem_rate  : 0.0074 [prop/ms]\n",
        "exin      : 0.1965 [act_units/ms]\n",
        "d         : 0.0240 [prop/ms]\n",
        "cd        : 1.6000 [act_units]\n",
        "bias      : 2.5000 [act_units]\n",
        "\n",
        "  Picture - Semantic Classification\n",
        "  POSITION   LATENCY    EFFECT\n",
        "     1         250         0\n",
        "     2         200       -50\n",
        "     3         175       -75\n",
        "     4         175       -75\n",
        "     5         150      -100\n",
        "\n",
        "  Word Naming\n",
        "  POSITION   LATENCY    EFFECT\n",
        "     1          50         0\n",
        "     2          50         0\n",
        "     3          50         0\n",
        "     4          50         0\n",
        "     5          50         0\n",
        "\n",
        "  Word Naming With Gender-Marked Determiner (Transfer)\n",
        "  POSITION   LATENCY    EFFECT\n",
        "     1         100         0\n",
        "     2         103         3\n",
        "     3         107         7\n",
        "     4         111        11\n",
        "     5         115        15\n",
        "\n",
        "  Picture Naming fMRI\n",
        "  POSITION   LATENCY    EFFECT\n",
        "     1         106         0\n",
        "     2         119        13\n",
        "     3         130        24\n",
        "     4         141        35\n",
        "     5         150        44\n",
        "  POSITION   BOLD\n",
        "     1      6.00   \n",
        "     2      7.33   \n",
        "     3      8.45   \n",
        "     4      9.58   \n",
        "     5      10.50   \n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hHYcwJFRqOXI"
      },
      "source": [
        "# 以下は オリジナルソースコード\n",
        "\n",
        "```C++\n",
        "/***************************************************\n",
        " *                                                 *\n",
        " *  CONCEPTUAL BIAS.C                              *\n",
        " *                                                 *\n",
        " *  SIMULATION OF LEMMA RETRIEVAL IN SPEAKING      *\n",
        " *                                                 *\n",
        " *  Simulation of cumulative semantic and          *\n",
        " *  semantic blocking effects                      *\n",
        " *                                                 *\n",
        " *  Journal: Cognition                             *\n",
        " *                                                 *\n",
        " *  Ardi Roelofs, November 2017                    *\n",
        " *                                                 *\n",
        " *  (C) Copyright DCC                              *\n",
        " *                                                 *\n",
        " ***************************************************/\n",
        "\n",
        " /*\n",
        "  A brief note on C and programming style:\n",
        " \n",
        "  This program is written in the C programming language, which is\n",
        "  described by Kernighan and Ritchie (1988) and many others. C was \n",
        "  chosen because it is among the most widely and frequently used \n",
        "  programming languages, and C programs can be compiled (using \n",
        "  freeware C and C++ compilers) for all main computer platforms \n",
        "  and operating systems. \n",
        "  \n",
        "  Following Kernighan and Plauger's (1978) maxim \"write clearly \n",
        "  -- don't be too clever\", I avoided the use of pointers\n",
        "  and other initially somewhat obscure constructs to help readers \n",
        "  unfamiliar with C. Given that the program is rather small \n",
        "  (everything is in one file), I chose for external variables \n",
        "  that are globally accessible to all functions rather than \n",
        "  using function arguments and return values for communicating\n",
        "  data between functions. External variables are more convenient\n",
        "  and efficient here than long argument lists.\n",
        "\n",
        "  Kernighan, B.W., & Plauger, P.J. (1978). The Elements of\n",
        "  Programming Style (Second Edition). New York: McGraw Hill.\n",
        "\n",
        "  Kernighan, B.W., & Ritchie, D.M. (1988). The C Programming Language\n",
        "  (Second Edition). Englewood Cliffs, NJ: Prentice Hall.\n",
        " */\n",
        "\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <float.h>\n",
        "\n",
        "\n",
        "#define STEP_SIZE 25   /* duration time step in ms */\n",
        "#define N_STEPs (1000+STEP_SIZE)/STEP_SIZE /* trunc after 41 steps */\n",
        "#define N_CONCEPTs 6\n",
        "#define N_LEMMAs 6\n",
        "#define N_GENDERs 3\n",
        "#define N_BUTTONs 2\n",
        "#define N_TASKs 5\n",
        "#define N_POSs 5 /* ordinal position*/\n",
        "#define Y 1.0   /* connection present */\n",
        "#define N 0.0   /* connection absent */\n",
        "#define PICTURE_NAMING 0 /* Belke (2013, JML), Exp 1. */\n",
        "#define PICTURE_CLASSIFICATION 1 /* manmade, natural */\n",
        "#define WORD_NAMING 2\n",
        "#define WORD_NAMING_WITH_DET 3\n",
        "#define PICTURE_NAMING_fMRI 4\n",
        "         /* BOLD response, Canini et al. (2016, HBM) */\n",
        "\n",
        " /* Labeling network nodes */\n",
        " /* Concepts */\n",
        "#define FORK 0\n",
        "#define SPOON 1\n",
        "#define CUP 2\n",
        "#define GLASS 3\n",
        "#define KNIFE 4\n",
        "#define MANMADE 5\n",
        "\n",
        "/* German lemmas */\n",
        "#define GABEL 0  /* fork */\n",
        "#define LOFFEL 1 /* spoon */\n",
        "#define TASSE 2  /* cup */\n",
        "#define GLAS 3   /* glass */\n",
        "#define MESSER 4 /* knife */\n",
        "#define KUENSTLICH 5  /* manmade */\n",
        "\n",
        "/* Grammatical genders */\n",
        "#define MASC 0   /* masculine */\n",
        "#define FEM 1    /* feminine */\n",
        "#define NEUTER 2 /* neuter */\n",
        "\n",
        "/* Button nodes */\n",
        "#define B_MANMADE 0  /* Button 1: manmade */\n",
        "#define B_NATURAL 1  /* Button 2: natural */\n",
        "\n",
        " double CONC_con[N_CONCEPTs][N_CONCEPTs];\n",
        "\n",
        " /* Connections conceptual network for categorical relations */\n",
        " double CATEG_con[N_CONCEPTs][N_CONCEPTs] =  {\n",
        "\t           /* FORK  SPOON CUP GLASS KNIFE MANMADE */\n",
        " /* FORK   */   {   N,    Y,   Y,    Y,    Y,    Y },\n",
        " /* SPOON  */   {   Y,    N,   Y,    Y,    Y,    Y },\n",
        " /* CUP    */   {   Y,    Y,   N,    Y,    Y,    Y },\n",
        " /* GLASS  */   {   Y,    Y,   Y,    N,    Y,    Y },\n",
        " /* KNIFE  */   {   Y,    Y,   Y,    Y,    N,    Y },\n",
        " /* MANMADE*/   {   Y,    Y,   Y,    Y,    Y,    N }\n",
        " };\n",
        "\n",
        " /* Connections conceptual network for thematic relations */\n",
        " double ASSOC_con[N_CONCEPTs][N_CONCEPTs] =  {\n",
        "\t          /* CHURCH RING DRESS CAKE BOUQUET WEDDING */\n",
        " /* CHURCH  */   {   N,    N,   N,    N,    N,    Y },\n",
        " /* RING    */   {   N,    N,   N,    N,    N,    Y },\n",
        " /* DRESS   */   {   N,    N,   N,    N,    N,    Y },\n",
        " /* CAKE    */   {   N,    N,   N,    N,    N,    Y },\n",
        " /* BOUQUET */   {   N,    N,   N,    N,    N,    Y },\n",
        " /* WEDDING */   {   Y,    Y,   Y,    Y,    Y,    N }\n",
        " };\n",
        "\n",
        "\n",
        " /* Connections between concept and lemma nodes */\n",
        " /* Lemma nodes are Gabel, Loffel, Tasse, Glas, Messer\n",
        "    (and kuenstlich [manmade]) for the category \"tableware\" \n",
        "\tof Belke (2013, JML), and Kirche, Ring, Brautkleid, \n",
        "\tTorte, Blumenstrauss (and Hochzeit) for the theme \n",
        "\t\"wedding\" of Rose & Abdel Rahman (2016, Cognition)\n",
        "*/\n",
        " double LEM_con[N_CONCEPTs][N_LEMMAs] = {\n",
        "    { Y,  N,  N,  N,  N,  N },\n",
        "    { N,  Y,  N,  N,  N,  N },\n",
        "    { N,  N,  Y,  N,  N,  N },\n",
        "    { N,  N,  N,  Y,  N,  N },\n",
        "    { N,  N,  N,  N,  Y,  N },\n",
        "    { N,  N,  N,  N,  N,  Y }\n",
        " };\n",
        "\n",
        " /* Connections between lemma and gender nodes */\n",
        " double GEN_con[N_LEMMAs][N_GENDERs] =  {\n",
        "\t               /* MASC  FEM  NEUTER */\n",
        " /* GABEL  */      {   N,    Y,    N  },\n",
        " /* LOFFEL */      {   Y,    N,    N  },\n",
        " /* TASSE  */      {   N,    Y,    N  },\n",
        " /* GLAS   */      {   N,    N,    Y  },\n",
        " /* MESSER */      {   N,    N,    Y  },\n",
        " /* KUENSTLICH*/   {   N,    N,    N  }\n",
        " };\n",
        "\n",
        "\n",
        " /* Connections between concept and button nodes */\n",
        " double BUTTON_con[N_CONCEPTs][N_BUTTONs] = {\n",
        "\t        /* B_MANMADE B_NATURAL */\n",
        "\t /* FORK   */ { N,    N },\n",
        "\t /* SPOON  */ { N,    N },\n",
        "\t /* CUP    */ { N,    N },\n",
        "\t /* GLASS  */ { N,    N },\n",
        "\t /* KNIFE  */ { N,    N },\n",
        "\t /* MANMADE*/ { Y,    N }\n",
        " };\n",
        "\n",
        "\n",
        "\n",
        "\n",
        " /* Here a network node is defined, having an activation level,\n",
        " and an input buffer; its output is equal to its activation */\n",
        " struct node { \n",
        "\t double act;\n",
        "\t double input;\n",
        " } concept[N_CONCEPTs], lemma[N_LEMMAs], gender[N_GENDERs], button[N_BUTTONs];\n",
        "\n",
        " \n",
        " int pos;   /* ordinal position, i.e., 1 to 5 (in C is 0 to 4) */\n",
        " int T;     /* time in ms */\n",
        "\n",
        " int task;  /* PICTURE NAMING, PICTURE CLASSIFICATION, WORD NAMING, \n",
        "\t\t\t   WORD NAMIMG WITH DET, PICTURE_NAMING_fMRI */\n",
        "\n",
        " /* Parameter set plus values */\n",
        " double CONC_rate = 0.5 * 0.0101 * STEP_SIZE;   \n",
        "            /* 0.5 of default prop per step_size ms \n",
        "\t\t\t   because of the increased size of conceptual\n",
        "\t\t\t   network, cf. Roelofs (2003, Psych. Rev.) */\n",
        " double LEM_rate = 0.0074 * STEP_SIZE;   /* prop per step_size ms */\n",
        " double DECAY_rate = 0.0240 * STEP_SIZE; /* prop per step_size ms */\n",
        " double EXTIN = 0.1965 * STEP_SIZE;      /* act_units per step_size ms */\n",
        " double CRIT_DIFF;                       /* act_units */\n",
        "\n",
        " double BIAS = 2.5;\n",
        "\n",
        " int BLOCKED_CYCLIC = 0; /* 1 = run for blocked-cyclic naming */\n",
        " double PREV_BIAS = 0.0; /* previous bias */ \n",
        " /* The PREV_BIAS parameter is needed for simulating blocked-cyclic\n",
        "    naming, because the bias increase during a cycle is also present \n",
        "\tduring the next cycle. To run the model for blocked-cyclic naming,\n",
        "\tset the PREV_BIAS values by hand for each new cycle.\n",
        "    Previous bias in cycle 1: 0.0, cycle 2: 2.5, cycle 3: 5.0, \n",
        "\t                 cycle 4: 7.5, cycle 5: 10.0, cycle 6: 12.5\n",
        "\tThe semantic blocking effect in a cycle is the mean increase over\n",
        "\tordinal positions relative to the first position. The effect of bias\n",
        "\tfor the first ordinal position is the same for the homogeneous and \n",
        "\tthe heterogeneous conditions. For later ordinal positions, the bias \n",
        "\teffect will differ between conditions because the position effect\n",
        "\toccurs only within categories or themes (thus only in the homogeneous\n",
        "\tcondition).\n",
        "  */\n",
        "\n",
        " int TAXONOMIC = 1; /* categorical relatedness, Belke (2013, JML) */\n",
        " int THEMATIC = 0;  /* thematic relatedness, \n",
        "\t\t\t\t\t   Rose & Abdel Rahman (2016, Cognition) */\n",
        " \n",
        " /* The parameter values for the critical difference [selection\n",
        "    threshold] for the different tasks: PN = picture naming, \n",
        "\tPC is picture classification, WR is word reading */\n",
        "  double CD_PN = 1.6, CD_PC = 1.6,  CD_WR = 1.6; \n",
        "  /* default: all values the same */\n",
        "\n",
        " /* control flags for production rule application */\n",
        " /* cf. EPIC, Meyer & Kieras, Psych. Rev. 1997 */  \n",
        " int FLAG_CONCEPT;\n",
        " int ENHANCE_CONCEPT;\n",
        " int FLAG_LEMMA;\n",
        " int FLAG_GENDER;\n",
        " int FLAG_CATEGORY_CONCEPT;\n",
        " int FLAG_BUTTON_NODE;\n",
        "\n",
        " int SIM_DATA[N_TASKs][N_POSs];\n",
        " double BOLD_response[N_TASKs][N_POSs];\n",
        "\n",
        " double h[N_STEPs];\n",
        " double S[N_STEPs];\n",
        " double f[N_STEPs];\n",
        "\n",
        " void reset_network(void);\n",
        " void set_spreading_rates(void);\n",
        " void reset_spreading_rates(void);\n",
        " void set_task_dependent_parameters(void);\n",
        " void update_network(void);\n",
        " void set_input_to_zero(void);\n",
        " void get_external_input(void);\n",
        " void get_internal_input(void);\n",
        " void update_activation_of_nodes(void);\n",
        "\n",
        " void reset_system(void);\n",
        " void reset_f_h_S_(void);\n",
        " void compute_POS_functions(void);\n",
        " void compute_hazard_rate(void);\n",
        " void compute_cumul_survival_function(void);\n",
        " void compute_mass_function(void);\n",
        " double compute_expectation_of_RT_(void);\n",
        " void compute_BOLD_response(void);\n",
        "\n",
        " void reset_production_rule_system(void);\n",
        " void apply_production_rules(void);\n",
        "\n",
        " void print_heading(void);\n",
        " void print_expectations_of_RT(void);\n",
        "  \n",
        "\n",
        "/*****************\n",
        " * MAIN ROUTINES *\n",
        " *****************/\n",
        "\n",
        " main()\n",
        " {\n",
        "    for(task=0;task<N_TASKs;task++) {\n",
        "\n",
        "       reset_system();\n",
        "       set_spreading_rates();\n",
        "       set_task_dependent_parameters();\n",
        "\n",
        "\t   print_heading();\n",
        "\n",
        "       compute_POS_functions();\n",
        "\n",
        "\t   print_expectations_of_RT();\n",
        "\n",
        "       reset_spreading_rates();\n",
        "    }\n",
        " }\n",
        "\n",
        "\n",
        " void compute_POS_functions()\n",
        " {\n",
        "\n",
        "\t for (pos = 0; pos < N_POSs; pos++) {\n",
        "\t\t reset_f_h_S_();\n",
        "\t\t reset_network();\n",
        "\t\t reset_production_rule_system();\n",
        "\t\t for (T = 0; T < 1000; T += STEP_SIZE) {\n",
        "\t\t\t /* stop for lemma retrieval latency > 1000 ms */\n",
        "\t\t\t compute_hazard_rate();\n",
        "\t\t\t update_network();\n",
        "\t\t\t apply_production_rules();\n",
        "\t\t }\n",
        "\t\t compute_cumul_survival_function();\n",
        "\t\t compute_mass_function();\n",
        "\t\t SIM_DATA[task][pos] = (int)compute_expectation_of_RT_();\n",
        "\t }\n",
        "\t      if(task==PICTURE_NAMING_fMRI)\n",
        "\t\t   compute_BOLD_response();\n",
        " }\n",
        "\n",
        "\n",
        "\n",
        " void reset_system()\n",
        " {\n",
        "     int j;\n",
        "\n",
        "      for(j=0;j<N_POSs;j++)\n",
        "    \tSIM_DATA[task][j]=0;\n",
        "\n",
        "      for(j=0;j<N_POSs;j++)\n",
        "    \tBOLD_response[task][j]=0.0;\n",
        "\n",
        " }\n",
        "\n",
        "\n",
        " void set_spreading_rates()\n",
        " {\n",
        "   int i,j;\n",
        "\n",
        "  /* Sets the conceptual connections for categorical reations */\n",
        "   if(TAXONOMIC) {\n",
        "   for(i=0;i<N_CONCEPTs;i++)\n",
        "     for(j=0;j<N_CONCEPTs;j++) \n",
        "\t   CONC_con[i][j] = CATEG_con[i][j];\n",
        "   }\n",
        "\n",
        " /* Sets the conceptual connections for thematic reations */\n",
        "   if(THEMATIC) {\n",
        "   for(i=0;i<N_CONCEPTs;i++)\n",
        "     for(j=0;j<N_CONCEPTs;j++) \n",
        "\t   CONC_con[i][j] = ASSOC_con[i][j];\n",
        "   }\n",
        "\n",
        "\n",
        " /* Sets the strengths of the connections */\n",
        "\n",
        "   for(i=0;i<N_CONCEPTs;i++)\n",
        "     for(j=0;j<N_CONCEPTs;j++)\n",
        "\t   CONC_con[i][j]*=CONC_rate;\n",
        "\n",
        "   for(i=0;i<N_CONCEPTs;i++)\n",
        "     for(j=0;j<N_LEMMAs;j++) \n",
        "\t   LEM_con[i][j]*=LEM_rate;\n",
        "\n",
        "   for(i=0;i<N_LEMMAs;i++)\n",
        "     for(j=0;j<N_GENDERs;j++) \n",
        "\t   GEN_con[i][j]*=LEM_rate;\n",
        "\n",
        "   for(i=0;i<N_CONCEPTs;i++)\n",
        "\t for(j=0;j<N_BUTTONs;j++)\n",
        "\t\tBUTTON_con[i][j]*=LEM_rate;\n",
        "\n",
        " }\n",
        "\n",
        "\n",
        " void set_task_dependent_parameters()\n",
        " {\n",
        "\n",
        "    if(task==PICTURE_NAMING) {\n",
        "       CRIT_DIFF=CD_PN;\n",
        "       }\n",
        "\n",
        "    if(task==PICTURE_CLASSIFICATION) {\n",
        "       CRIT_DIFF=CD_PC;\n",
        "       }\n",
        "\n",
        "    if(task==WORD_NAMING) {\n",
        "       CRIT_DIFF=CD_WR;\n",
        "       }\n",
        "\n",
        "    if(task==WORD_NAMING_WITH_DET) {\n",
        "       CRIT_DIFF=CD_WR;\n",
        "       }\n",
        "\n",
        "    if(task==PICTURE_NAMING_fMRI) {\n",
        "       CRIT_DIFF=CD_PN;\n",
        "       }\n",
        " }\n",
        "\n",
        "\n",
        " void reset_spreading_rates()\n",
        " {\n",
        " /* Needed, because otherwise in later tasks rates become a\n",
        "    proportion of earlier ones; this routine keeps them fixed */\n",
        "\n",
        "   int i,j;\n",
        "\n",
        "   for(i=0;i<N_CONCEPTs;i++)\n",
        "     for(j=0;j<N_CONCEPTs;j++) \n",
        "\t   CONC_con[i][j]*=(1.0/CONC_rate);\n",
        "\n",
        "   for(i=0;i<N_CONCEPTs;i++)\n",
        "     for(j=0;j<N_LEMMAs;j++)\n",
        "\t   LEM_con[i][j]*=(1.0/LEM_rate);\n",
        "\n",
        "\n",
        "   for(i=0;i<N_LEMMAs;i++)\n",
        "     for(j=0;j<N_GENDERs;j++) \n",
        "  \t   GEN_con[i][j]*=(1.0/LEM_rate);\n",
        "\t\n",
        "   for(i=0;i<N_CONCEPTs;i++)\n",
        "\t for(j=0;j<N_BUTTONs;j++)\n",
        "\t\tBUTTON_con[i][j]*=(1.0/LEM_rate);\n",
        "\n",
        " }\n",
        "\n",
        " void reset_network()\n",
        " {\n",
        "   int i;\n",
        "\n",
        "   for(i=0;i<N_CONCEPTs;i++) \n",
        "     concept[i].act=0.0;\n",
        "\n",
        "   for(i=0;i<N_LEMMAs;i++)\n",
        "     lemma[i].act=0.0;\n",
        "\n",
        "   for(i=0;i<N_GENDERs;i++)\n",
        "\t gender[i].act=0.0;\n",
        "\n",
        "   for(i=0;i<N_BUTTONs;i++)\n",
        "\t button[i].act=0.0;\n",
        "\n",
        "}\n",
        "\n",
        "\n",
        " void reset_production_rule_system()\n",
        " {\n",
        "  /* reset control flags in working memory */\n",
        "  \n",
        "  FLAG_CONCEPT = 0;\n",
        "  ENHANCE_CONCEPT = 0;\n",
        "  FLAG_LEMMA = 0;\n",
        "\n",
        "  FLAG_GENDER = 0;\n",
        "\n",
        "  FLAG_CATEGORY_CONCEPT = 0;\n",
        "  FLAG_BUTTON_NODE = 0;\n",
        "  \n",
        " }\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "/*********************\n",
        " * UPDATING ROUTINES *\n",
        " *********************/\n",
        "\n",
        " void update_network()\n",
        " {\n",
        "   set_input_to_zero();\n",
        "   get_external_input();\n",
        "   get_internal_input();\n",
        "   update_activation_of_nodes();\n",
        " }\n",
        "\n",
        "\n",
        " void apply_production_rules()\n",
        " {\n",
        "\n",
        " /* Production rule application for picture naming */\n",
        "\n",
        " /* here the lemma of Gabel for the selected concept FORK is flagged */\n",
        "  if((task==PICTURE_NAMING || task==PICTURE_NAMING_fMRI) \n",
        "\t  && FLAG_CONCEPT==1 && lemma[GABEL].act) \n",
        "     FLAG_LEMMA = 1;\n",
        "\n",
        " /* here the concept FORK is flagged for selection and enhancement \n",
        "              cf. P1 in Roelofs, 2003, Psych. Rev., p. 100 */\n",
        "  if((task==PICTURE_NAMING || task==PICTURE_NAMING_fMRI) \n",
        "\t  && concept[FORK].act) {\n",
        "     FLAG_CONCEPT = 1;\n",
        "     ENHANCE_CONCEPT = 1;\n",
        "  }\n",
        "\n",
        " /* production rule application for picture classification */\n",
        "\n",
        " /* here the button node for the category concept MAN-MADE is flagged */\n",
        "  if(task==PICTURE_CLASSIFICATION  \n",
        "\t  && FLAG_CATEGORY_CONCEPT==1 && button[B_MANMADE].act) \n",
        "     FLAG_BUTTON_NODE = 1;\n",
        "\n",
        " /* here the category concept MAN-MADE for the concept FORK is flagged */\n",
        "  if(task==PICTURE_CLASSIFICATION  \n",
        "\t  && FLAG_CONCEPT==1 && concept[MANMADE].act) \n",
        "     FLAG_CATEGORY_CONCEPT = 1;\n",
        "\n",
        " /* here the concept FORK is flagged */\n",
        "  if(task==PICTURE_CLASSIFICATION  && concept[FORK].act) \n",
        "     FLAG_CONCEPT = 1;\n",
        "\n",
        "\n",
        " /* Production rule application for word reading */\n",
        "\n",
        " /* here the lemma of Gabel is flagged */\n",
        "  if(task==WORD_NAMING && lemma[GABEL].act) \n",
        "     FLAG_LEMMA = 1;\n",
        "\n",
        "\n",
        " /* Production rule application for word reading \n",
        "                     with gender-marked determiner */\n",
        "\n",
        " /* here the gender of the lemma of Gabel is flagged */\n",
        "  if(task==WORD_NAMING_WITH_DET && FLAG_LEMMA == 1 && gender[FEM].act) \n",
        "     FLAG_GENDER = 1;\n",
        "\n",
        " /* here the lemma of Gabel is flagged */\n",
        "  if(task==WORD_NAMING_WITH_DET && lemma[GABEL].act) \n",
        "     FLAG_LEMMA = 1;\n",
        "  \n",
        " }\n",
        "\n",
        "\n",
        "\n",
        " void set_input_to_zero()\n",
        " {\n",
        "   int i;\n",
        "\n",
        "   for(i=0;i<N_CONCEPTs;i++)\n",
        "       concept[i].input=0.0;\n",
        "\n",
        "   for(i=0;i<N_LEMMAs;i++)\n",
        "       lemma[i].input=0.0;\n",
        " \n",
        "   for(i=0;i<N_GENDERs;i++)\n",
        "\t   gender[i].input=0.0;\n",
        "\n",
        "   for(i=0;i<N_BUTTONs;i++)\n",
        "\t   button[i].input=0.0;\n",
        "\n",
        " }\n",
        "\n",
        "\n",
        "\n",
        "  void get_external_input()\n",
        " {\n",
        "\n",
        "\n",
        "      /* picture input */\n",
        "\t \n",
        "\t\tif(pos==0 && (task==PICTURE_NAMING || task==PICTURE_CLASSIFICATION\n",
        "\t\t\t|| task==PICTURE_NAMING_fMRI)) {\n",
        " \t   concept[FORK].input += (PREV_BIAS + EXTIN);  \n",
        "\t\t} \n",
        "\n",
        "\t\tif(pos==1 && (task==PICTURE_NAMING || task==PICTURE_CLASSIFICATION\n",
        "\t\t\t|| task==PICTURE_NAMING_fMRI)) {\n",
        "\t   concept[FORK].input += (PREV_BIAS + EXTIN);\n",
        "\t   concept[SPOON].input += (PREV_BIAS + BIAS); /* bias position \"2\" */\n",
        "  \n",
        "\t\t} \n",
        "\n",
        "\t\tif(pos==2 && (task==PICTURE_NAMING || task==PICTURE_CLASSIFICATION\n",
        "\t\t\t|| task==PICTURE_NAMING_fMRI)) {\n",
        "\t   concept[FORK].input += (PREV_BIAS + EXTIN); \n",
        "\t   concept[SPOON].input += (PREV_BIAS + BIAS); /* bias position \"2\" */ \n",
        "\t   concept[CUP].input += (PREV_BIAS + BIAS);   /* bias position \"3\" */\n",
        "\t\t} \n",
        "\n",
        "\t\tif(pos==3 && (task==PICTURE_NAMING || task==PICTURE_CLASSIFICATION\n",
        "\t\t\t|| task==PICTURE_NAMING_fMRI)) {\n",
        "\t   concept[FORK].input += (PREV_BIAS + EXTIN);\n",
        "\t   concept[SPOON].input += (PREV_BIAS + BIAS); /* bias position \"2\" */ \n",
        "\t   concept[CUP].input += (PREV_BIAS + BIAS);   /* bias position \"3\" */ \n",
        "\t   concept[GLASS].input += (PREV_BIAS + BIAS); /* bias position \"4\" */\n",
        "\t\t} \n",
        "\n",
        "\t\tif(pos==4 && (task==PICTURE_NAMING || task==PICTURE_CLASSIFICATION\n",
        "\t\t\t|| task==PICTURE_NAMING_fMRI)) {\n",
        "\t   concept[FORK].input += (PREV_BIAS + EXTIN);  \n",
        "\t   concept[SPOON].input += (PREV_BIAS + BIAS);  /* bias position \"2\" */ \n",
        "\t   concept[CUP].input += (PREV_BIAS + BIAS);    /* bias position \"3\" */ \n",
        "\t   concept[GLASS].input += (PREV_BIAS + BIAS);  /* bias position \"4\" */ \n",
        "\t   concept[KNIFE].input += (PREV_BIAS + BIAS);  /* bias position \"5\" */\n",
        "\t\t} \n",
        "\n",
        "\t/* Target concept gets activation enhancement */\n",
        "      if((task==PICTURE_NAMING || task==PICTURE_NAMING_fMRI) \n",
        "\t\t    && ENHANCE_CONCEPT==1 )\n",
        "\t   concept[FORK].input += 1.0 * EXTIN;\n",
        "\n",
        "\n",
        "\n",
        "      /* word input */\n",
        "\n",
        " \t  if(task==WORD_NAMING || task==WORD_NAMING_WITH_DET) {\n",
        " \t   lemma[GABEL].input += EXTIN;  \n",
        "\t\t} \n",
        "\n",
        "\t\tif(pos==1 && task==WORD_NAMING_WITH_DET) {\n",
        "\t   concept[SPOON].input += BIAS; /* bias position \"2\" */ \n",
        "\t\t} \n",
        "\n",
        "\t\tif(pos==2 && task==WORD_NAMING_WITH_DET) {\n",
        "\t   concept[SPOON].input += BIAS;   /* bias position \"2\" */ \n",
        "\t   concept[CUP].input += BIAS;     /* bias position \"3\" */ \n",
        "\t\t} \n",
        "\n",
        "\t\tif(pos==3 && task==WORD_NAMING_WITH_DET) {\n",
        "\t   concept[SPOON].input += BIAS;  /* bias position \"2\" */ \n",
        "\t   concept[CUP].input += BIAS;    /* bias position \"3\" */ \n",
        "\t   concept[GLASS].input += BIAS;  /* bias position \"4\" */ \n",
        " \t\t} \n",
        "\n",
        "\t\tif(pos==4 && task==WORD_NAMING_WITH_DET) {\n",
        "\t   concept[SPOON].input += BIAS;  /* bias position \"2\" */ \n",
        "\t   concept[CUP].input += BIAS;    /* bias position \"3\" */ \n",
        "\t   concept[GLASS].input += BIAS;  /* bias position \"4\" */ \n",
        "\t   concept[KNIFE].input += BIAS;  /* bias position \"5\" */ \n",
        "\t\t} \n",
        "\n",
        " }\n",
        "\n",
        "\n",
        " void get_internal_input()\n",
        " {\n",
        "   int i,j;\n",
        "\n",
        "   for(i=0;i<N_CONCEPTs;i++)\n",
        "     for(j=0;j<N_CONCEPTs;j++) \n",
        "       concept[i].input += ( (concept[j].act * CONC_con[j][i])\n",
        "\t\t      +\n",
        "\t\t    (lemma[j].act * LEM_con[j][i])  );\n",
        "\n",
        "\n",
        "   for(i=0;i<N_LEMMAs;i++)\n",
        "     for(j=0;j<N_CONCEPTs;j++) \n",
        "       lemma[i].input += ( concept[j].act * LEM_con[j][i] );\n",
        "       \n",
        "\n",
        "   for(i=0;i<N_GENDERs;i++)\n",
        "     for(j=0;j<N_LEMMAs;j++) \n",
        "       gender[i].input += ( lemma[j].act * GEN_con[j][i] );\n",
        "\n",
        "   for(i=0;i<N_BUTTONs;i++)\n",
        "\t for(j=0;j<N_CONCEPTs;j++)\n",
        "\t\tbutton[i].input += (concept[j].act * BUTTON_con[j][i]);\n",
        "\n",
        " }\n",
        "\n",
        "\n",
        " void update_activation_of_nodes()\n",
        " {\n",
        "   int i;\n",
        "\n",
        "   for(i=0;i<N_CONCEPTs;i++) \n",
        "     concept[i].act = ((concept[i].act * (1.0 - DECAY_rate)) \n",
        "\t\t + concept[i].input);\n",
        "\n",
        "   for(i=0;i<N_LEMMAs;i++) \n",
        "     lemma[i].act = ((lemma[i].act * (1.0 - DECAY_rate)) \n",
        "\t\t + lemma[i].input);\n",
        "     \n",
        "   for(i=0;i<N_GENDERs;i++) \n",
        "     gender[i].act = ((gender[i].act * (1.0 - DECAY_rate)) \n",
        "\t\t + gender[i].input);\n",
        "\n",
        "   for(i=0;i<N_BUTTONs;i++)\n",
        "\t   button[i].act = ((button[i].act * (1.0 - DECAY_rate))\n",
        "\t\t   + button[i].input);\n",
        "\n",
        " }\n",
        "\n",
        "\n",
        "\n",
        "/*********************************************************\n",
        " *  HAZARD-, CUMUL_SURVIVAL-, MASS-FUNCTION ROUTINES     *\n",
        " *********************************************************/\n",
        "\n",
        "\n",
        " void compute_hazard_rate()\n",
        " {\n",
        "\n",
        "\n",
        "   if(T>=0) {\n",
        "\n",
        "      if(task==PICTURE_NAMING || task==PICTURE_NAMING_fMRI) {\n",
        "\n",
        "\t if( FLAG_LEMMA==1   \n",
        "\t    &&\n",
        "\t   ( (lemma[GABEL].act - lemma[LOFFEL].act) > CRIT_DIFF )\n",
        "\t    &&\n",
        "\t   ( (lemma[GABEL].act - lemma[TASSE].act) > CRIT_DIFF )\n",
        "\t    && \n",
        "\t   ( (lemma[GABEL].act - lemma[GLAS].act)  > CRIT_DIFF )\n",
        "\t    && \n",
        "\t   ( (lemma[GABEL].act - lemma[MESSER].act) > CRIT_DIFF )  )\n",
        "\n",
        "\t    h[(T/STEP_SIZE)+1] = lemma[GABEL].act / \n",
        "\t\t\t        (lemma[GABEL].act   \n",
        "\t\t\t       + lemma[LOFFEL].act  \n",
        "\t\t\t       + lemma[TASSE].act\n",
        "\t\t\t       + lemma[GLAS].act\n",
        "\t\t\t       + lemma[MESSER].act );\n",
        "\t\t   /* the denominator consists of semantic cohort memmbers */\n",
        "\t else\n",
        "\t    h[(T/STEP_SIZE)+1] = 0.0;\n",
        "      }\n",
        "\n",
        "      if(task==WORD_NAMING) {\n",
        "\n",
        "\t\t  if (FLAG_LEMMA == 1\n",
        "\t\t\t  &&\n",
        "\t\t\t  ((lemma[GABEL].act - lemma[LOFFEL].act) > CRIT_DIFF)\n",
        "\t\t\t  &&\n",
        "\t\t\t  ((lemma[GABEL].act - lemma[TASSE].act) > CRIT_DIFF)\n",
        "\t\t\t  &&\n",
        "\t\t\t  ((lemma[GABEL].act - lemma[GLAS].act)  > CRIT_DIFF)\n",
        "\t\t\t  &&\n",
        "\t\t\t  ((lemma[GABEL].act - lemma[MESSER].act) > CRIT_DIFF))\n",
        "\n",
        "\t\t\t  h[(T / STEP_SIZE) + 1] = lemma[GABEL].act /\n",
        "\t\t\t       (lemma[GABEL].act\n",
        "\t\t\t\t  + lemma[LOFFEL].act\n",
        "\t\t\t\t  + lemma[TASSE].act\n",
        "\t\t\t\t  + lemma[GLAS].act\n",
        "\t\t\t\t  + lemma[MESSER].act);\n",
        "\t\t  /* the denominator consists of semantic cohort memmbers */\n",
        "\t\t  else\n",
        "\t\t\t  h[(T / STEP_SIZE) + 1] = 0.0;\n",
        "\t  }\n",
        "\n",
        "\n",
        "    if(task==WORD_NAMING_WITH_DET) {\n",
        "\n",
        "\t if( FLAG_LEMMA==1 && FLAG_GENDER==1   \n",
        "\t    &&\n",
        "\t\t ((lemma[GABEL].act - lemma[LOFFEL].act) > CRIT_DIFF)\n",
        "\t\t &&\n",
        "\t\t ((lemma[GABEL].act - lemma[TASSE].act) > CRIT_DIFF)\n",
        "\t\t &&\n",
        "\t\t ((lemma[GABEL].act - lemma[GLAS].act)  > CRIT_DIFF)\n",
        "\t\t &&\n",
        "\t\t ((lemma[GABEL].act - lemma[MESSER].act) > CRIT_DIFF)\n",
        "\t\t &&\n",
        "\t    (gender[FEM].act ) > CRIT_DIFF )\n",
        "\n",
        "\t\t h[(T / STEP_SIZE) + 1] = lemma[GABEL].act /\n",
        "\t\t      (lemma[GABEL].act\n",
        "\t\t\t + lemma[LOFFEL].act\n",
        "\t\t\t + lemma[TASSE].act\n",
        "\t\t\t + lemma[GLAS].act\n",
        "\t\t\t + lemma[MESSER].act);\n",
        "\t else\n",
        "\t    h[(T/STEP_SIZE)+1] = 0.0;\n",
        "      }\n",
        "\n",
        "\n",
        "\n",
        "      if(task==PICTURE_CLASSIFICATION) {\n",
        "\n",
        "\t if( FLAG_BUTTON_NODE==1   \n",
        "\t    &&\n",
        "\t   ( button[B_MANMADE].act - button[B_NATURAL].act > CRIT_DIFF ) )\n",
        "\t\t /* In simulating picture classification with vocal\n",
        "\t\t responding (Riley et al. 2015, FiP), the buttons would\n",
        "\t\t become the corresponding lemmas\n",
        "\t\t */\n",
        "\t\t h[(T/STEP_SIZE)+1] = 1.0;\n",
        "\t else\n",
        "\t    h[(T/STEP_SIZE)+1] = 0.0;\n",
        "      }\n",
        "\n",
        "\n",
        "   }\n",
        " }\n",
        "\n",
        "\n",
        " void compute_cumul_survival_function()\n",
        " {\n",
        "     int j,s;\n",
        "     double aux;\n",
        "\n",
        "     /* NOTE: cum_survival or S[s] is upto and including s */\n",
        "\n",
        "     for(s=0;s<N_STEPs;s++) {\n",
        "       for(j=0, aux=1.0;j<=s;j++)\n",
        "\t  aux*=(1.0-h[j]);\n",
        "       S[s]=aux;\n",
        "       }\n",
        " }\n",
        "\n",
        " void compute_mass_function()\n",
        " {\n",
        "     int s;\n",
        "\n",
        "     /* NOTE: Prob(not selected before step s) equals S[s-1], that is\n",
        "\tsurviving upto and including the previous time step */\n",
        "\n",
        "     for(s=1;s<N_STEPs;s++)\n",
        "       f[s]=h[s] * S[s-1];\n",
        "\n",
        "     /* NOTE: f[0] will always be 0, so does not have to be computed */\n",
        " }\n",
        "\n",
        " double compute_expectation_of_RT_()\n",
        " {\n",
        "     int s;\n",
        "     double mean=0.0;\n",
        "\n",
        "\t for(s=0;s<N_STEPs;s++) \n",
        "\t  mean+=f[s] * s * STEP_SIZE;\n",
        "\t \n",
        "     return mean;\n",
        " }\n",
        "\n",
        " void reset_f_h_S_()\n",
        " {\n",
        "    int s;\n",
        "\n",
        "    for(s=0;s<N_STEPs;s++) {\n",
        "      f[s]=0.0;\n",
        "      h[s]=0.0;\n",
        "      S[s]=0.0;\n",
        "      }\n",
        " }\n",
        "\n",
        " void compute_BOLD_response()\n",
        " {\n",
        "    int j;\n",
        "\n",
        "    for(j=0;j<N_POSs;j++)\n",
        "     BOLD_response[task][j]= \n",
        "\t  (6.0 /* 6.0 = intercept estimated from Canini et al. (2016) */\n",
        "\t + ( (double) SIM_DATA[task][j] - (double) SIM_DATA[task][0] ) \n",
        "\t * (4.5 / ( (double) SIM_DATA[task][4] - (double) SIM_DATA[task][0])));\n",
        "\t       /* 4.5 = slope estimated from Canini et al. (2016) */\n",
        "  }\n",
        "\n",
        "\n",
        "\n",
        "/*****************\n",
        " *  I/0 ROUTINES *\n",
        " *****************/\n",
        "\n",
        " void print_heading()\n",
        " {\n",
        "\n",
        "   printf(\"Simulation of Lemma Retrieval in Speaking  (c) Ardi Roelofs\\n\");\n",
        "   printf(\"working...\\n\");\n",
        "\n",
        " }\n",
        "\n",
        "\n",
        " void print_expectations_of_RT()\n",
        " {\n",
        "     int j, tot_latency=0, tot_effect=0;\n",
        "\n",
        "     if(task==PICTURE_NAMING)\n",
        "\tprintf(\"\\n  Picture Naming\\n\\n\");\n",
        "     if(task==PICTURE_CLASSIFICATION)\n",
        "\tprintf(\"\\n  Picture - Semantic Classification\\n\\n\");\n",
        "     if(task==WORD_NAMING)\n",
        "\tprintf(\"\\n  Word Naming\\n\\n\");\n",
        "     if(task==WORD_NAMING_WITH_DET)\n",
        "\tprintf(\"\\n  Word Naming With Gender-Marked Determiner (Transfer)\\n\\n\");\n",
        "     if(task==PICTURE_NAMING_fMRI)\n",
        "\tprintf(\"\\n  Picture Naming fMRI\\n\\n\");\n",
        "\n",
        "     printf(\"  POSITION   LATENCY    EFFECT\\n\");\n",
        "     for(j=0;j<N_POSs;j++) {\n",
        "\t printf(\"%6d \", j+1);\n",
        "\t printf(\"     %6d    %6d\", SIM_DATA[task][j], \n",
        "\t\t SIM_DATA[task][j] - SIM_DATA[task][0] );\n",
        "\t printf(\"\\n\");\n",
        "     }\n",
        "\n",
        "\t if(BLOCKED_CYCLIC) {\n",
        "       for(j=0;j<N_POSs;j++) {\n",
        "         tot_latency+=SIM_DATA[task][j];\n",
        "         tot_effect+=SIM_DATA[task][j] - SIM_DATA[task][0];\n",
        " \t      }\n",
        "\t printf(\"Cycle mean  %6d    %6d\\n\", tot_latency/5, tot_effect/5); \n",
        "\t }\n",
        "\n",
        "\t if(task==PICTURE_NAMING_fMRI) {  \n",
        "     printf(\"  POSITION   BOLD\\n\");\n",
        "\t for(j=0;j<N_POSs;j++) {\n",
        "\t printf(\"%6d \", j+1);        \n",
        "\t printf(\"     %.2f   \",   BOLD_response[task][j]);\n",
        "\t printf(\"\\n\");              \n",
        "      }\n",
        "\t }\n",
        "\n",
        "     printf(\"\\nParameter values:\\n\");\n",
        "     printf(\"conc_rate : %.4f [prop/ms]\\n\",CONC_rate/STEP_SIZE);\n",
        "     printf(\"lem_rate  : %.4f [prop/ms]\\n\",LEM_rate/STEP_SIZE);\n",
        "     printf(\"exin      : %.4f [act_units/ms]\\n\",EXTIN/STEP_SIZE);\n",
        "     printf(\"d         : %.4f [prop/ms]\\n\",DECAY_rate/STEP_SIZE);\n",
        "     printf(\"cd        : %.4f [act_units]\\n\",CRIT_DIFF);\n",
        "     printf(\"bias      : %.4f [act_units]\\n\",BIAS);\n",
        "\n",
        "     printf(\"\\npress any key to continue \");\n",
        "\n",
        "     getchar();\n",
        " }\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A4Dr7fMAqOXJ"
      },
      "source": [
        "import svgutils.transform as sg\n",
        "from IPython.display import SVG,display\n",
        "\n",
        "#create new SVG figure\n",
        "fig = sg.SVGFigure(\"16cm\", \"10cm\")\n",
        "\n",
        "# load matpotlib-generated figures\n",
        "fig1 = sg.fromfile('../figures/2018Roelofs_fig1.svg')\n",
        "plot1 = fig1.getroot()\n",
        "fig.append([plot1])\n",
        "fig.save(\"svg_filter_line2.svg\")\n",
        "display(SVG(filename='svg_filter_line2.svg'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hOF90KQUqOXJ"
      },
      "source": [
        "!gls -tl '../figures/2018Roelofs_fig1.svg'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yU-4Y8_tqOXJ"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}