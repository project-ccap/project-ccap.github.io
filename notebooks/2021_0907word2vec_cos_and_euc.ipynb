{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2021_0907word2vec_cos_and_euc.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyNbvVi5iOCjBXFUIeEoNy0Y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/project-ccap/project-ccap.github.io/blob/master/notebooks/2021_0907word2vec_cos_and_euc.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Uajmf6vO43Z"
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "import os\n",
        "import platform\n",
        "\n",
        "# word2vec のため gensim を使う\n",
        "from gensim.models import KeyedVectors\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "\n",
        "class ccap_w2v():\n",
        "    \n",
        "    def __init__(self):\n",
        "        # local Mac で実行しているか, それとも colab 上で実行しているかを判定\n",
        "        (isMac, isColab) = (True, False) if platform.system() == 'Darwin' else (False, True)\n",
        "        is2017, is2021 = True, False\n",
        "\n",
        "        if isColab:\n",
        "            # 形態素分析ライブラリーMeCab と 辞書(mecab-ipadic-NEologd)のインストール \n",
        "            # reference: https://qiita.com/jun40vn/items/78e33e29dce3d50c2df1\n",
        "            !apt-get -q -y install sudo file mecab libmecab-dev mecab-ipadic-utf8 git curl python-mecab\n",
        "            !git clone --depth 1 https://github.com/neologd/mecab-ipadic-neologd.git\n",
        "            !echo yes | mecab-ipadic-neologd/bin/install-mecab-ipadic-neologd -n\n",
        "            !pip install mecab-python3\n",
        "    \n",
        "            # シンボリックリンクによるエラー回避\n",
        "            !ln -s /etc/mecabrc /usr/local/etc/mecabrc    \n",
        "\n",
        "            if is2017:\n",
        "                # word2vec の訓練済モデルを入手\n",
        "                !wget http://www.cis.twcu.ac.jp/~asakawa/2017jpa/2017Jul_jawiki-wakati_neologd_hid200_win20_neg20_cbow.bin.gz\n",
        "                #!wget http://www.cis.twcu.ac.jp/~asakawa/2017jpa/2017Jul_jawiki-wakati_neologd_hid200_win20_neg20_sgns.bin.gz\n",
        "                #!wget http://www.cis.twcu.ac.jp/~asakawa/2017jpa/2017Jul_jawiki-wakati_neologd_hid300_win20_neg20_sgns.bin.gz'\n",
        "                #!wget http://www.cis.twcu.ac.jp/~asakawa/2017jpa/2017Jul_jawiki-wakati_neologd_hid200_win20_neg20_cbow.bin.g\n",
        "            else:    \n",
        "                #訓練済 word2vec ファイルの取得\n",
        "                #!wget --no-check-certificate --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1B9HGhLZOja4Xku5c_d-kMhCXn1LBZgDb' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1B9HGhLZOja4Xku5c_d-kMhCXn1LBZgDb\" -O 2021_05jawiki_hid128_win10_neg10_cbow.bin.gz && rm -rf /tmp/cookies.txt\n",
        "                #!wget --no-check-certificate --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1OWmFOVRC6amCxsomcRwdA6ILAA5s4y4M' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1OWmFOVRC6amCxsomcRwdA6ILAA5s4y4M\" -O 2021_05jawiki_hid128_win10_neg10_sgns.bin.gz && rm -rf /tmp/cookies.txt\n",
        "                !wget --no-check-certificate --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1JTkU5SUBU2GkURCYeHkAWYs_Zlbqob0s' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1JTkU5SUBU2GkURCYeHkAWYs_Zlbqob0s\" -O 2021_05jawiki_hid200_win20_neg20_cbow.bin.gz && rm -rf /tmp/cookies.txt\n",
        "                #!wget --no-check-certificate --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1VPL2Mr9JgWHik9HjRmcADoxXIdrQ3ds7' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1VPL2Mr9JgWHik9HjRmcADoxXIdrQ3ds7\" -O 2021_05jawiki_hid200_win20_neg20_sgns.bin.gz && rm -rf /tmp/cookies.txt\n",
        "\n",
        "        import MeCab\n",
        "\n",
        "        # word2vec データの読み込み, ファイルの所在に応じて変更してください\n",
        "        if is2017:\n",
        "            w2v_base = '/Users/asakawa/study/2016wikipedia/' if isMac else '.'\n",
        "            w2v_file = '2017Jul_jawiki-wakati_neologd_hid200_win20_neg20_cbow.bin.gz'\n",
        "            w2v_file = os.path.join(w2v_base, w2v_file)\n",
        "        else:\n",
        "            w2v_base = '/Users/asakawa/study/2019attardi_wikiextractor.git/wiki_texts/AA' if isMac else '.'\n",
        "            w2v_file = '2021_05jawiki_hid128_win10_neg10_sgns.bin'\n",
        "\n",
        "        if isColab:\n",
        "            neologd_path = \"-d /usr/lib/x86_64-linux-gnu/mecab/dic/mecab-ipadic-neologd\"\n",
        "        else:\n",
        "            neologd_path = \"-d /usr/local/lib/mecab/dic/mecab-ipadic-neologd\"\n",
        "\n",
        "        w2v_base = '.' if isColab else w2v_base\n",
        "        w2v_file = os.path.join(w2v_base, w2v_file)\n",
        "        w2v = KeyedVectors.load_word2vec_format(w2v_file, \n",
        "                                                encoding='utf-8', \n",
        "                                                unicode_errors='replace',\n",
        "                                                binary=True)\n",
        "        self.w2v = w2v\n",
        "        self.tagger = MeCab.Tagger('-Oyomi ' + neologd_path)\n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wXcUUgIpO6OJ"
      },
      "source": [
        "_w2v = ccap_w2v()\n",
        "w2v = _w2v.w2v"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S8gWVsNFO-6V"
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\n",
        "import numpy as np\n",
        "# source: https://github.com/paraschopra/one-network-many-uses\n",
        "from scipy import spatial\n",
        "\n",
        "\n",
        "frequency_threshold = 20000  #最初の単語だけ取り出す\n",
        "all_word_embeddings = []\n",
        "all_words = []\n",
        "for word in list(w2v.vocab.keys())[:frequency_threshold]:\n",
        "    all_word_embeddings.append(w2v[word])\n",
        "    all_words.append(word)\n",
        "\n",
        "\n",
        "def return_cosine_sorted(target_word_embedding):\n",
        "    \"\"\"\n",
        "    all_word_embeddings で定義された単語ベクトルのリストから，cosine 類似度に基づいた np.array を返す\n",
        "    \"\"\"\n",
        "    words = []\n",
        "    cosines = []\n",
        "    for i in range(len(all_word_embeddings)):\n",
        "        cosines.append(1 - spatial.distance.cosine(target_word_embedding, all_word_embeddings[i]))\n",
        "\n",
        "    sorted_indexes = np.argsort(cosines)[::-1]\n",
        "    return np.vstack((np.array(all_words)[sorted_indexes], np.array(cosines)[sorted_indexes])).T\n",
        "\n",
        "\n",
        "def return_euclidean_sorted(target_word_embedding):\n",
        "    \"\"\"\n",
        "    all_word_embeddings で定義された単語ベクトルのリストから，Euclidean 類似度に基づいた np.array を返す\n",
        "    \"\"\"\n",
        "    words = []\n",
        "    euclideans = []\n",
        "    for i in range(len(all_word_embeddings)):\n",
        "        euclideans.append(spatial.distance.sqeuclidean(target_word_embedding, all_word_embeddings[i]))\n",
        "\n",
        "    sorted_indexes = np.argsort(euclideans)\n",
        "    return np.vstack((np.array(all_words)[sorted_indexes], np.array(euclideans)[sorted_indexes])).T\n",
        "\n",
        "\n",
        "def return_similar_words(word, top_n=5, sim='cos'):\n",
        "    \"\"\"\n",
        "    sim: 'cos' or 'euc' の差異によってどれくらい近接語が異なるのか？\n",
        "    \"\"\"\n",
        "    \n",
        "    if sim == 'cos':\n",
        "        return return_cosine_sorted(return_embedding(word))[1:top_n+1]\n",
        "    else:\n",
        "        return return_euclidean_sorted(return_embedding(word))[1:top_n+1]\n",
        "\n",
        "\n",
        "def return_embedding(word):\n",
        "    if word in all_words:\n",
        "        target_embedding_index = [i for i, s in enumerate(all_words) if word in s][0]\n",
        "        return all_word_embeddings[target_embedding_index]\n",
        "    else:\n",
        "        return None\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ff98X2e2TDca"
      },
      "source": [
        "for word in ['秋', 'ジャズ']:\n",
        "    print(f'{word}: {return_similar_words(word, sim=\"cos\", top_n=5)}')\n",
        "    print(f'{word}: {return_similar_words(word, sim=\"euc\", top_n=5)}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCYtIoH7TH16"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}