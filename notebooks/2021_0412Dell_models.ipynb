{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "2021-0412Dell_models.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/project-ccap/project-ccap.github.io/blob/master/notebooks/2021_0412Dell_models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81a960ad"
      },
      "source": [
        "# Simulations and explanation for the weight-decay and sp models\n",
        "- date: 2021-0412\n",
        "- author: Shin Asakawa\n",
        "- Origin: Foygel and Dell (2000) Models of Impaired Lexical Access in Speech Production, \n",
        "- Journal of Memory and Language 43, 182–216 (2000) doi:10.1006/jmla.2000.2716\n",
        "\n",
        "<!--\n",
        "## 蘊蓄\n",
        "\n",
        "ボックスアンドアローモデル，日本名，箱と矢印モデルの起源は，言うまでもなく，情報処理分野からの借用であろう。\n",
        "情報処理モデルを取り入れた，認知心理学関係者のモデルが認知心理学的症状を説明するために用いられたことが起源であろう。\n",
        "[Wikipedia の記述](https://en.wikipedia.org/wiki/Cognitive_model)でもそのように書かれている。\n",
        "ところで，ボックスアンドアローモデルを，\n",
        "２つに分けることができると思う。\n",
        "1. フローチャート型 flowchart\n",
        "2. 力学系型 dyanmical system\n",
        "\n",
        "慣例として，いずれのモデルでも，コンピュータコードとして実装が存在すると，計算モデルと呼ばれるようである。\n",
        "Marr の意味での 計算論モデル は数学的に記述可能なモデルを指す。一方，数学的な記述とは無関係に計算モデルと呼ばれることもある。\n",
        "\n",
        "神経心理学との関連で言えば，\n",
        "二重経路連接モデル (Coltheart ら,2000) はフローチャート型モデルである。\n",
        "一方，相互活性化モデル(McClelland and Rumelhart, 1981) は力学系型のモデルといえる。\n",
        "\n",
        "両者の相違を簡単に記述すると，以下のようになる:\n",
        "1. フローチャート型モデル: 箱の中で記述されている内容が実行されてから，次に矢印に示されている次の箱に処理を移し，次の箱によって指示されている処理が実行されると考える\n",
        "2. 力学系モデル: 箱の状態は時々刻々変化する。その変化が矢印を通じて他の箱に伝達される。矢印で指示された次の箱の処理は，前の箱の処理が終了することを仮定しないで自律的に動作する。言い換えれば，力学系モデルでは，各箱に状態が存在し，その状態が変動することを仮定する。\n",
        "\n",
        "一方で，フローチャートモデルでは，状態に重きを置くのではなく，手順として記述される。\n",
        "フローチャートで状態変化を記述することも可能であるし，力学系モデルで手順を記述することも可能である。\n",
        "このため両者は，しばしば同一視して用いられることもある。\n",
        "ある段階 (ステージ) が終了してから，次の段階が駆動されるような逐次段階を仮定する初期の，二重経路連接モデルと，各段階の状態が時間変動する相互活性化モデルとの相違である。\n",
        "\n",
        "いずれのモデルが優れている，劣っているということではない。\n",
        "そうではなく，両モデルの相違を念頭に置いて議論した方がモデルを評価する際に便利であろうと思う。\n",
        "\n",
        "ニューラルネットワーク用語で言えば，フローチャート型モデルの代表は，階層型ニューラルネットワークであり，力学系モデルの代表はリカレントニューラルネットワークである。\n",
        "階層型とリカレント型との両ニューラルネットワークの相違は，自己結合を持つか否かである。\n",
        "次式は，それぞれのニューラルネットワークの動作式を表している:\n",
        "\n",
        "$$\n",
        "\\begin{cases}\n",
        "y_i &= a\\left(\\sum_i w_ix_i + b_i\\right), \\hspace{3em}\\text{階層型の場合}\\\\\n",
        "y_{i,t+1} &= a\\left(y_{i,t}+\\sum_i w_ix_{i,t-1} + b_i\\right),\\hspace{3em}\\text{リカレント型}\n",
        "\\end{cases}\n",
        "$$ \n",
        "\n",
        "ここで，$y$:ニューロンの出力，$a$:出力関数, $w$:シナプス結合強度, $x$:ニューロンへ入力信号 を表す。\n",
        "-->"
      ],
      "id": "81a960ad"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "be31f5cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        },
        "outputId": "104cb5e5-602b-42be-9b6a-ccc66108dac0"
      },
      "source": [
        "from IPython import display\n",
        "\n",
        "print('Foygell and Dell (2000) Fig. 1. オリジナルは Dell (1997) 3 つの層の結合は双方向。\\n上から意味層, 語彙層, 音素層。最上層の意味層で 暗く塗りつぶされているニューロンは `cat`, `dog`, `rat` で共有されていることを示す。')\n",
        "\n",
        "display.Image(url='https://raw.githubusercontent.com/project-ccap/project-ccap.github.io/master/figures/2000Foygel_Dell_fig1.png', width=480)\n"
      ],
      "id": "be31f5cb",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Foygell and Dell (2000) Fig. 1. オリジナルは Dell (1997) 3 つの層の結合は双方向。\n",
            "上から意味層, 語彙層, 音素層。最上層の意味層で 暗く塗りつぶされているニューロンは `cat`, `dog`, `rat` で共有されていることを示す。\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<img src=\"https://raw.githubusercontent.com/project-ccap/project-ccap.github.io/master/figures/2000Foygel_Dell_fig1.png\" width=\"480\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "711a1c83",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "566e0552-cebe-4cf2-d539-f3341239f142"
      },
      "source": [
        "print('必要となるライブラリの読み込み...', end=\" \")\n",
        "import numpy as np\n",
        "import sys\n",
        "import time\n",
        "\n",
        "from numpy.random import Generator, PCG64\n",
        "rng = Generator(PCG64())\n",
        "#rng.standard_normal()\n",
        "\n",
        "# 表示精度桁数の設定\n",
        "#np.set_printoptions(suppress=False, formatter={'float': '{:7.4f}'.format})\n",
        "np.set_printoptions(suppress=False, formatter={'float': '{:6.3f}'.format})\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "#事前に japanize_matplotlib のインストールが必要です。次行，行頭の #を削除してく，このセルを実行してください\n",
        "!pip install japanize_matplotlib\n",
        "import japanize_matplotlib\n",
        "print('done')\n",
        "\n",
        "rng = Generator(PCG64())  # 乱数の定義"
      ],
      "id": "711a1c83",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "必要となるライブラリの読み込み... Collecting japanize_matplotlib\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/aa/85/08a4b7fe8987582d99d9bb7ad0ff1ec75439359a7f9690a0dbf2dbf98b15/japanize-matplotlib-1.1.3.tar.gz (4.1MB)\n",
            "\u001b[K     |████████████████████████████████| 4.1MB 5.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from japanize_matplotlib) (3.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->japanize_matplotlib) (2.8.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->japanize_matplotlib) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->japanize_matplotlib) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->japanize_matplotlib) (1.3.1)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib->japanize_matplotlib) (1.19.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->japanize_matplotlib) (1.15.0)\n",
            "Building wheels for collected packages: japanize-matplotlib\n",
            "  Building wheel for japanize-matplotlib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for japanize-matplotlib: filename=japanize_matplotlib-1.1.3-cp37-none-any.whl size=4120276 sha256=25996243b55ddea8f6b5e6645dfc19fc787c5afc5ef280c8bc9dddb14e47b7b1\n",
            "  Stored in directory: /root/.cache/pip/wheels/b7/d9/a2/f907d50b32a2d2008ce5d691d30fb6569c2c93eefcfde55202\n",
            "Successfully built japanize-matplotlib\n",
            "Installing collected packages: japanize-matplotlib\n",
            "Successfully installed japanize-matplotlib-1.1.3\n",
            "done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 696
        },
        "id": "3b86b5c2",
        "outputId": "649ab116-b9b5-4034-bf8b-61c529b69ac6"
      },
      "source": [
        "print('#Dell モデルの再現実験, 原著論文 Foygell and Dell (2000)を参照のこと')\n",
        "FoygellDell_tab1={\n",
        "    #Table 1 のデータ\n",
        "    'LH':[0.69,0.03,0.07,0.15,0.01,0.02],\n",
        "    'IG':[0.69,0.09,0.05,0.02,0.03,0.01]\n",
        "}\n",
        "\n",
        "FoygellDell_tab2_and_4={\n",
        "    #Table 2 に記載のデータ。小数点以下４桁目が必要なのか疑問。理由は PNT の検査図版は 175 枚しかない。\n",
        "    #どんなに努力しても一回の検査で得られるデータは 175 しかないのだから，小数点以下 2 桁で十分ではないかなー\n",
        "    #各行のデータ， 最初の 6 列は，それぞれののデータ，\n",
        "    #2行目最後の 4 列は weight, decay パラメータの推定値を表す. Foygell and Dell (2000)table 4 より引用\n",
        "    #3行目は Tab.4 の sp モデル\n",
        "    'W.B.': [[0.9400,0.0200,0.0100,0.0100,0.0100,0.0000,0.0200,0.5600, 0.0352, 0.0274],\n",
        "             [0.9416,0.0309,0.0063,0.0137,0.0054,0.0021,0.0255,0.5781,0.0054,2.282],\n",
        "             [0.9419,0.0282,0.0076,0.0172,0.0047,0.0004,0.0352,0.0274,0.0051, 2.194]],\n",
        "    'T.T.': [[0.9300,0.0100,0.0100,0.0000,0.0200,0.0000,0.0200,0.5600, 0.0340, 0.0866],\n",
        "             [0.9247,0.0496,0.0063,0.0055,0.0131,0.0008,0.0542,0.6758,0.0168,7.657],\n",
        "            [0.9689,0.0077,0.0109,0.0000,0.0125,0.0000,0.0340,0.0866,0.0162,1.194]],\n",
        "    'J.Fr.':[[0.9200,0.0100,0.0100,0.0200,0.0200,0.0000,0.0200,0.5600, 0.0316, 0.0305],\n",
        "             [0.9061,0.0536,0.0111,0.0160,0.0116,0.0016,0.0470,0.6602,0.0191,7.782],\n",
        "             [0.9332,0.0366,0.0074,0.0140,0.0070,0.0018,0.0316,0.0305,0.0135,8.566]],\n",
        "    'V.C.':[[0.8700,0.0200,0.0100,0.0300,0.0100,0.0000,0.0200,0.5700, 0.0407, 0.0229],\n",
        "            [0.9145,0.0390,0.0112,0.0265,0.0056,0.0032,0.0213,0.5703,0.0199,3.267],\n",
        "            [0.9317,0.0246,0.0079,0.0305,0.0053,0.0000,0.0407,0.0229,0.0253,1.694]],\n",
        "    'L.B.':[[0.8200,0.0400,0.0200,0.0900,0.0100,0.0100,0.0070,0.5000, 0.0274, 0.0221],\n",
        "            [0.8248,0.0528,0.0300,0.0708,0.0066,0.0150,0.0087,0.5156,0.0107,2.641],\n",
        "            [0.8213,0.0534,0.0273,0.0828,0.0075,0.0077,0.0274,0.0221,0.0070,1.306]],\n",
        "    'J.B.':[[0.7600,0.0600,0.0100,0.0500,0.0200,0.0100,0.0065,0.5000, 0.0264, 0.0246],\n",
        "            [0.8288,0.0798,0.0266,0.0374,0.0183,0.0091,0.0523,0.6953,0.0305,4.458],\n",
        "            [0.8419,0.0564,0.0259,0.0561,0.0084,0.0113,0.0264,0.0246,0.0345,6.088]],\n",
        "    'J.L.':[[0.7600,0.0300,0.0100,0.0600,0.0300,0.0100,0.0250,0.6000, 0.0255, 0.0221],\n",
        "            [0.8288,0.0798,0.0266,0.0374,0.0183,0.0091,0.0523,0.6953,0.0368,11.966],\n",
        "            [0.7921,0.0601,0.0375,0.0867,0.0107,0.0129,0.0255,0.0221,0.0251,14.040]],\n",
        "    'G.S.': [[0.7000,0.0200,0.0600,0.1500,0.0100,0.0200,0.0057,0.5000, 0.0246, 0.0191],\n",
        "             [0.6894,0.0673,0.0615,0.1404,0.0087,0.0327,0.0070,0.5156,0.0208,6.865],\n",
        "             [0.7182,0.0555,0.0505,0.1511,0.0080,0.0167,0.0246,0.0191,0.0168,4.570]],\n",
        "    'L.H.':[[0.6900,0.0300,0.0700,0.1500,0.0100,0.0200,0.0057,0.5000,0.0237,0.0178],\n",
        "            [0.6767,0.0700,0.0671,0.1466,0.0088,0.0308,0.0065,0.5117,0.0179,4.773],\n",
        "            [0.6712,0.0573,0.0661,0.1768,0.0085,0.0201,0.0237,0.0178,0.0175,3.166]],\n",
        "    'J.G.':[[0.5500,0.0600,0.0800,0.1800,0.0400,0.0300,0.0450,0.7000,0.0191,0.0172],    \n",
        "            [0.5543,0.1121,0.1091,0.1542,0.0246,0.0457,0.0514,0.7227,0.0281,8.988],\n",
        "            [0.5667,0.0746,0.0882,0.2170,0.0123,0.0412,0.0191,0.0172,0.0217,13.273]],\n",
        "    'E.G.':[[0.9300,0.0300,0.0000,0.0100,0.0200,0.0000,0.1000,0.6000,0.0316,0.0305],\n",
        "            [0.9222,0.0498,0.0017,0.0062,0.0199,0.0002,0.0698,0.7148,0.0089,2.129],\n",
        "            [0.9332,0.0336,0.0074,0.0140,0.0070,0.0018,0.0316,0.0305,0.0070,6.245]],\n",
        "    'B.Me.':[[0.8400,0.0300,0.0100,0.0000,0.0500,0.0100,0.1000,0.8200,0.0165,0.0866],\n",
        "             [0.8424,0.0925,0.0147,0.0216,0.0258,0.0030,0.0750,0.7617,0.0290,18.265],\n",
        "             [0.8468,0.0313,0.0938,0.0000,0.0177,0.0104,0.0165,0.0866,0.0368,23.438]],\n",
        "    'B.Mi.':[[0.8300,0.0500,0.0100,0.0100,0.0200,0.0100,0.0550,0.7000,0.0255,0.0328],\n",
        "             [0.8712,0.0620,0.0202,0.0280,0.0120,0.0066,0.0407,0.6484,0.0198,4.914],\n",
        "            [0.8973,0.0538,0.0181,0.0128,0.0078,0.0102,0.0255,0.0328,0.0282,5.012]],\n",
        "    'J.A.':[[0.7800,0.0400,0.0000,0.0200,0.0300,0.0100,0.0580,0.7000,0.0246,0.0294],\n",
        "            [0.8455,0.0824,0.0191,0.0259,0.0234,0.0037,0.0626,0.7227,0.0331,10.487],\n",
        "            [0.8627,0.0637,0.0263,0.0236,0.0093,0.0144,0.0246,0.0294,0.0378,15.927]],\n",
        "    'A.F.':[[0.7500,0.0200,0.0300,0.0700,0.0600,0.0400,0.1000,0.8500,0.0205,0.0229],\n",
        "            [0.7318,0.1004,0.0565,0.0679,0.0258,0.0176,0.0573,0.7246,0.0391,26.456],\n",
        "            [0.7113,0.0841,0.0644,0.0935,0.0123,0.0344,0.0205,0.0229,0.0401,45.699]],\n",
        "    'N.C.':[[0.7500,0.0300,0.0700,0.0800,0.0100,0.0000,0.1000,0.8500,0.0237,0.0221],\n",
        "            [0.7683,0.0621,0.0488,0.0929,0.0079,0.0200,0.0078,0.5156,0.0199,8.503],\n",
        "            [0.7693,0.0638,0.0479,0.0907,0.0082,0.0201,0.0237,0.0221,0.0205,8.810]],\n",
        "    'I.G.':[[0.6900,0.0900,0.0500,0.0200,0.0300,0.0100,0.1000,0.8600,0.0198,0.0340],\n",
        "            [0.7594,0.1116,0.0475,0.0457,0.0255,0.0103,0.0661,0.7500,0.0315,4.534],\n",
        "            [0.7948,0.0863,0.0544,0.0131,0.0138,0.0376,0.0198,0.0340,0.0449,10.018]],\n",
        "    'H.B.':[[0.6100,0.0600,0.1300,0.1800,0.0200,0.0100,0.0500,0.7130,0.0191,0.0172],\n",
        "            [0.5526,0.1002,0.1120,0.1697,0.0170,0.0485,0.0400,0.6816,0.0337,9.922],\n",
        "            [0.5667,0.0746,0.0882,0.2170,0.0123,0.0412,0.0191,0.0172,0.0322,10.628]],\n",
        "    'J.F.':[[0.5600,0.1400,0.0100,0.0200,0.1100,0.0100,0.1000,0.8600,0.0107,0.0365],\n",
        "            [0.7129,0.1359,0.0452,0.0587,0.0391,0.0082,0.0982,0.8594,0.0721,37.590],\n",
        "            [0.5237,0.1369,0.1662,0.0136,0.0178,0.1418,0.0107,0.0365,0.0928,131.684]],\n",
        "    'G.L.':[[0.2800,0.0400,0.2100,0.3000,0.0300,0.0900,0.0790,0.8500,0.0093,0.0154],\n",
        "            [0.2500,0.0985,0.2036,0.3121,0.0282,0.1076,0.0806,0.8594,0.0284,7.351],\n",
        "            [0.2716,0.1020,0.1565,0.3230,0.0137,0.1332,0.0093,0.0154,0.0397,15.974]],\n",
        "    'W.R.':[[0.0800,0.0600,0.1500,0.2800,0.0500,0.3300,0.1000,0.9400,0.0010,0.0178],\n",
        "            [0.1598,0.0859,0.2027,0.4039,0.0242,0.1235,0.0965,0.9336,0.1068,82.627],\n",
        "            [0.1343,0.1179,0.2319,0.2594,0.0132,0.2433,0.0010,0.0178,0.0610,37.527]]}\n",
        "\n",
        "\n",
        "def draw_dell_graph(A, B, \n",
        "                    title=None,\n",
        "                    width_inches=7, height_inches=4,\n",
        "                    alabel='健常統制群データ(Dell,1997)', acolor='red',\n",
        "                    blabel='beta 調整後のシミュレーション結果', bcolor='green',\n",
        "                    fontsize=16):\n",
        "    \"\"\"Dell モデルのグラフ描画\n",
        "    A と B 比較対象の２つのモデル出力について，６種類の反応カテゴリの\n",
        "    棒グラフを描画\n",
        "\n",
        "    引数:\n",
        "    A: np.array((6))\n",
        "    B: np.array((6))\n",
        "    出力値:\n",
        "        なし\n",
        "    \"\"\"\n",
        "    fig = plt.figure(figsize=(width_inches,height_inches))\n",
        "    ax = fig.add_axes([0,0,1,1])\n",
        "    X = np.arange(B.shape[0])\n",
        "    \n",
        "    ax.bar(X-0.2, A, color=acolor, width=0.4, label=alabel)\n",
        "    ax.bar(X+0.2, B, color=bcolor, width=0.4, label=blabel)\n",
        "    plt.legend(fontsize=fontsize)\n",
        "    if isinstance(title, str):\n",
        "        plt.title(title,fontsize=fontsize)\n",
        "    # https://www.javaer101.com/ja/article/5091810.html\n",
        "    ax.set_xticks(ax.get_xticks().tolist()) \n",
        "    ax.set_ylim(bottom=0, top=1.0)\n",
        "    ax.set_xticklabels(['', '正解', '意味エラー','形態エラー','混合エラー','無関連エラー', '非単語エラー', ''],fontsize=int(fontsize*0.8))\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "#plt.title('Dell(1997) Tab. 4 より作成:')\n",
        "# Dell(1997)による健常者のデータ\n",
        "Dells_controls = np.array([0.9690, 0.0120, 0.0010, 0.0090, 0.0030, 0.0000])  \n",
        "\n",
        "# Dell(1997)による WD モデルのデータ\n",
        "Dells_WD = np.array([0.9660, 0.0210, 0.0000, 0.0120, 0.0000, 0.0010])  \n",
        "draw_dell_graph(Dells_controls, Dells_WD, \n",
        "                title='Dell model の結果図示',\n",
        "                alabel=\"Dell(1997)健常者のデータ\", \n",
        "                blabel=\"Dell(1997) WD モデル\")\n",
        "\n",
        "# Foygel & Dell(2000)による SP モデルのデータ, Tab. 3 Foygel and Dell (2000)\n",
        "Dells_SP = np.array([0.9722, 0.0126, 0.0011, 0.0138, 0.0002, 0.0001])  \n",
        "draw_dell_graph(Dells_controls, Dells_SP, \n",
        "                alabel=\"Dell(1997)健常者のデータ\", \n",
        "                blabel=\"Dell(1997) SP モデル\")\n"
      ],
      "id": "3b86b5c2",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "#Dell モデルの再現実験, 原著論文 Foygell and Dell (2000)を参照のこと\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 504x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 504x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d09fbca4-5433-44de-bcf2-aea3b8660afd"
      },
      "source": [
        "def draw_dell_graph3(A, B, C, name='noname',\n",
        "                     title = None,\n",
        "                     acolor='green', bcolor='red', ccolor='blue',\n",
        "                     alabel='健常統制群データ(Dell,1997)', \n",
        "                     blabel='Weight decay',\n",
        "                     clabel='s-p model',\n",
        "                     width_inches=4, height_inches=3,\n",
        "                     fontsize=12):\n",
        "    \"\"\"Dell モデルのグラフ描画\n",
        "    A, B, C 比較対象の 3 つのモデル出力について，６種類の反応カテゴリの棒グラフを描画\n",
        "\n",
        "    引数:\n",
        "    A: np.array((6))\n",
        "    B: np.array((6))\n",
        "    C: np.array((6))\n",
        "    出力値:\n",
        "        なし\n",
        "    \"\"\"\n",
        "    fig = plt.figure(figsize=(width_inches,height_inches))\n",
        "    ax = fig.add_axes([0,0,1,1])  #  [left, bottom, width, height] of the new axes\n",
        "    A, B, C = np.array(A[:6]), np.array(B[:6]), np.array(C[:6])\n",
        "    X = np.arange(B.shape[0])\n",
        "    \n",
        "    ax.bar(X-0.2, A, color=acolor, width=0.2, label=alabel)\n",
        "    ax.bar(X    , B, color=bcolor, width=0.2, label=blabel)\n",
        "    ax.bar(X+0.2, C, color=ccolor, width=0.2, label=clabel)\n",
        "    plt.legend(fontsize=fontsize)\n",
        "    if isinstance(title, str):\n",
        "        plt.ttile(title)\n",
        "\n",
        "    # https://www.javaer101.com/ja/article/5091810.html\n",
        "    ax.set_xticks(ax.get_xticks().tolist()) \n",
        "    ax.set_ylim(bottom=0, top=1.0)\n",
        "    ax.set_title('Patient {0}'.format(name))\n",
        "    ax.set_xticklabels(['', '正解', '意味エラー','形態エラー','混合エラー','無関連エラー', '非単語エラー', ''],fontsize=int(fontsize*0.8))\n",
        "    plt.show()\n",
        "\n"
      ],
      "id": "d09fbca4-5433-44de-bcf2-aea3b8660afd",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05ea4483-dcb5-4618-82ac-c6fbc8221764"
      },
      "source": [
        "np.set_printoptions(suppress=False, formatter={'float': '{:4.2f}'.format})\n",
        "\n",
        "print('#Dell のデータ, 実データ, wd model, sp model, Foygell and Dell (2000) Table 2 and 4 を参照のこと')\n",
        "for patient in FoygellDell_tab2_and_4:\n",
        "    data_n = 0\n",
        "    data_n_wd = 1\n",
        "    data_n_sp = 2\n",
        "    data = np.array(FoygellDell_tab2_and_4[patient][data_n][:6])\n",
        "    wd_data = np.array(FoygellDell_tab2_and_4[patient][data_n_wd][:6])\n",
        "    sp_data = np.array(FoygellDell_tab2_and_4[patient][data_n_sp][:6])\n",
        "    print('{0:5s} {1} {2} {3}'.format(patient, data, wd_data, sp_data))\n",
        "    draw_dell_graph3(data, wd_data, sp_data, name=patient, \n",
        "                     alabel=patient, blabel='WD モデル推定値', clabel='SP モデル推定値',\n",
        "                     width_inches=6, height_inches=3, \n",
        "                     fontsize=12, \n",
        "                     ccolor='black', acolor='gray', bcolor='pink')\n"
      ],
      "id": "05ea4483-dcb5-4618-82ac-c6fbc8221764",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48d9cf0b",
        "outputId": "51a6892d-bbed-4cff-e4b8-63bf3208d505"
      },
      "source": [
        "print('#ニューラルネットワーク業界で頻用される出力関数の一行野郎 one liner 定義...', end='')\n",
        "sigmoid = lambda x: 1/(1+np.exp(-x)) # ロジスティックシグモイド関数\n",
        "d_sigmoid = lambda x: x * (1-x)\n",
        "\n",
        "ReLU = lambda x: np.maximum(0, x)\n",
        "d_ReLU = lambda x:[1 if x_ > 0 else 0 for x_ in x]\n",
        "\n",
        "tanh = lambda x: np.tanh(x)\n",
        "d_tanh = lambda x: 1 - x**2\n",
        "print('done')\n",
        "\n",
        "print('#ソフトマックス関数の定義...', end='')\n",
        "def softmax(x, beta=1.):\n",
        "    \"\"\"softmax 関数の定義\n",
        "    引数\n",
        "    x: np.array\n",
        "        softmax を行う変数群，ベクトルを仮定\n",
        "    beta: float\n",
        "        逆温度，この値の逆数が温度\n",
        "        \n",
        "    戻り値\n",
        "    x.shape[0] 次元の多項確率密度\n",
        "    \"\"\"\n",
        "    if not isinstance(x, np.ndarray):\n",
        "        return None\n",
        "\n",
        "    if x.ndim == 1:\n",
        "        return np.exp(x * beta)/np.exp(x * beta).sum()\n",
        "    else:\n",
        "        return np.array([np.exp(x_ * beta)/np.exp(x_ * beta).sum() for x_ in x])\n",
        "\n",
        "print('done')\n",
        "\n",
        "print('#交差エントロピー誤差関数との定義...', end='')\n",
        "def CE_loss(teach, pred):\n",
        "    \"\"\"\n",
        "    交差エントロピー誤差の計算\n",
        "    - 引数\n",
        "    teach: np.array\n",
        "        教師信号ベクトル\n",
        "    pred: np.array\n",
        "        予測値ベクトル\n",
        "            \n",
        "    - 戻り値\n",
        "    loss: float\n",
        "        損失関数の値\n",
        "    \"\"\"\n",
        "    epsilon = np.finfo(np.float).eps\n",
        "    #epsilon = 0.001\n",
        "    #loss = - (teach * np.log(pred) + (1-teach) * np.log(1-pred)).sum()\n",
        "    loss = 0.\n",
        "    for t, p in zip(teach, pred):\n",
        "        if t > epsilon and p > epsilon:\n",
        "            loss += t * np.log(p)\n",
        "            \n",
        "    return -1. * loss\n",
        "\n",
        "print('done')\n"
      ],
      "id": "48d9cf0b",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "#ニューラルネットワーク業界で頻用される出力関数の一行野郎 one liner 定義...done\n",
            "#ソフトマックス関数の定義...done\n",
            "#交差エントロピー誤差関数との定義...done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "18cb6650"
      },
      "source": [
        "# メモ\n",
        "<!--\n",
        "上の２つの結合係数行列は Dell らが用いたものである。ところがこの結合係数行列を\n",
        "相関係数行列で置き換えることができるだろう。そう考えて，相関係数行列を計算してみたのが上のセルの出力中では下２つの行列である。\n",
        "\n",
        "* **相関係数で考えておく理由**は次の通り:<br/>\n",
        "Dell らは入力層のニューロン数を 54 個としている。ところが実際に動物を表現しているニューロン数は誰も数えたことが無いし，しかも，数えることが現時点では不可能である。\n",
        "また，人によっても異なるであろう。\n",
        "そのため 54 個というニューロン数の決定について恣意的であると言わざるを得ない。\n",
        "ニューロン個数の恣意性を排除するために，各ニューロンを抽象化かつ簡便化すると，各概念について一つだけのニューロンを用意することが最小構成となる。\n",
        "\n",
        "そのために，以下では，\n",
        "1. Dell モデルのニューロン個数を用いた再現実験と，その後，\n",
        "2. 相関係数行列を用いた改変モデルを示す。さらに，\n",
        "3. Dell モデルでは説明の困難なパラメータ推定問題について，勾配降下法を用いて解決する方法を示す。さらに，その後，\n",
        "4. 任意の単語に拡張し，日本語版も示すことにする。\n",
        "-->"
      ],
      "id": "18cb6650"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5e1ff189"
      },
      "source": [
        "\n",
        "合成関数の微分則から，損失関数をパラメータ $\\mathbf{\\theta}$ の各成分 $\\beta,\\theta_d,\\theta_s,\\theta_p$ で微分することで勾配降下法による学習を定義できる。\n",
        "Dell の動作方程式を若干書き換える\n",
        "\n",
        "$$\n",
        "x_{t+1} = (1-d)x_t + \\theta_{s,p} \\sum_i w_i x_i +\\mathcal{N}(0,a_1^2+a_2^2)\\hspace{1em}\\text{(Dell's original)}\n",
        "$$\n",
        "\n",
        "$$\n",
        "y_{i,t+1} = a\\left((1-\\theta_d)x_{i,t} + \\theta_{s,p} \\sum_j w_{j,t-1} x_{j,t}+b_i\\right) \\hspace{1em}\\text{(modified)}\n",
        "$$\n",
        "\n",
        "ここで， $a$ は活性化関数である。$a=\\mathbb{1}$ のとき Dell モデルに一致する。\n",
        "$y$ は出力値， $x$ は内部状態とする。元来，Dell モデルは RNN とみなせるで，内部状態と外部出力とを区別することが妥当であると思われる。 \n",
        "\n",
        "\\begin{equation}\n",
        "\\begin{split}\n",
        "\\frac{\\partial l}{\\partial \\theta}&=\\frac{\\partial l}{\\partial p}\\frac{\\partial p}{\\partial{y}}\\frac{\\partial y}{\\partial \\theta}\\\\\n",
        "&\\sum_i\\frac{t_i-p_i}{p_i\\left(1-p_i\\right)}\\sum_j p_j\\left(\\delta_{ij}-p_j\\right)\\frac{\\partial y_j}{\\partial\\theta}\\\\\n",
        "\\end{split}\n",
        "\\end{equation}\n",
        "ここで $\\delta_{ij}$ は Dirac の delta であるとする。\n",
        "\n",
        "$a$ が Dell の 式(1) であるとすると $\\partial l/\\partial\\theta$ は次式のようになる:\n",
        "\\begin{equation}\n",
        "\\begin{split}\n",
        "\\frac{\\partial l}{\\partial\\theta}&=\\sum_i\\frac{t_i-p_i}{p_i\\left(1-p_i\\right)}\\sum_j p_i\\left(\\delta_{ij}-p_j\\right) \\frac{d}{da_j}\\frac{\\partial a_j}{\\partial\\theta}\\hspace{5cm}\\text{ここで， $\\frac{d}{da_j}\\frac{\\partial a_j}{\\partial\\theta}=c_j$ とおくと}\\\\\n",
        "&=\\sum_i\\frac{t_i-p_i}{p_i\\left(1-p_i\\right)}p_i\\left(c_i-\\sum_jp_jc_j\\right)\\\\\n",
        "&=\\sum_i\\frac{t_i-p_i}{1-p_i}\\left(c_i-\\bar{c}\\right),\\\\\n",
        "\\end{split}\n",
        "\\end{equation}\n",
        "ただし，$\\mu_{x_{t-1}}$ は下位層のニューロンの出力に確率 $p_i$ を掛けて総和したもの，すなわち平均である。\n",
        "\n",
        "\n"
      ],
      "id": "5e1ff189"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "db8ab63f"
      },
      "source": [
        "以下では， \n",
        "- $t_i$: `teacher`\n",
        "- $p_i$: `pred`\n",
        "- $t_i-p_i$: `delta`"
      ],
      "id": "db8ab63f"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b000dd43"
      },
      "source": [
        "class Dell2021():\n",
        "    \"\"\"Optimization for the Foygell and Dell model's parameter vector.\n",
        "    ソフトマックス関数により多項分布の確率密度に変換した値から\n",
        "    損失関数を算出し，その損失間数値に基づいて勾配降下法に従って各パラメータ最適化を行う\n",
        "    ただし beta は逆温度である。1/beta が実際の温度\n",
        "    \n",
        "    $\\beta$ に加えて，$\\theta=(w,d,s,p)$ についても $\\partial l/\\partial\\theta$ を用いて\n",
        "    更新する\n",
        "    \"\"\"\n",
        "    \n",
        "#    def __init__(self, w=0.1, d=0.5, s=0.0698, p=0.1,\n",
        "    def __init__(self, d=0.5, param=None, # w=0.1, d=0.5, s=1., p=1.,\n",
        "                 beta_init=1., iter_max=10**5, lr=0.5, \n",
        "                 time_n = 16,\n",
        "                 teacher=None,\n",
        "                 interval=None, verbose=True, nonstop=False,\n",
        "                 IFG_beta=15.,  # 頭頂葉の関与を表す\n",
        "                 f=tanh, Weights='R', model='WD', data=None):\n",
        "        \"\"\"\n",
        "        - 引数\n",
        "        beta_init: float\n",
        "            ソフトマックス関数を計算する際に用いる温度パラメータの初期値\n",
        "        iter_max: int\n",
        "            繰り返し回数の上限値。Dell のオリジナルモデルは iter_max = 16 に固定されていた\n",
        "        lr: float\n",
        "            学習係数\n",
        "        interval: int\n",
        "            途中結果を出力する際の間隔。\n",
        "            デフォルトでは iter_max の 1/10 毎に途中結果を出力する\n",
        "        verbose: bool\n",
        "            True なら途中結果の冗長な出力を印字する\n",
        "            デフォルト: True\n",
        "        nonstop: bool\n",
        "            途中で学習を打ち切るフラグ\n",
        "            デフォルト: False\n",
        "        f: function\n",
        "            出力関数\n",
        "        W: str\n",
        "            'R': 相関係数行列を用いる\n",
        "            'softmax': 相関係数をソフトマックスに変換して用いる\n",
        "            else: 相関係数行列のソフトマックス変換を用いる\n",
        "        \"\"\"\n",
        "        self.sem_jolt = 10 # 元論文 (Foygell and Dell, 2000) page 185 footnote\n",
        "        self.lex_jolt = 100\n",
        "        self.jolt_t = 7  # カウントが 0 ベースなので t=7 (8-1) が 8 回目\n",
        "        \n",
        "        if param == None:\n",
        "            self.param = {'WD':{'Weight':0.1,  # for normal\n",
        "                                'Decay':0.5    # for normal\n",
        "                               },\n",
        "                          'SP':{'Decay': 0.6,\n",
        "                                'S_Weight':0.0698,\n",
        "                                'P_Weight':0.1000\n",
        "                               }}\n",
        "        else:\n",
        "            self.param = param\n",
        "\n",
        "        if model=='WD':\n",
        "            self.s, self.p = self.param['WD']['Weight'], self.param['WD']['Weight']\n",
        "        else:\n",
        "            self.s, self.p = self.param['SP']['S_Weight'], self.param['SP']['P_Weight']\n",
        "\n",
        "\n",
        "        # 音素の定義\n",
        "        self.phonemes = {'onset':['f', 'r', 'd', 'k', 'm'],\n",
        "                         'vowel':['ae', 'o'],\n",
        "                         'coda':['t','g']}\n",
        "        self.Onset, self.Vowel, self.Coda = slice(0,5), slice(5,7), slice(7,9)\n",
        "\n",
        "        self.teacher = teacher\n",
        "        self.data = None\n",
        "        self.nonstop = nonstop\n",
        "        self.beta = beta_init\n",
        "        self.iter_max = iter_max\n",
        "        self.lr = lr\n",
        "        if interval == None:\n",
        "            # interval が定義されていなければ設定する\n",
        "            self.interval = iter_max * 10**-1\n",
        "        else:\n",
        "            self.interval = interval\n",
        "        if verbose == None:\n",
        "            self.verbose = False\n",
        "        else:\n",
        "            self.verbose = True\n",
        "        #self.epsilon = 10 ** -5\n",
        "        self.epsilon = np.finfo(np.float).eps\n",
        "\n",
        "        self.max_t = 16  # Dell の 1 試行あたりの繰り返し数 相互活性化モデルでの繰り返し更新回数\n",
        "\n",
        "        self.Weights = Weights\n",
        "        if self.Weights == 'R':              #相関係数\n",
        "            _, self.Ws, _ = self.init_Ws()\n",
        "            _, self.Wp, _ = self.init_Wp()\n",
        "        elif self.Weights == 'softmax':      #ソフトマックス\n",
        "            _, _, self.Ws = self.init_Ws()\n",
        "            _, _, self.Wp = self.init_Wp()\n",
        "        else:                                #オリジナル\n",
        "            self.Ws, _, _ = self.init_Ws()\n",
        "            self.Wp, _, _ = self.init_Wp()\n",
        "        self.lexicon_candidates = list(self.phonology.keys())\n",
        "\n",
        "        # nubmer of neurons of each layer\n",
        "        #self.n_sem, self.n_lex, self.n_pho, self.n_phon = 6, 6, 6, 9\n",
        "        self.n_sem = self.Ws.shape[1]\n",
        "        self.n_lex = self.Ws.shape[0]\n",
        "        if self.n_lex != self.Wp.shape[0]:  #整合性チェックのため\n",
        "            assert('self.n_lex != self.Wp.shape[0]:')\n",
        "        self.n_pho = self.Wp.shape[1]\n",
        "\n",
        "        self.sem_slice = slice(0,                    self.n_sem)\n",
        "        self.lex_slice = slice(self.n_sem,           self.n_sem+self.n_lex)\n",
        "        self.pho_slice = slice(self.n_sem+self.n_lex,self.n_sem+self.n_lex+self.n_pho)\n",
        "\n",
        "        self.time_n = time_n\n",
        "        self.IFG_beta = IFG_beta\n",
        "        self.decay = d\n",
        "        #self.a1, self.a2 = 0.01, 0.16\n",
        "        self.a1, self.a2 = 0., 0.\n",
        "        self.f = f\n",
        "\n",
        "        self.W = self.make_W()\n",
        "        if data == None:\n",
        "            self.teacher = np.array([0.97, 0.01, 0.00, 0.01, 0.00, 0.00])\n",
        "            self.one_trial(verbose=verbose)\n",
        "        else:\n",
        "            init_neurons()\n",
        "            self.data = data\n",
        "\n",
        "        return\n",
        "\n",
        "\n",
        "    def init_Ws(self):\n",
        "        Ws = np.array([[1,1,1,1,1,1,1,1,1,1, 0,0,0,0,0,0,0,0,0,0, \n",
        "                        0,0,0,0,0,0,0,0,0,0, 0,0,0,0,0,0,0,0,0,0,\n",
        "                        0,0,0,0,0,0,0,0,0,0, 0,0,0,0],             # cat 正解\n",
        "                       [0,0,0,0,0,0,0,1,1,1, 1,1,1,1,1,1,1,0,0,0, \n",
        "                        0,0,0,0,0,0,0,0,0,0, 0,0,0,0,0,0,0,0,0,0, \n",
        "                        0,0,0,0,0,0,0,0,0,0, 0,0,0,0],             # dog 意味エラー\n",
        "                       [0,0,0,0,0,0,0,0,0,0, 0,0,0,0,0,0,0,1,1,1, \n",
        "                        1,1,1,1,1,1,1,0,0,0, 0,0,0,0,0,0,0,0,0,0,\n",
        "                        0,0,0,0,0,0,0,0,0,0, 0,0,0,0],             # mat 形態エラー\n",
        "                       [0,0,0,0,0,0,0,1,1,1, 0,0,0,0,0,0,0,0,0,0, \n",
        "                        0,0,0,0,0,0,0,1,1,1, 1,1,1,1,0,0,0,0,0,0,\n",
        "                        0,0,0,0,0,0,0,0,0,0, 0,0,0,0],             # rat 混合エラー\n",
        "                       [0,0,0,0,0,0,0,0,0,0, 0,0,0,0,0,0,0,0,0,0, \n",
        "                        0,0,0,0,0,0,0,0,0,0, 0,0,0,0,1,1,1,1,1,1,\n",
        "                        1,1,1,1,0,0,0,0,0,0, 0,0,0,0],             # fog 無関連エラー\n",
        "                       [0,0,0,0,0,0,0,0,0,0, 0,0,0,0,0,0,0,0,0,0, \n",
        "                        0,0,0,0,0,0,0,0,0,0, 0,0,0,0,0,0,0,0,0,0,\n",
        "                        0,0,0,0,1,1,1,1,1,1, 1,1,1,1]              # lat 非単語\n",
        "                      ], dtype=np.float)\n",
        "        Ws *= self.s\n",
        "        R_ws = np.corrcoef(Ws)\n",
        "        return Ws, R_ws, softmax(R_ws,beta=1)\n",
        "\n",
        "\n",
        "    def init_Wp(self):\n",
        "        # 語彙層と音韻層とを結ぶ結合係数行列の定義\n",
        "        #                                     f.   r.   d.   k.   m.   ae.  o.   t.   g\n",
        "        self.phonology = {'cat': np.array([ 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0]),  # correct\n",
        "                          'dog': np.array([ 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0]),  # semantic error\n",
        "                          'mat': np.array([ 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0]),  # formal error\n",
        "                          'rat': np.array([ 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0]),  # mixed error\n",
        "                          'fog': np.array([ 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0]),  # unrelated error\n",
        "                          'lat': np.array([ 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0])}  # nonword\n",
        "        # phonology は BOW 形式なんですなー\n",
        "        Wp = np.zeros((len(self.phonology), len(self.phonology['cat'])), dtype=np.float)\n",
        "        for i, x in enumerate(self.phonology.values()):\n",
        "            Wp[i] = np.copy(x)\n",
        "\n",
        "        Wp *= self.p\n",
        "        R_wp = np.corrcoef(np.array([self.phonology[item] for item in self.phonology]))\n",
        "        return Wp, R_wp, softmax(R_wp, beta=1)\n",
        "\n",
        "\n",
        "    def make_W(self):\n",
        "        \"\"\"大きな遷移行列の作成\n",
        "            意味，語彙，音韻の3層を一列にならべてベクトル表現した場合\n",
        "    \n",
        "        戻り値:\n",
        "        - W: np.array\n",
        "            単一結合係数行列\n",
        "        \"\"\"\n",
        "        if self.Weights == 'R':              #相関係数\n",
        "            _, self.Ws, _ = self.init_Ws()\n",
        "            _, self.Wp, _ = self.init_Wp()\n",
        "        elif self.Weights == 'softmax':      #ソフトマックス\n",
        "            _, _, self.Ws = self.init_Ws()\n",
        "            _, _, self.Wp = self.init_Wp()\n",
        "        else:                                #オリジナル\n",
        "            self.Ws, _, _ = self.init_Ws()\n",
        "            self.Wp, _, _ = self.init_Wp()\n",
        "\n",
        "        nL, nS, nP = self.n_lex, self.n_sem, self.n_pho\n",
        "        \n",
        "        Isem, Ilex, Ipho = np.eye(nS), np.eye(nL), np.eye(nP)\n",
        "        Dsem, Dlex, Dpho = np.eye(nS) * self.decay, np.eye(nL) * self.decay, np.eye(nP) * self.decay\n",
        "        \n",
        "        Z_sl = np.zeros((nS, nP))\n",
        "        c1 = np.concatenate((Isem-Dsem, self.Ws.T, Z_sl), axis=1)\n",
        "        c2 = np.concatenate((self.Ws, Ilex-Dlex, self.Wp), axis=1)\n",
        "        c3 = np.concatenate((Z_sl.T, self.Wp.T, Ipho-Dpho), axis=1)\n",
        "        W = np.concatenate((c1,c2,c3))\n",
        "        return W\n",
        "\n",
        "    \n",
        "    def init_neurons(self):\n",
        "        \"\"\"各層のニューロンを初期化\"\"\"\n",
        "        Sem = np.zeros([self.n_sem,], dtype=np.float)  # 意味層\n",
        "        Lex = np.zeros([self.n_lex,], dtype=np.float)  # 語彙層\n",
        "        Pho = np.zeros([self.n_pho,], dtype=np.float)  # 音韻層\n",
        "        \n",
        "        # Sem[0] すなわち cat 画像だけ 1 に設定する。すなわちネコ画像が入力されたことを意味\n",
        "        #Sem[0] = 1.                   \n",
        "        Sem[:10] = np.copy(np.ones(10)) * self.sem_jolt\n",
        "\n",
        "        ret = np.concatenate((Sem,Lex,Pho))  # 一行のベクトルになるように改変\n",
        "        return ret\n",
        "\n",
        "    \n",
        "    def split(self, X=None):\n",
        "        if not isinstance(X, np.ndarray):\n",
        "            X = np.copy(self.y)\n",
        "        #s,l,p = np.copy(self.y[self.sem_slice]), np.copy(self.y[self.lex_slice]), np.copy(self.y[self.pho_slice])\n",
        "        s,l,p = np.copy(X[self.sem_slice]), np.copy(X[self.lex_slice]), np.copy(X[self.pho_slice])\n",
        "        \n",
        "        return s, l, p\n",
        "\n",
        "    \n",
        "    def merge(self, s, l, p):\n",
        "        ret = np.concatenate((s,l,p))\n",
        "        return ret\n",
        "\n",
        "    \n",
        "    #def update(self, Sem, Lex, Pho, f=None):\n",
        "    def update(self, f=None):\n",
        "        \"\"\"Dell の 3 層相互活性化モデルに従って各層のニューロンの活性値を更新\n",
        "    \n",
        "        引数:\n",
        "        - f: function\n",
        "            出力関数。指定しなければ変換せずに値を出力\n",
        "            Dell らのモデルは恒等写像。そのため各ニューロンの活性値が指数関数的増加，減衰を示す。\n",
        "            それを回避するためには何らかの正規化，正則化が必要になると考えられる。\n",
        "            Sigmoid, tanh, ReLu, \n",
        "    \n",
        "        戻り値:\n",
        "        #- Sem_next: np.array\n",
        "        #    次刻の意味層ベクトル\n",
        "        #- Lex_next: np.array\n",
        "        #    次刻の語彙層ベクトル\n",
        "        #- Pho_next: np.array\n",
        "        #    次刻の音韻層ベクトル\n",
        "        \"\"\"\n",
        "        \n",
        "        self.Sem, self.Lex, self.Pho = self.split(self.y)\n",
        "        Sem_next = self.Sem * (1. - self.decay) + self.s * np.matmul(self.Ws.T, self.Lex)\n",
        "        Lex_next = self.Lex * (1. - self.decay) + self.s * np.matmul(self.Ws, self.Sem) + self.p * np.matmul(self.Wp, self.Pho)\n",
        "        Pho_next = self.Pho * (1. - self.decay) + self.p * np.matmul(self.Wp.T, self.Lex)\n",
        "    \n",
        "        # ノイズの付加\n",
        "        for x in [Sem_next, Lex_next, Pho_next]:\n",
        "            for i, xx in enumerate(x):\n",
        "                xx += rng.standard_normal() * (self.a1 + self.a2 * xx)\n",
        "                #x[i] = max(0, xx)  # ReLU\n",
        "\n",
        "        # 非線形変換 or not\n",
        "        if f == None:\n",
        "            self.Sem, self.Lex, self.Pho = Sem_next, Lex_next, Pho_next \n",
        "        else:\n",
        "            self.Sem, self.Lex, self.Pho = f(Sem_next), f(Lex_next), f(Pho_next)\n",
        "            \n",
        "        #return self.Sem, self.Lex, self.Pho\n",
        "        return self.merge(self.Sem, self.Lex, self.Pho)\n",
        "\n",
        "\n",
        "    def grad(self, Teach, X):\n",
        "        # 予測値\n",
        "        Prob = softmax(X, beta=self.beta)  \n",
        "        \n",
        "        # 教師信号と出力値との差分ベクトル\n",
        "        Delta = Teach - Prob\n",
        "        \n",
        "        # 誤差の微分\n",
        "        g_Delta = Delta / (Prob * (1-Prob)) \n",
        "        \n",
        "        return Prob, Delta, g_Delta\n",
        "\n",
        "    \n",
        "    def IFG_process(self):\n",
        "        \"\"\"IFg: Inferior Frontal gyrus から／へ の相互作用を実現する\n",
        "        \"\"\"\n",
        "        ##self.Sem = softmax(self.Sem, beta=beta_fixed)\n",
        "        #Lex = self.y[self.n_sem:self.n_sem+self.n_lex]\n",
        "        #Lex = softmax(Lex, beta=self.IFG_beta)\n",
        "        \n",
        "        #Pho = self.y[self.n_sem+self.n_lex:]\n",
        "        #Pho = softmax(Pho, beta=self.IFG_beta)\n",
        "        \n",
        "        #self.y[self.n_sem:self.n_sem+self.n_lex] = np.copy(Lex)\n",
        "        #self.y[self.n_sem+self.n_lex:] = np.copy(Pho)\n",
        "        #self.Lex = softmax(self.Lex, beta=self.IFG_beta)\n",
        "        #self.Pho = softmax(self.Pho, beta=self.IFG_beta)\n",
        "\n",
        "        Sem, Lex, Pho = self.split()\n",
        "        self.y[self.lex_slice] = np.copy(softmax(Lex))\n",
        "        \n",
        "        \n",
        "    def one_trial(self, verbose=False):\n",
        "        \"\"\"Dell モデルの一試行を実施\n",
        "        言い換えれば一枚のネコ画像を提示して反応を収集\n",
        "        \n",
        "        argments:\n",
        "        max_t: int\n",
        "            相互活性化モデルでの最終時刻，相互活性を繰り返す回数の上限値\n",
        "            デフォルトでは 16 回。\n",
        "            原著論文 (Foygell and Dell, 2000) では n と記載されている\n",
        "        beta_fixed: float\n",
        "            前頭葉 へ／から の相互作用の影響を制御するパラメータ\n",
        "            実際にはソフトマックス関数の温度パラメータ\n",
        "            \n",
        "        returns:\n",
        "        self.y: np.array\n",
        "            \n",
        "        sefl.seriesY: np.array((self.y, max_t))\n",
        "            各層の履歴\n",
        "        \"\"\"\n",
        "        time_n = self.time_n\n",
        "        self.y = self.init_neurons()       #各層のニューロンの初期値の設定\n",
        "\n",
        "        # BPTT を用いて, w, d, s, p の各パラメータを更新するため各ニューロンの履歴を保存領域の確保\n",
        "        self.seriesY = np.zeros((time_n, len(self.y)), dtype=np.float)\n",
        "        \n",
        "        for t in range(self.max_t):\n",
        "            if t == self.jolt_t:\n",
        "                s,l,p = self.split()\n",
        "                l[np.argmax(l)] = self.lex_jolt\n",
        "                self.y[self.lex_slice] = np.copy(l)\n",
        "\n",
        "            if verbose:\n",
        "                if t == 0:\n",
        "                    print('         {0}'.format(self.lexicon_candidates))\n",
        "                    \n",
        "                lex = self.convert_onset_vowel_coda_2_lexicon(self.y)\n",
        "                pred = softmax(lex, beta=self.beta)\n",
        "                loss = CE_loss(self.teacher, pred)\n",
        "                print('t={0:02d} lex:{1}'.format(t+1, self.y[self.lex_slice]), end=' ')\n",
        "                print('pred:{0} loss:{1:.3f} beta:{2:.3f}'.format(pred, loss, self.beta))\n",
        "\n",
        "            self.seriesY[t] = np.copy(self.y)\n",
        "            self.y = np.dot(self.W, self.y)   #各層のニューロンの値を更新 \n",
        "            \n",
        "        return self.y, self.seriesY\n",
        "\n",
        "\n",
        "    #def convert_onset_vowel_coda_2_lexicon_invert(self, X, verbose=False):\n",
        "    def convert_onset_vowel_coda_2_lexicon(self, X, verbose=False):\n",
        "        \"\"\"phonlogy 表現からもっともらしい語彙表現を検索し，その当てはまり度合いから\n",
        "        語彙表象の値を返すことを考える。\n",
        "        今一つのアイデアとしては，\n",
        "        phonolgy から lexicon への逆変換を考えて，そこでの値をソフトマックスする。\n",
        "        1. phonolgy 層を onset, vowel, coda の 3 部分に分解\n",
        "        2. 分解した各音で softmax を実施し確率密度に変換\n",
        "        3. 3 つの部分を合成して phoneme 表現とする\n",
        "        4. phoneme 表現と phonology の 6 単語間の交差エントロピー誤差を計算する\n",
        "        5. 6 単語との交差エントロピー誤差の値から，最小値を引き， (最大値-最小値) で割ることで 0-1 に変換\n",
        "        6. マイナス 1 を掛けて 上限反転させて +1 することで， 0 から 1 までの値にする\n",
        "        \"\"\"\n",
        "        val = np.finfo(np.float).max     #np で定義済の安全な最大値を代入\n",
        "        #val = 0.\n",
        "        name = 'NG'                      #len(words) + 1 語彙名のダミー\n",
        "        s, lexeme, phoneme = self.split(X)\n",
        "        lex = np.dot(self.Wp, phoneme)\n",
        "        #lex = sigmoid(lex)\n",
        "        return lex\n",
        "        \n",
        "        for i, word in enumerate(self.phonology):\n",
        "            loss = CE_loss(phonology[word], phoneme)\n",
        "            lex[i] = loss\n",
        "            if loss < val:\n",
        "                name = word\n",
        "                val = loss\n",
        "        lex_diff = lex.max() - lex.min()\n",
        "        lex = - ((lex - lex.min()) / lex_diff) + 1.\n",
        "        return lex\n",
        "\n",
        "    \n",
        "    \n",
        "    def convert_onset_vowel_coda_2_lexicon_ok(self, X, verbose=False):\n",
        "        \"\"\"phonlogy 表現からもっともらしい語彙表現を検索し，その当てはまり度合いから\n",
        "        語彙表象の値を返すことを考える。\n",
        "        1. phonolgy 層を onset, vowel, coda の 3 部分に分解\n",
        "        2. 分解した各音で softmax を実施し確率密度に変換\n",
        "        3. 3 つの部分を合成して phoneme 表現とする\n",
        "        4. phoneme 表現と phonology の 6 単語間の交差エントロピー誤差を計算する\n",
        "        5. 6 単語との交差エントロピー誤差の値から，最小値を引き， (最大値-最小値) で割ることで 0-1 に変換\n",
        "        6. マイナス 1 を掛けて 上限反転させて +1 することで， 0 から 1 までの値にする\n",
        "        \"\"\"\n",
        "        val = np.finfo(np.float).max     #np で定義済の安全な最大値を代入\n",
        "        #val = 0.\n",
        "        name = 'NG'                      #len(words) + 1 語彙名のダミー\n",
        "        s, lexeme, phoneme = self.split(X)\n",
        "        onset, vowel, coda = softmax(phoneme[:5]), softmax(phoneme[5:7]), softmax(phoneme[7:])\n",
        "        phoneme = np.concatenate((onset,vowel,coda))\n",
        "        lex = np.zeros_like(lexeme)\n",
        "        \n",
        "        for i, word in enumerate(self.phonology):\n",
        "            loss = CE_loss(phonology[word], phoneme)\n",
        "            lex[i] = loss\n",
        "            if loss < val:\n",
        "                name = word\n",
        "                val = loss\n",
        "        lex_diff = lex.max() - lex.min()\n",
        "        #lex = - (lex - lex.min() / lex_diff) + 1.\n",
        "        lex = - ((lex - lex.min()) / lex_diff) + 1.\n",
        "        return lex\n",
        "\n",
        "\n",
        "    def convert_onset_vowel_coda_2_lexicon_sigmoid(self, X, verbose=False):\n",
        "        \"\"\"phonlogy 表現からもっともらしい語彙表現を検索し，その当てはまり度合いから\n",
        "        語彙表象の値を返すことを考える。\n",
        "        1. phonolgy 層を sigmoid 変換して phoneme とする\n",
        "        2. phoneme 表現 と phonology の 6 単語間の交差エントロピー誤差を計算する\n",
        "        5. 6 単語との交差エントロピー誤差の値から，最小値を引き， (最大値-最小値) で割ることで 0-1 に変換\n",
        "        6. マイナス 1 を掛けて 上限反転させて +1 することで， 0 から 1 までの値にする\n",
        "        \"\"\"\n",
        "        val = np.finfo(np.float).max     #np で定義済の安全な最大値を代入\n",
        "        #val = 0.\n",
        "        name = 'NG'                      #len(words) + 1 語彙名のダミー\n",
        "        \n",
        "        s, lexeme, phoneme = self.split(X)\n",
        "        lex = np.zeros_like(lexeme)\n",
        "        phoneme = sigmoid(phoneme)\n",
        "        \n",
        "        for i, word in enumerate(self.phonology):\n",
        "            loss = CE_loss(phonology[word], phoneme)\n",
        "            lex[i] = loss\n",
        "            if loss < val:\n",
        "                name = word\n",
        "                val = loss\n",
        "        lex_diff = lex.max() - lex.min()\n",
        "        lex = - (lex - lex.min() / lex_diff) + 1.\n",
        "        return lex\n",
        "    \n",
        "\n",
        "    def fit(self, teacher=None, data=None, verbose=False, nonstop=False):\n",
        "        \"\"\"[]\n",
        "        fit は学習させることを意味するから命名\n",
        "\n",
        "        引数:\n",
        "        teacher: np.array\n",
        "            教師信号。\n",
        "        data: np.array\n",
        "            データ。教師信号に近づくように学習させる\n",
        "            \n",
        "        戻り値:\n",
        "        beta: float\n",
        "            温度パラメータ\n",
        "        [loss, pred, mse]\n",
        "        loss: float\n",
        "            損失関数の値\n",
        "        pred: np.array\n",
        "            予測値\n",
        "        mse: float\n",
        "            最小自乗誤差\n",
        "        \"\"\"\n",
        "        if isinstance(teacher, np.ndarray):\n",
        "            self.teacher = teacher\n",
        "        elif self.teacher == None:\n",
        "            print('Set the teacher signal.')\n",
        "            sys.exit()\n",
        "\n",
        "        if isinstance(data, np.ndarray):\n",
        "            self.data = data\n",
        "        else:\n",
        "            self.y, self.seriesY = self.one_trial(verbose=verbose)\n",
        "            #self.data = self.y\n",
        "\n",
        "        lex_est = self.convert_onset_vowel_coda_2_lexicon(self.y)\n",
        "        pred = softmax(lex_est)\n",
        "        loss0 = CE_loss(self.teacher, pred)  #損失関数の初期値\n",
        "        nonstopped = False\n",
        "        \n",
        "        satu_flag = False\n",
        "        \n",
        "        for i in range(self.iter_max):\n",
        "            \n",
        "            self.y, self.seriesY = self.one_trial(verbose=False)\n",
        "            lex_est = self.convert_onset_vowel_coda_2_lexicon(self.y)\n",
        "            pred = softmax(lex_est, beta=self.beta)\n",
        "            \n",
        "            loss = CE_loss(self.teacher, pred)\n",
        "            if loss0 < (loss + self.epsilon) and (not satu_flag) and (i>0):\n",
        "                print('iteration saturated at {0:05d} loss:{1:.3f}'.format(i,loss))\n",
        "                satu_flag = True\n",
        "            if loss0 > loss:\n",
        "                loss0 = loss\n",
        "                \n",
        "            if (i % self.interval) == 0:  # 途中結果の出力\n",
        "                if self.verbose:\n",
        "                    delta = self.teacher - pred                #教師信号と出力値との差分ベクトル\n",
        "                    mse = (delta**2).sum()/delta.shape[0]\n",
        "                    print('t:{0:05d} '.format(i),end='')\n",
        "                    print('beta:{0:6.3f} decay:{1:.3f} s:{2:.3f} p:{3:.3f}, loss:{4:.3f} pred:{5}'.format(\n",
        "                        1/self.beta, self.decay, self.s, self.p, loss, pred))\n",
        "                if (loss0 - loss) < self.epsilon and (i > 0) and (not nonstopped):\n",
        "                    print('Iteration terminated at {} times'.format(i))\n",
        "                    return [self.beta, self.decay, self.p, self.s], [loss, pred]\n",
        "            \n",
        "            self.y, self.seriesY = self.one_trial(verbose=verbose)\n",
        "            lex = self.convert_onset_vowel_coda_2_lexicon(self.y)\n",
        "            pred = softmax(lex, beta=self.beta)\n",
        "            delta = self.teacher - pred                #教師信号と出力値との差分ベクトル\n",
        "            g_delta = delta / (1-pred)\n",
        "\n",
        "            #beta の更新\n",
        "            ybar = lex.mean()\n",
        "            ybar2 = np.dot(pred, lex)\n",
        "            #Z = np.exp(lex).sum()\n",
        "            #ydiff = lex - ybar/(Z + self.epsilon)\n",
        "            ydiff = lex - ybar\n",
        "            #ydiff = lex - ybar2\n",
        "            self.beta += self.lr * (g_delta * ydiff).sum()\n",
        "\n",
        "            s, l, p = self.split(self.seriesY[-1])\n",
        "            W_pp = self.W[self.pho_slice, self.pho_slice]\n",
        "            W_lp = self.W[self.lex_slice, self.pho_slice]\n",
        "            W_sl = self.W[self.sem_slice, self.lex_slice]\n",
        "            \n",
        "            d_delta = np.dot(W_lp.T, g_delta)\n",
        "            y = np.dot(W_pp,p)\n",
        "            ybar = y.mean()\n",
        "            ydiff = y - ybar\n",
        "            self.decay += self.lr * (d_delta * ydiff).sum()\n",
        "\n",
        "            l_delta = np.dot(W_lp, d_delta)\n",
        "            y = np.dot(W_lp,p)\n",
        "            ybar = y.mean()\n",
        "            ydiff = y - ybar\n",
        "            self.p += self.lr * (l_delta * ydiff).sum()\n",
        "            \n",
        "            s_delta = np.dot(W_sl, l_delta)\n",
        "            y = np.dot(W_lp,p)\n",
        "            y2 = np.dot(W_sl,y)\n",
        "            ybar = y2.mean()\n",
        "            ydiff = y2 - ybar\n",
        "            #print('546 ydiff.sahpe:', ydiff.shape)\n",
        "            #print('547 s_delta.shape:', s_delta.shape)\n",
        "            #print('584 ', s_delta * ydiff)\n",
        "            #sys.exit()\n",
        "            self.s += self.lr * (s_delta * ydiff).sum()\n",
        "                \n",
        "            #self.decay -= self.lr * d_decay\n",
        "            #if self.decay < self.epsilon:\n",
        "            #    self.decay = self.epsilon\n",
        "            #for x, y  in zip([self.s, self.p],[d_s, d_p]):\n",
        "            #    x += self.lr * y\n",
        "\n",
        "\n",
        "        # 平均自乗誤差の計算\n",
        "        #mse = (delta**2).sum()/delta.shape[0]\n",
        "        return [self.beta, self.decay, self.p, self.s], [loss, pred]\n",
        "    \n",
        "    \n",
        "#表示桁数の設定\n",
        "np.set_printoptions(suppress=False, formatter={'float': '{:4.2f}'.format})\n",
        "#np.set_printoptions(suppress=False, formatter={'float': '{:4.2f}'.format})\n",
        "\n",
        "teacher = np.copy(Dells_controls)\n",
        "#teacher = np.array([0.82, 0.04, 0.02, 0.09, 0.01, 0.01])  # L.B\n",
        "#f = Dell2021(Weights='raw', teacher=teacher, d=0.5, iter_max=10 ** 4, lr=25, IFG_beta=8, f=tanh, verbose=True) # f=ReLU)\n",
        "model = Dell2021(Weights='raw', teacher=teacher, d=0.5, iter_max=10 ** 4, lr=1, IFG_beta=8, f=tanh, verbose=False) # f=ReLU)\n",
        "\n",
        "#data = np.array([8.359,2.218,3.285,5.258,0.193,3.504])\n",
        "#data = np.array([20.840,9.077,6.209,14.118,0.833,6.792])\n",
        "[beta, decay, s, p], [loss, pred] = model.fit(teacher=teacher, verbose=False)\n",
        "\n",
        "draw_dell_graph(teacher, pred, \n",
        "                alabel=\"Dell(1997)健常者のデータ\", acolor='blue',\n",
        "                blabel=\"2021 年型 Dell 最新モデル\", bcolor='green')\n",
        "\n",
        "print('          ', list(model.phonology.keys()))\n",
        "print('teacher:  ', teacher)\n",
        "print('pred:     ', pred)\n",
        "print('beta:{0:.3f} decay:{1:.3f} s:{2:.3f} p:{3:.3f}'.format(1/beta, decay, s, p))\n"
      ],
      "id": "b000dd43",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "af8ccc15-ea55-4308-b566-10bfe5f26a48"
      },
      "source": [
        "print('#Dell のデータ, 実データ, wd model, sp model, Foygell and Dell (2000) Table 2 and 4 を参照のこと')\n",
        "for patient in FoygellDell_tab2_and_4:\n",
        "    data_n, data_n_wd, data_n_sp = 0, 1, 2\n",
        "    data = np.array(FoygellDell_tab2_and_4[patient][data_n][:6])\n",
        "    #model = Dell2021(Weights='raw', teacher=data, d=0.5, iter_max=10 ** 4, lr=1, IFG_beta=8, f=tanh, verbose=False)\n",
        "    model = Dell2021(Weights='raw', teacher=data, d=0.5, iter_max=10 ** 4, lr=0.5, IFG_beta=8, f=tanh, verbose=False)\n",
        "    [beta, decay, s, p], [loss, pred] = model.fit(teacher=data, verbose=False)\n",
        "\n",
        "    #alabel=\n",
        "    draw_dell_graph(data, pred, title='Foygell and Dell (2000)', \n",
        "                    alabel='patient:{0} From Foygell & Dell(2000) Tab. 2'.format(patient), acolor='black',\n",
        "                    blabel='2021年型 新型Dellモデルによる推定値', bcolor='gray',\n",
        "                    width_inches=6, height_inches=3, fontsize=12)\n"
      ],
      "id": "af8ccc15-ea55-4308-b566-10bfe5f26a48",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6958c470"
      },
      "source": [
        "#import gensim.downloader as api\n",
        "#glove_en = api.load('word2vec-google-news-300', return_path=True)\n",
        "\n",
        "#DellX = np.zeros((len(lexicons),len(glove_en['cat'])))\n",
        "#for i, word in enumerate(lexicon):\n",
        "#    DellX[i] = np.copy(glove_en[word])\n",
        "\n",
        "#Dell_wordR = np.corrcoef(DellX)\n",
        "#np.savetxt('Dell_wordR.txt',Dell_wordR)\n",
        "\n",
        "# Dell の Lexicon 間の相関係数行列。存在しない場合は，このセル上部のコメントをはずして実行\n",
        "Dell_LexR = np.array([\n",
        "    [1.000000000000000000e+00, 7.607610875238556281e-01, 1.526896477666510876e-01, \n",
        "     5.327596034338319964e-01, 7.083070865057317089e-02, -1.112107376916258127e-02],\n",
        "    [7.607610875238557391e-01, 1.000000000000000000e+00, 1.842294356793724996e-01, \n",
        "     4.393862362725595161e-01, 6.237472001379058828e-02, 3.078664862324366047e-03],\n",
        "    [1.526896477666510876e-01, 1.842294356793724719e-01, 1.000000000000000000e+00, \n",
        "     7.657631000394304888e-02, 8.018105209643067166e-02, 1.477240578677296579e-01],\n",
        "    [5.327596034338321074e-01, 4.393862362725595716e-01, 7.657631000394306275e-02, \n",
        "     9.999999999999998890e-01, 6.513470828101816656e-02, -6.153752081466464657e-02],\n",
        "    [7.083070865057317089e-02, 6.237472001379059522e-02, 8.018105209643067166e-02, \n",
        "     6.513470828101815269e-02, 1.000000000000000000e+00, 1.396624608082916268e-02],\n",
        "    [-1.112107376916258127e-02, 3.078664862324366480e-03, 1.477240578677296579e-01, \n",
        "     -6.153752081466464657e-02, 1.396624608082916268e-02, 9.999999999999997780e-01]])\n",
        "print(lexicon)\n",
        "print(Dell_LexR)"
      ],
      "id": "6958c470",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c7338dcf"
      },
      "source": [
        ""
      ],
      "id": "c7338dcf",
      "execution_count": null,
      "outputs": []
    }
  ]
}