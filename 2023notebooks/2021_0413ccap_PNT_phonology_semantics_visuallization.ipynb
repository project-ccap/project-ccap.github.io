{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/project-ccap/project-ccap.github.io/blob/master/2023notebooks/2021_0413ccap_PNT_phonology_semantics_visuallization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sIAhUL6st95L"
      },
      "source": [
        "# フィラデルフィア絵画命名検査の音韻，意味情報の視覚化\n",
        "- filename: 2021_0413ccap_PNT_phonology_semantics_visuallization.ipynb\n",
        "- author: 浅川伸一\n",
        "- date: 2021-0414\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0t35YrJyjcZ2",
        "tags": []
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "np.set_printoptions(suppress=False, formatter={'float': '{:6.3f}'.format})\n",
        "import os\n",
        "\n",
        "pnt_stim_fname = 'pnt_stim.csv'\n",
        "if not os.path.exists(pnt_stim_fname):\n",
        "    #フィラデルフィア絵画命名検査の各図版の刺激名データを外部から入手\n",
        "    !wget https://raw.githubusercontent.com/hanayik/Philadelphia-Naming-Test/master/assets/stim.csv -O pnt_stim.csv\n",
        "\n",
        "i = 0\n",
        "PNT = {}\n",
        "PNT_words = []\n",
        "with open(pnt_stim_fname, 'r') as f:\n",
        "    while i < 185:\n",
        "        x =  f.readline().strip().replace(' ','').split(',')\n",
        "        if i == 0:\n",
        "            x_keys = x\n",
        "        else:\n",
        "            PNT[int(x[0])] = {}\n",
        "            for x_, key in zip(x, x_keys):\n",
        "                PNT[int(x[0])][key] = x_\n",
        "            PNT_words.append(PNT[int(x[0])]['PictureName'])\n",
        "        i += 1\n",
        "\n",
        "print(PNT_words)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ecXmwpKduxdP"
      },
      "source": [
        "# フィラデルフィア絵画命名検査の音韻情報を視覚化"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2GnMGXE-jqZL",
        "tags": []
      },
      "outputs": [],
      "source": [
        "#単語の音韻情報を得るために，カーネギーメロン大学の単語音韻辞書を読み込み\n",
        "import nltk\n",
        "\n",
        "try:\n",
        "    arpabet = nltk.corpus.cmudict.dict()\n",
        "except LookupError:\n",
        "    nltk.download('cmudict')\n",
        "    arpabet = nltk.corpus.cmudict.dict()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9di0VwGWkAa2",
        "tags": []
      },
      "outputs": [],
      "source": [
        "#各単語を音韻情報に変換\n",
        "PNT_phoneme = {}\n",
        "for word in PNT_words:\n",
        "    if word in arpabet:\n",
        "        PNT_phoneme[word] = arpabet[word]\n",
        "#PNT_phoneme"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7UC8NmbqkDJ6",
        "tags": []
      },
      "outputs": [],
      "source": [
        "import re\n",
        "try:\n",
        "    import Levenshtein\n",
        "except ImportError:\n",
        "    !pip install Levenshtein\n",
        "    import Levenshtein\n",
        "\n",
        "# CMU (カーネギーメロン大学) の単語音韻辞書には次の 39 個の音素が使われている\n",
        "arpabet_phoneme=['<EOW>', 'AA', 'AE', 'AH', 'AO', 'AW', 'AY', 'B', 'CH', 'D', 'DH',\n",
        "                 'EH', 'ER', 'EY', 'F', 'G', 'HH', 'IH', 'IY', 'JH', 'K',\n",
        "                 'L', 'M', 'N', 'NG', 'OW', 'OY', 'P', 'R', 'S', 'SH',\n",
        "                 'T', 'TH', 'UH', 'UW', 'V', 'W', 'Y', 'Z', 'ZH']\n",
        "\n",
        "#以下は音韻情報から各単語の音韻距離を計算するための準備\n",
        "PPP = np.zeros((len(PNT),len(arpabet_phoneme)), dtype=int)\n",
        "max_len = 0\n",
        "for i, word in enumerate(PNT_words):\n",
        "    phonology_ = PNT_phoneme[word][0]\n",
        "    l = len(phonology_)\n",
        "    if l > max_len:\n",
        "        max_len = l\n",
        "\n",
        "    for p in phonology_:\n",
        "        # 音韻から 数字を取り除く\n",
        "        p_ = re.sub('[012]','', p)\n",
        "        j = arpabet_phoneme.index(p_)\n",
        "        PPP[i,j] += 1\n",
        "\n",
        "pnt_phon_mat = np.zeros((len(PNT), max_len),dtype=int)\n",
        "for i, word in enumerate(PNT_words):\n",
        "    j = 0\n",
        "    for p in PNT_phoneme[word][0]:\n",
        "        p_ = re.sub('[012]','', p)\n",
        "        x = arpabet_phoneme.index(p_)\n",
        "        pnt_phon_mat[i,j] = x\n",
        "        j += 1\n",
        "\n",
        "i=1\n",
        "for word, v in zip(PNT_words, pnt_phon_mat):\n",
        "    print(f'{i:03d} {word}', end=\":[\")\n",
        "    for _v in v:\n",
        "        if _v == 0:\n",
        "            print(']', end=\", [\")\n",
        "            break\n",
        "        print(_v, end=' ')\n",
        "    for _v in v:\n",
        "        if arpabet_phoneme[_v] == '<EOW>':\n",
        "            print(']')\n",
        "            break\n",
        "        print(arpabet_phoneme[_v], end=\" \")\n",
        "    i += 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gj7QM04ovev-"
      },
      "source": [
        "## 以下にカーネギーメロン大学の単語音韻の情報を貼り付けます\n",
        "```\n",
        "# Natural Language Toolkit: Carnegie Mellon Pronouncing Dictionary Corpus Reader\n",
        "#\n",
        "# Copyright (C) 2001-2021 NLTK Project\n",
        "# Author: Steven Bird <stevenbird1@gmail.com>\n",
        "# URL: <http://nltk.org/>\n",
        "# For license information, see LICENSE.TXT\n",
        "\n",
        "\"\"\"\n",
        "The Carnegie Mellon Pronouncing Dictionary [cmudict.0.6]\n",
        "ftp://ftp.cs.cmu.edu/project/speech/dict/\n",
        "Copyright 1998 Carnegie Mellon University\n",
        "\n",
        "File Format: Each line consists of an uppercased word, a counter\n",
        "(for alternative pronunciations), and a transcription.  Vowels are\n",
        "marked for stress (1=primary, 2=secondary, 0=no stress).  E.g.:\n",
        "NATURAL 1 N AE1 CH ER0 AH0 L\n",
        "\n",
        "The dictionary contains 127069 entries.  Of these, 119400 words are assigned\n",
        "a unique pronunciation, 6830 words have two pronunciations, and 839 words have\n",
        "three or more pronunciations.  Many of these are fast-speech variants.\n",
        "\n",
        "Phonemes: There are 39 phonemes, as shown below:\n",
        "\n",
        "Phoneme Example Translation    Phoneme Example Translation\n",
        "------- ------- -----------    ------- ------- -----------\n",
        "AA      odd     AA D           AE      at      AE T\n",
        "AH      hut     HH AH T        AO      ought   AO T\n",
        "AW      cow     K AW           AY      hide    HH AY D\n",
        "B       be      B IY           CH      cheese  CH IY Z\n",
        "D       dee     D IY           DH      thee    DH IY\n",
        "EH      Ed      EH D           ER      hurt    HH ER T\n",
        "EY      ate     EY T           F       fee     F IY\n",
        "G       green   G R IY N       HH      he      HH IY\n",
        "IH      it      IH T           IY      eat     IY T\n",
        "JH      gee     JH IY          K       key     K IY\n",
        "L       lee     L IY           M       me      M IY\n",
        "N       knee    N IY           NG      ping    P IH NG\n",
        "OW      oat     OW T           OY      toy     T OY\n",
        "P       pee     P IY           R       read    R IY D\n",
        "S       sea     S IY           SH      she     SH IY\n",
        "T       tea     T IY           TH      theta   TH EY T AH\n",
        "UH      hood    HH UH D        UW      two     T UW\n",
        "V       vee     V IY           W       we      W IY\n",
        "Y       yield   Y IY L D       Z       zee     Z IY\n",
        "ZH      seizure S IY ZH ER\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M8rzBSzYkH3i",
        "tags": []
      },
      "outputs": [],
      "source": [
        "#視覚化のためのライブラリを読み込む\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import TSNE\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "try:\n",
        "    import japanize_matplotlib\n",
        "except ImportError:\n",
        "    !pip install japanize_matplotlib\n",
        "    import japanize_matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lnhW39mmkT2a",
        "tags": []
      },
      "outputs": [],
      "source": [
        "#レーベンシュタイン距離は，utf8 で符号化された文字列間の距離なので，カーネギーメロン大学の\n",
        "#単語音韻辞書を用いて，単語の音素情報を擬似的な文字列に変換する。\n",
        "#そのため一旦，無意味な日本語カナに変換することを試みた\n",
        "ja_str = 'アイウエオカキクケコサシスセソタチツテトナニヌネノハヒフヘホマミムメモヤユヨラリルレロワヰヱヲン'\n",
        "pnt_phon_Sim = np.zeros((len(PNT), len(PNT)))\n",
        "\n",
        "for i, w1 in enumerate(PNT_words):\n",
        "    p1 = PNT_phoneme[w1][0]\n",
        "    p1 = [re.sub('[012]', '', x) for x in p1]\n",
        "    jw1 = \"\"\n",
        "    for x in p1:\n",
        "        jw1 = jw1 + ja_str[arpabet_phoneme.index(x)]\n",
        "\n",
        "    for j, w2 in enumerate(PNT_words):\n",
        "        p2 = PNT_phoneme[w2][0]\n",
        "        p2 = [re.sub('[012]', '', x) for x in p2]\n",
        "        jw2 = \"\"\n",
        "        for x in p2:\n",
        "            jw2 = jw2 + ja_str[arpabet_phoneme.index(x)]\n",
        "        pnt_phon_Sim[i,j] = Levenshtein.distance(jw1,jw2)\n",
        "\n",
        "        #print(i, j, w1, p1, jw1, w2, p2, jw2, Levenshtein.distance(jw1,jw2))\n",
        "\n",
        "pnt_phon_Sim /= pnt_phon_Sim.max()\n",
        "pnt_phon_Sim_df = pd.DataFrame(data=pnt_phon_Sim, index=PNT_words)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(12,10))         # Sample figsize in inches\n",
        "sns.heatmap(pnt_phon_Sim_df, ax=ax)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FcG1_bLjk1vz",
        "tags": []
      },
      "outputs": [],
      "source": [
        "#主成分分析による音韻距離の視覚化\n",
        "def ax_scatter_gram(ax, pca1, pca2, wordlist, title=None):\n",
        "    ax.scatter(pca1, pca2, s=200, color='cyan')\n",
        "    for i, label in enumerate(wordlist):\n",
        "        ax.annotate(label, (pca1[i], pca2[i]),fontsize=14)\n",
        "    ax.set_xlabel(\"第一主成分\")\n",
        "    ax.set_ylabel(\"第二主成分\")\n",
        "    ax.set_title(title,fontsize=18)\n",
        "\n",
        "def plot_pca(ax, R, wordlist, title=\"\"):\n",
        "    pca = PCA(n_components=2)\n",
        "    pca_result = pca.fit_transform(R)\n",
        "    pca1, pca2 = pca_result[:,0], pca_result[:,1]\n",
        "    print('\\tExplained variation per principal component: {}'.format(pca.explained_variance_ratio_))\n",
        "    ax_scatter_gram(ax, pca1, pca2, wordlist, title=title)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(8,8))         # Sample figsize in inches\n",
        "#fig, ax = plt.subplots(figsize=(12,13))         # Sample figsize in inches\n",
        "plot_pca(ax, pnt_phon_Sim, PNT_words, title='音韻情報のレーベンシュタイン距離による附置 (PCA)')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ITxaGlA-k6gC",
        "tags": []
      },
      "outputs": [],
      "source": [
        "#上図と同じデータを tSNE を使って視覚化\n",
        "tsne = TSNE()\n",
        "pnt_tsne = TSNE(n_components=2).fit_transform(pnt_phon_Sim)\n",
        "fig, ax = plt.subplots(figsize=(8,8))         # Sample figsize in inches\n",
        "#fig, ax = plt.subplots(figsize=(12,13))         # Sample figsize in inches\n",
        "ax.scatter(pnt_tsne[:,0], pnt_tsne[:,1], s=200, color='cyan')\n",
        "for i, label in enumerate(PNT_words):\n",
        "    ax.annotate(label, (pnt_tsne[i,0], pnt_tsne[i,1]),fontsize=14)\n",
        "ax.set_xlabel(\"tSNE 1\")\n",
        "ax.set_ylabel(\"tSNE 2\")\n",
        "title = '音韻情報のレーベンシュタイン距離によるフィラデルフィア絵画命名検査刺激図版の附置 （ｔＳＮＥ）'\n",
        "ax.set_title(title,fontsize=18)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ytDeYbKawzRI"
      },
      "source": [
        "#フィラデルフィア絵画命名検査の意味情報の視覚化"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sE0-pEZZlRrj",
        "tags": []
      },
      "outputs": [],
      "source": [
        "import gensim.downloader as api\n",
        "#単語埋め込みモデルのダウンロード，数分程度時間がかかります\n",
        "#glove_en = api.load('word2vec-google-news-300', return_path=True)\n",
        "glove_en = api.load('word2vec-google-news-300')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CgwE_eoeoZuT"
      },
      "outputs": [],
      "source": [
        "#行列の表示桁数の設定\n",
        "np.set_printoptions(suppress=False, formatter={'float': '{:6.3f}'.format})\n",
        "\n",
        "\n",
        "#単語埋め込みモデルから，単語の意味情報を取り出して格納\n",
        "PNT_semantics = np.zeros((len(PNT),len(glove_en['whale'])))\n",
        "for i, word in enumerate(PNT_words):\n",
        "    PNT_semantics[i] = np.copy(glove_en[word])\n",
        "\n",
        "#相関係数行列を計算して表示\n",
        "PNT_df = pd.DataFrame(data=PNT_semantics,index=PNT_words)\n",
        "PNT_df.T.corr()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8IxtUyQsqdQ3"
      },
      "outputs": [],
      "source": [
        "#意味間の相関係数行列の視覚化\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(12,10))         # Sample figsize in inches\n",
        "sns.heatmap(PNT_df.T.corr(), ax=ax)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_0WhGobWqf2x"
      },
      "outputs": [],
      "source": [
        "#上で求めた相関係数行列から主成分分析により附置を描画\n",
        "def ax_scatter_gram(ax, pca1, pca2, wordlist, title=None):\n",
        "    #ax.scatter(pca1[:1], pca2[:1], s=200, color='red')\n",
        "    ax.scatter(pca1, pca2, s=100, color='cyan')\n",
        "    #ax.scatter(pca1, pca2, s=200, color='cyan')\n",
        "    for i, label in enumerate(wordlist):\n",
        "        ax.annotate(label, (pca1[i], pca2[i]),fontsize=10)\n",
        "        #ax.annotate(label, (pca1[i], pca2[i]),fontsize=14)\n",
        "    ax.set_xlabel(\"第一主成分\")\n",
        "    ax.set_ylabel(\"第二主成分\")\n",
        "    ax.set_title(title,fontsize=10)\n",
        "\n",
        "def plot_pca(ax, R, wordlist, title=\"\"):\n",
        "    pca = PCA(n_components=2)\n",
        "    pca_result = pca.fit_transform(R)\n",
        "    pca1, pca2 = pca_result[:,0], pca_result[:,1]\n",
        "    print('\\tExplained variation per principal component: {}'.format(pca.explained_variance_ratio_))\n",
        "    ax_scatter_gram(ax, pca1, pca2, wordlist, title=title)\n",
        "\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(8,8))         # Sample figsize in inches\n",
        "#fig, ax = plt.subplots(figsize=(12,13))         # Sample figsize in inches\n",
        "plot_pca(ax, PNT_df.T.corr(), PNT_words, title='単語埋め込みモデルを用いた PNT 刺激の意味附置 (PCA)')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QG6rLa4Tq2FN"
      },
      "outputs": [],
      "source": [
        "#上図と同じデータを用いて tSNE で描画\n",
        "tsne = TSNE()\n",
        "pnt_tsne = TSNE(n_components=2).fit_transform(PNT_semantics)\n",
        "#print(pnt_tsne.shape)\n",
        "fig, ax = plt.subplots(figsize=(8,8))           # Sample figsize in inches\n",
        "#fig, ax = plt.subplots(figsize=(12,13))         # Sample figsize in inches\n",
        "ax.scatter(pnt_tsne[:,0], pnt_tsne[:,1], s=100, color='cyan')\n",
        "#ax.scatter(pnt_tsne[:,0], pnt_tsne[:,1], s=200, color='cyan')\n",
        "for i, label in enumerate(PNT_words):\n",
        "    ax.annotate(label, (pnt_tsne[i,0], pnt_tsne[i,1]),fontsize=10)\n",
        "ax.set_xlabel(\"tSNE 1\")\n",
        "ax.set_ylabel(\"tSNE 2\")\n",
        "title = '単語埋め込みモデルを用いた PNT 刺激の意味附置 (tSNE)'\n",
        "ax.set_title(title,fontsize=12)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9J1C4yFmq56U"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}